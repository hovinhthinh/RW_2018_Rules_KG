\section{Rules and Reasoning}
\label{sec:reasoning}
In this section we briefly review concepts of rules, logic programming (see \cite{DBLP:conf/rweb/EiterIK09} for more details) as well as %their usage in 
deductive and inductive reasoning.
%relational association rules \cite{warmer}.

\subsection{Logic Programs} Logic programs consist of a set of rules. Intuitively, a rule is an if-then expression, whose if-part may contain several conditions, some possibly with
negation. The then-part has a single atom that has to hold, whenever the if-part holds. In general, the left part of a rule can also contain disjunctions, but in this tutorial we consider only non-disjunctive rules. More formally,


\begin{definition}[Rule] A \emph{rule} $r$ is an expression of the form
\begin{equation}
H\leftarrow B, \naf\ E
\end{equation}
where $H$ is a standard first-order atom of the form $a(\vec{X})$, $B$ is a conjunction of positive atoms of the form $b_1(\vec{Y_1}),\dotsc,b_k(\vec{Y_k})$, and $\naf\ E$ %with slight abuse of notation, 
 is a conjunction of negated atoms $\naf\, b_{k+1}(\vec{Y_{k+1}}),\dotsc,\naf\, b_n(\vec{Y_{n}})$. Moreover,  $\vec{X},\vec{Y_1},\ldots,\vec{Y_{n}}$ are tuples of either variables or constants whose length corresponds to the arity of the predicates $a,b_1,\ldots,b_n$ respectively.
% . such that $\naf$ is the so-called \emph{negation as failure (NAF)} or \emph{default negation}, \ie $\naf\, b_n$ is true if either $b_n$ is false or unknown. 
\end{definition}

The left-hand side of a rule $r$ is referred to as its head, denoted by $\mi{head(r)}$, while the right-hand side is its body $\mi{body(r)}$. The positive and negative parts of the body are respectively denoted as $\mi{body^+(r)}$ and $\mi{body^-(r)}$. A rule $r$ is called \emph{positive} or
\emph{Horn} if $\mi{body^-}(r)=\emptyset$.

\begin{example}
Consider $\mi{r_2}$ from Section~\ref{sec:intro}. We have that $\mi{head(r_2)}=\{livesIn(Y,Z)\}$, while $\mi{body^+(r_2)=\{isMarriedTo(X,Y), livesIn(X,Z)\}}$, and moreover it holds that, $\mi{body^-(r_2)=\{not\;researcher(Y)\}}$. \qed
\end{example}




A logic program $P$ is \emph{ground} if it consists of only ground rules, i.e. rules without
variables. 

\begin{example}
For instance, a possible grounding of the rule $\mi{r_2}$ is given as follows $\mi{livesIn(dave,chicago)\leftarrow livesIn(clara,chicago),isMarriedTo(clara,dave),}$\\$
\phantom{livesIn(dave,chicago)\leftarrow}\naf\mi{\;researcher(dave)}$. \qed
\end{example}

Ground instantiation $Gr(P)$ of a nonground program $P$ is obtained by substituting variables with constants in all possible ways. 


\begin{definition}[Herbrand Universe, Base, Interpretation]
A \emph{Herbrand universe}  $\mi{HU(P)}$ is a set of all constants occurring in the given program $\mi{P}$. A \emph{Herbrand base}  $\mi{HB(P)}$ is a set of all possible ground atoms that can be formed with predicates and constants appearing in $P$. A \emph{Herbrand interpretation} is any subset of $\mi{HB(P)}$.
\end{definition}

We now formally define the satisfaction relation.

\begin{definition}[Satisfaction, Model] An interpretation $I$ satisfies
\begin{itemize}
\item a ground atom a, denoted $I \models a$, if $a \in I$,
\item a negated ground atom $\mi{not\; a}$, denoted $I \models \mi{not\; a}$ if $I \not \models a$,
\item  a conjunction $b_1,\dotsc,b_n$ of ground literals, denoted $I \models b_1,\dotsc,b_n$, if for
each $i\in \{1,\dotsc, n\}$ it holds that $I \models b_i$,
\item a ground rule $r$, denoted $I \models r$ if $I \models \mi{body(r)}$ implies $I \models \mi{head(r)}$, i.e., if all literals in the body hold then the literal in the head also holds.
\end{itemize}
\end{definition}

An interpretation $I$ is a \emph{model} of a ground program $P$, if $I \models r$ for each rule
$r \in P$. A model $I$ is \emph{minimal} if there is no other model $I' \subset I$.
By $\mi{MM(P)}$ we denote the set-inclusion minimal model of a ground positive program $P$.

\begin{definition}[Gelfond-Lifschitz reduct, answer set]
An interpretation $I$ of $P$ is an \emph{answer set} (or \emph{stable model}) of $P$ iff $I \in \mi{MM}(P^I)$, where $P^I$ is the \emph{Gelfond-Lifschitz (GL) reduct} of $P$, obtained from $Gr(P)$ by removing (i) each rule $r$ such that $\mi{Body}^-(r) \cap I\neq\emptyset$, and (ii) all the negative atoms from the remaining rules. The set of answer sets of a program $P$ is denoted by $AS(P)$.
\end{definition}



\begin{example}\label{ex:as}
Consider the program \\
{\small \leftline{$P = \left\{
            \renewcommand{\arraystretch}{1.1}
            \begin{array}{@{\,}l@{~~}l@{}}
              \mbox{(1) }\mi{livesIn(brad,berlin)};\;\mbox{(2) }\mi{isMarriedTo(brad,ann)};\\
              \mbox{(3) } \mi{livesIn(Y,Z)\leftarrow isMarriedTo(X,Y),livesIn(X,Z),  \naf\ researcher(Y)}\\
            \end{array}%
            \!\right\}$}}
            
\normalsize
{\smallskip

\noindent            
The ground instantiation $Gr(P)$ of $P$ is obtained by substituting $X,Y,Z$ with $\mi{brad, \,ann}$ and $\mi{berlin}$ respectively. For $I{=}\{${\small$\mi{isMarriedTo(brad{,}ann){,}livesIn(ann{,}berlin)},\\ \mi{livesIn(brad,berlin)}$}$\}$, the GL-reduct $P^I$ of $P$ contains $\mi{livesIn(ann,berlin)}\leftarrow \mi{livesIn(brad,berlin),isMarriedTo(brad,ann)}$ and the facts (1), (2). As $I$ is a minimal model of $P^I$, it holds that $I$ is an answer set of $P$.}\qed
\end{example}
\normalsize

Apart from the model computation, another important task concerns deciding whether a given atom $a$ is entailed from the program $P$ denoted by $P \models a$. Typically, one distinguishes between brave and cautious entailment. We say that an atom $a$ is \emph{cautiously entailed} from a program $P$ ($P \models_c a$) if $a$ is present in all answer sets of $P$. Conversely, an atom $a$ is \emph{bravely entailed} from a program $P$ ($P \models_b a$) if it is present in at least one answer set of $P$. If a program has only a single answer set, e.g., it is positive, then obviously cautious and brave entailments coincide, in which case we omit the subscript.

The answer set semantics for nonmonotonic logic programs is based on the CWA, under which whatever can not be derived from a program is assumed to be false. Nonmonotonic logic programs are widely applied for formalizing common sense deductive reasoning over incomplete information.



\subsection{Inductive Reasoning Tasks}
%In this section we first describe the possible learning tasks that could be performed over KGs and then overview the existing systems for relational association rule learning tailored towards incomplete KGs. 
\label{sec:rules_learning_tasks}

So far we have focused on logic programs and their semantics for deductive reasoning. We now discuss the problem of automatic rule induction, which is a research area commonly referred to as rule learning (see, e.g., \cite{DBLP:books/daglib/0021868,DBLP:series/cogtech/FurnkranzGL12}). 

Broadly speaking, rule learning is an important sub-field of machine learning, which focuses on symbolic methods for intelligent data analysis, i.e., methods that employ a certain description language in which the learned knowledge is represented. % One of the main attractions of rule induction is that the rules are much more transparent and easier to interpret than, e.g., a regression model or trained neural network.

First-order learning approaches are also referred to as %\emph{relational data mining (RDM)}, \emph{relational learning
%(RL)} or
 \emph{inductive logic programming (ILP)}, since the patterns they discover are expressed in
relational formalisms of first-order logic (see \cite{DBLP:books/daglib/0021868} for overview).
The goal of ILP is to generalize individual instances/observations in the presence of background knowledge by building
hypotheses about yet unseen instances. The most commonly addressed task in ILP is the task
of learning logical definitions of relations. From training examples ILP induces a
logic program (predicate definition) corresponding to a view
that defines the target relation in terms of other relations
that are given as background knowledge. 

More formally, the classical inductive logic programming task of learning from positive and negative examples 
is defined as follows:
\begin{definition}[Inductive learning from examples]\label{def:learnex}
\begin{itemize}
\item[] \textbf{Given:}
\begin{itemize}
\item Positive examples $E^+$ and negative examples $E^-$ over target relation $p$
\item Relations that can be used to induce the definition of $p$, i.e., background knowledge $B$
\item Syntactic restrictions on the definition of $p$
\end{itemize}
\smallskip

\item[] \textbf{Find:}
\begin{itemize}
\item A hypothesis $\mi{Hyp}$ that defines the target relation $p$, which is (i) \emph{complete}, i.e., $\forall e\in E^+$, it holds $B \cup \mi{Hyp} \models e$, and (ii) \emph{consistent}, i.e., $\forall e' \in E^-$: $B \cup \mi{Hyp} \not \models e'$.
\end{itemize}
\end{itemize}
\end{definition}
 This problem, introduced in \cite{DBLP:journals/ngc/Muggleton91}, is
 also often called \emph{learning from entailment}. 


\begin{example}
\label{ex:ilp}
Suppose that you possess information about some of the relationships between people in your family and their genders.
However, you do not know what the relationship $\mi{fatherOf}$ actually means. 
You might have the following beliefs, i.e., background knowledge.
\smallskip

{\leftline{$B = \left\{
            \renewcommand{\arraystretch}{1.1}
            \begin{array}{@{\,}l@{~~}l@{}}
              \mbox{(1) } \mi{parent (john, mary)};
               \mbox{(2) }\mi{male(john)};
              \mbox{(3) }\mi{parent (david, steve)};\\
              \mbox{(4) }\mi{ male(david)};
              \mbox{(5) }\mi{parent (kathy, ellen)};
              \mbox{(6) }\mi{ female (kathy)};
            \end{array}%
            \!\right\}$}}
\smallskip

Moreover, you are given the following positive and negative examples.
\smallskip

\noindent $\mi{E^+=\{fatherOf(john, mary), fatherOf(david, steve)\}}$\\
$\mi{E^-=\{fatherOf(kathy, ellen), fatherOf(john, steve)\}}$\\

One of the possible hypothesis that can be induced from the above knowledge reflecting the meaning of the $\mi{fatherOf}$ relation is given as follows:\\
$\mi{Hyp: fatherOf(X, Y)\leftarrow parentOf(X,Y), male(X)}$. This hypothesis is consistent with the background theory $B$, and together with $B$ it entails all of the positive examples, and none of the negative ones, i.e., $\mi{Hyp \cup B \models E^+}$, $\mi{Hyp \cup B \not \models E^-}$. The classical ILP task concerns automatic extraction of such hypothesis. \qed
\end{example}

In an alternative setting, known as \emph{learning from interpretations} proposed in \cite{DBLP:journals/ai/RaedtD94}, instead of positive and negative examples over a certain relation, one is given a Herbrand interpretation $E$, i.e., a set of facts, and conditions (i) and (ii) in Definition~\ref{def:learnex} are replaced with the requirement that $E$ is a minimal model of $\mi{Hyp} \cup B$.
Formally, 
\begin{definition}[Inductive learning from interpretations]
\begin{itemize}
\item[] \textbf{Given:}
\begin{itemize}
\item An interpretation $E$, i.e., a set of facts over various relations
\item Background knowledge $B$
\item Syntactic restrictions on the form of rules to be induced
\end{itemize}
\smallskip

\item[] \textbf{Find:}
\begin{itemize}
\item A hypothesis $\mi{Hyp}$, such that $E$ is a minimal Herbrand model of $\mi{Hyp \cup B}$.
\end{itemize}
\end{itemize}
\end{definition}

Several variations of learning from interpretations task have been proposed including learning from answer sets \cite{DBLP:journals/tocl/Sakama05,DBLP:journals/ai/LawRB18}, where given possibly multiple partial interpretations, the goal is to find a logic program, which has extensions of (all of) the provided interpretations as answer sets.

The ILP field has been actively developed within the past couple of decades, and extended along several dimensions.
Todate, the main tasks considered in this area can be classified based on the following parameters \cite{DBLP:conf/semweb/SazonauS17,Boytcheva2007OverviewOI}.
 %many other settings have been proposed.


% Probably the most widely-studied rule learning setting, which lies in the heart of inductive logic programming concerns the extraction of logic rules from a set of positive and negative examples and a logical background theory~\cite{foil,golem,quickfoil}.

% % \subsubsection{Learning from Positive and Negative Examples}
% % \label{subsec:ilp}
% % The most prominent setting that has been extensively studied in the context of inductive logic programming concerns the extraction of a hypothesis in a certain language, given a set of positive and negative examples and a logical background theory in the form of a logic program, e.g.,
% To get an idea of %how exactly 
% this classical ILP task, consider the following example.



% Table \ref{tab:ilp} provides classifications of some traditional ILP systems that have been introduced in the literature to solve the above supervised learning task. In particular, we could classify them based on %some 
% the following characteristics \cite{Boytcheva2007OverviewOI,R8146692}:
% \begin{itemize}
% \item \emph{learning setting}, i.e., learning from examples or learning from interpretations
% \item \emph{support of negation}, i.e., the presence of negation in the induced hypothesis
% \item \emph{incrementalness} %demonstrates 
% reflects how the examples are processed by %to 
% the learning system. In the incremental ILP setting, examples are provided continuously one by one. In contrast, non-incremental ILP systems %(or empirical ILP systems) 
% require all examples to be available at once at the beginning of the learning process. % and they cannot be changed afterwards.
% \item \emph{interactiveness} indicates the %ability 
% possibility to ask questions to an external oracle during the learning process. The oracle is  typically represented by a human domain expert. 
% % the user, for the intended interpretation of an example or clause. 
% \item \emph{single vs multiple predicate learning} reflects the number of target predicates in question during the rule extraction. % popular ILP systems focus on learning a single target predicate, where positive/negative examples are of the same relation. Even though multiple predicate ILP learning algorithms are more powerful, they are harder and less efficient.
% \item \emph{noise-handling ability} %denotes 
% indicates whether an ILP system is capable of %to 
% dealing with real-life imperfect data, including noise. %Even though data incorrectness is allowed, it should not be significant.
% \end{itemize}

\input{tables/ilp_overview}

%The most relevant parameters for our tutorial concern the 


%Along with the type of the input data used (e.g., examples, interpretations), there are several other parameters that distinguish the rule mining approaches : 
\begin{itemize}
\item \emph{type of the data source}, e.g., positive/negative examples, interpretations, text
\item \emph{quality of the data source}, e.g., noisy or clean
\item \emph{the way the data is given as input}, e.g., all data at once or incrementally
\item \emph{type of the output knowledge}, e.g., Horn/nonmonotonic rules over single/multiple predicates, description logic class descriptions, class inclusions, etc.
% \item \emph{method used}, e.g., natural language processing, machine learning, association rule mining, theory revision, oracle-based exact learning techniques, etc.
\item \emph{data (in)completeness assumption}, e.g., OWA, CWA, partial completeness assumption, etc.
\item \emph{availability and type of background knowledge}, e.g., DL ontology, set of datalog rules.
\item \emph{availability of an oracle}, e.g., involvement of a human expert in the loop
\end{itemize}

In Table~\ref{tab:ilp} we provide an overview of the most relevant for us existing inductive rule mining systems and their properties. 
While the majority of approaches within inductive logic programming (see, e.g., \cite{DBLP:journals/cacm/GulwaniHKMSZ15,DBLP:journals/ml/MuggletonRPBFIS12} for overview) focus on the extraction of Horn logic programs from the data, learning programs with negation has also been tackled in several works 
~\cite{DBLP:conf/ijcai/InoueK97,DBLP:journals/tocl/Sakama05,XHAIL,CorapiRL10,ILASP_system}. 
% Now, we provide an overview of the most relevant techniques from nonmonotonic rule learning that mainly differ with respect to the data that they take as an input.
% We classify the techniques into three major groups: learning from positive and negative examples, learning from entailmenmt and learning from full or partial interpretations (or answer sets).

% In~\cite{DBLP:journals/tocl/Sakama05} 
% one of the earlierst methods for learning nonmonotobic logic programs from answer sets has been proposed. 
% More specifically, given a single answer set, the authors of \cite{DBLP:journals/tocl/Sakama05} induce a program that has this answer set as a stable model. In~\cite{Sakama2009}, the approach has been extended to learn from multiple answer sets. 
% This approach accepts only one positive example, i.e.,  a conjunction of atoms, while totally dismissing the negative ones. ILASP ~\cite{ILASP_system}, induces the hypothesis from multiple positive examples using brave induction, while it ensures that the negative examples are cautiously entailed (i.e. negative examples are excluded from all answer sets). The algorithm exhaustively searches the space of possible clauses to find one that is consistent with all examples and background knowledge. To make this search feasible, it restricts the learning only to the target predicate(s). 


% DROPS~\cite{CorapiRL10} and its successor ASPAL~\cite{ASPAL} map the ILP problem into an abductive learning task.
% XHAIL~\cite{XHAIL} uses a hybrid algorithm combining abduction, deduction and induction steps to generate the hypothesis. The system takes a background theory, a set of examples (both positive and negative), and user-defined predicate declarations to constrain the search space as input and returns as an output a set of hypotheses that entail the examples with respect to the background theory. To that end, XHAIL still suffers from the same infeasible search space problem facing ILASP~\cite{Sakama2009}. An enhanced version of XHAIL that resolves scalability issues has been introduced in~\cite{XHAIL_extended}.
