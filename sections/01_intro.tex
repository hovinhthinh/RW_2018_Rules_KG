\section{Introduction}
%(2 pages)}
\label{sec:intro}

\leanparagraph{Motivation}
Recent advances in information extraction have led to
huge graph-structured knowledge bases (KBs) also known as knowledge graphs (KGs) such as NELL \cite{nell}, DBpedia \cite{dbpedia}, YAGO \cite{yago} and Wikidata \cite{wikidata}. These KGs contain millions or billions of relational facts in the form of subject-predicate-object (SPO) triples, e.g., $\tuple{\mi{clara\;marriedTo\;dave}}$ or $\tuple{\mi{dave\;isA\;researcher}}$. Such triples can be straightforwardly represented by means of positive unary and binary first-order logic facts, e.g. $\mi{marriedTo(clara,dave)}$ and $\mi{researcher(dave)}$.

An important task over KGs is rule learning, which is relevant for a variety of applications ranging from knowledge graph curation (completion, error detection) \cite{DBLP:journals/semweb/Paulheim17} to data mining and semantic culturonomics. Rules over KGs are of the form $\mi{head \leftarrow body}$, where $\mi{head}$ is a binary atom and $\mi{body}$ is a conjunction of, possibly negated, binary and unary atoms. 

Traditionally, rule induction has been studied in the context of relational data mining in databases (see e.g., \cite{DBLP:books/daglib/0021868} for overview), and has recently been adapted to KGs (e.g., \cite{amie,op,rdf2rules}). The methods from this area can be used to identify prominent patterns from KGs, such as \emph{``Married people live in the same
place''}, and cast them in the form of Horn rules, such as:
$\mi{r_1:\;}\mi{livesIn(Y,Z)}\leftarrow \mi{marriedTo(X,Y),livesIn(X,Z)}$. 

For the KG curation, this has two-fold benefits. First, since KGs operate under the Open World
Assumption (OWA) (i.e., absent facts are treated as unknown rather than false),
the rules can be used to derive additional facts such as missing living places. % For example, applying the rule
% $\mi{r_1}$ mined from the graph in Figure~\ref{rdf}, the missing living places of Dave and Lucy can be deduced based on the data about their spouses.
Second, rules can be used to eliminate erroneous facts in KGs. For example, assuming that $\mi{livesIn}$ is a functional relation, % Amsterdam as a 
a living place of a person could be questioned if it differs from the spouse's.

When rules are automatically learned, statistical measures like support, confidence and their variations are used to asssess the rules' quality. Most notably, the confidence of a rule is the fraction of facts predicted by the rule that are indeed in the KG. However, this is a meaningful measure for rule quality only when the KG is reasonably complete. For rules learned from incomplete KGs, confidence and other measures may be misleading, as they do not reflect the patterns in the missing facts. This might lead to the extraction of erroneous rules from incomplete and biased KGs. For example, a KG that knows a lot of information about families of popular scientists but lacks data in other domains, would yield a heavily biased rule $\mi{r_1':hasChild(X,Y)\leftarrow worksAt(X,Z), educated(Y,Z)}$, stating that workers of certain institutions often have children among the people educated there, as this is frequently the case for scientific families. 

To address this issue, several rule measures that are specifically tailored towards incomplete KGs have been proposed \cite{amie,DBLP:conf/www/ZupancD18} (see \cite{metrics-summary,Azevedo2007} for an overview of other measures). 
Along with KGs themselves, additional background knowledge could be used for better rule assessment. As proposed in \cite{carl} this includes meta data about the concrete numbers of facts of certain types that hold in the real world (e.g., \emph{``Einstein has 3 children''}) automatically extracted from Web resources using techniques like  \cite{paramita-acl-2017}. Other types of background knowledge comprise description logic theories, e.g., \cite{d2016ontology} or other more general hybrid theories, e.g., \cite{DBLP:journals/tplp/Lisi10,DBLP:journals/tplp/JozefowskaLL10}.

\input{figures/kg1}
%\begin{figure}[t]
%\begin{center}
%\begin{subfigure}[b]{0.75\textwidth}
%    \centering
%\includegraphics[width=0.7\textwidth]{figures/kg_extended}
%\caption{Rule mining for KG completion and KG cleaning}
%\label{rdf}
%\end{subfigure}
%\begin{subfigure}[b]{0.24\textwidth}
%\scriptsize
%\renewcommand*{\arraystretch}{0.95}
%\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
%\hline
%&  \rot{$\mi{bornInUS}$} &\rot{$\mi{livesInUS}$}&
%\rot{$\mi{stateless}$}&\rot{$\mi{immigrant}$}&\rot{$\mi{singer}$}&\rot{$\mi{poet}$}&\rot{$\mi{hasUSPass}$}\\ \hline
%$\mi{p1}$ & $\checkmark$ &$\checkmark$ &&&$\checkmark$&&$\checkmark$ \\ \hline
%$\mi{p2}$ & $\checkmark$ &$\checkmark$ &&&&&$\checkmark$ \\ \hline
%$\mi{p3}$ & $\checkmark$ &$\checkmark$ &&&$\checkmark$&$\checkmark$&$\checkmark$ \\ \hline
%$\mi{p4}$ & $\checkmark$ &$\checkmark$ &&&&&$\checkmark$ \\ \hline
%$\mi{p5}$ & $\checkmark$ &$\checkmark$ &$\checkmark$&&&& \\ \hline
%$\mi{p6}$ & $\checkmark$ & &$\checkmark$&&&& \\ \hline
%$\mi{p7}$ & $\checkmark$ & &$\checkmark$&&&& \\ \hline
%$\mi{p8}$ & $\checkmark$ & &$\checkmark$&$\checkmark$&&& \\ \hline
%$\mi{p9}$ & $\checkmark$ & &&$\checkmark$&&$\checkmark$& \\ \hline
%$\mi{p10}$ & $\checkmark$ & &&$\checkmark$&$\checkmark$&$\checkmark$& \\ \hline
%$\mi{p11}$ & $\checkmark$ & &&&$\checkmark$&$\checkmark$&$\checkmark$ \\ \hline
%\end{tabular}
%\smallskip
%\caption{US inhabitants KG}
%\label{tab:im}
%\end{subfigure}
%\caption{Examples of Knowledge Graphs}
%\end{center}
%\end{figure}

Even when meaningful, Horn rules, where all predicates in the rule body are positive such as $\mi{r_1}$ might not always be sufficiently expressive % .
% This is insufficient
to capture KG patterns accurately, as they  cannot handle exceptions, which often appear in practice. 
For instance, application of $\mi{r_1}$ mined from the KG in Figure~\ref{rdf} results in the facts $\mi{livesIn(alice,berlin)}$, $\mi{livesIn(dave,chicago)}$ and $\mi{livesIn(lucy,amsterdam)}$. Observe that the first two facts might be suspected to be wrong. Indeed, both $\mi{alice}$ and $\mi{dave}$ are researchers, and the rule $\mi{r_1}$ could be suspected to have researcher as a potential exception resulting in its more accurate version given as $\mi{r_2:\;}\mi{livesIn(Y,Z)}\leftarrow \mi{marriedTo(X,Y),livesIn(X,Z), not\;researcher(Y)}$.
% Thus making predictions using Horn rules might result in incorrect facts.
% For example, consider a more accurate version of $\mi{r_1}$ given as \\$\mi{r_2{:}livesIn(Y,Z){\leftarrow}
%   isMarriedTo(X,Y){,}livesIn(X,Z){,}{\naf\,} researcher(Y)}$, which \\states that \emph{``Married people live in the same place unless one is a
%   researcher''}. The additional knowledge that Alice is a researcher could be actually an explanation for her living in an unexpected place. If $\mi{r_2}$ often holds, then
% one can no longer complete the missing living place for Dave by assuming that he lives with his wife Clara. 
Exception handling has been faced in inductive logic programming (ILP) by learning nonmonotonic logic programs, i.e., programs with negations from databases (e.g., \cite{DBLP:conf/ijcai/InoueK97,DBLP:journals/tocl/Sakama05,R08}), and recently also studied in the context of KGs \cite{gad2016,rumis}.


The aim of this article is to survey the current research on rule learning from knowledge graphs. We present and discuss different techniques with the roots in inductive logic programming and relational data mining as well as their interalation and applications for KGs. 

\leanparagraph{Tutorial Overview}
In Section~\ref{sec:kgs} we start by briefly introducing knowledge graphs. We then provide neccessary preliminaries on rule-based reasoning over KGs in Section~\ref{sec:reasoning}. Section~\ref{sec:rules_kg_completion} presents an overview of rule learning tasks that can be performed on KGs and describes recent research progress in the context of Horn rule induction. We present techniques for nonmonotonic rule extraction in Section~\ref{sec:nmrulelearn}. Finally, in Section~\ref{sec:disc} we conclude the article with an outlook discussion, where we identify a number of promising directions for future work.


