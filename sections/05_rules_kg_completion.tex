\section{Combining Rule Learning and Reasoning For Knowledge Completion (5 pages)}
\label{sec:rules_kg_completion}
%!TEX root = ../main.tex
Traditional rules learning systems in the context of Inductive Logic Programming (ILP) \cite{probfoil,DBLP:conf/ijcai/RaedtDTBV15,DBLP:conf/clima/CorapiSIR11} are either memory-expensive or requires the availability of negative examples, which is hard to get due to the large KG size. In contrast, other unsupervised relational 
association rule learning systems such as \cite{DBLP:conf/esf/GoethalsB02,amie} induce logical rules from the KG by mining frequent patterns and casting them into implications. Most of the  existing methods tailored towards Open World Assumption (OWA) rely only on the available graph and exploit sophisticated rule measures \cite{amie,Chen:2016:OP:2882903.2882954, rumis}.
In this section, we briefly summarize some of these state-of-the-art rule mining systems, which combine rule learning and reasoning for knowledge graph completion under OWA. We classify them into two main categories: Horn rules learning and Non-monotonic rules learning systems.
\subsection{Horn rule learning}
Horn rule learning systems focus on mining rules consisting of only positive atoms. Some examples of such mining systems are AMIE \cite{}, OP, \cite{} and RDF2Rules \cite{}.
\subsubsection{AMIE}
AMIE is a state-of-the-art positive rule mining systems in the context of OWA. Apart from the algorithm being used to construct the rules, AMIE also introduce a novel rule measure namely PCA confidence, which is based on the Partial Closed world Assumption (PCA), stating that data of the knowledge graph is added in batch.
\thi{PCA confidence formular here}.
PCA confidence is then exploited by AMIE to mine positive rules using the its introduced algorithm. In AMIE, rule is treated as a sequence of atoms, where the first atom is the head of the rule, and other atoms are the body of the rule. Mining operators are introduced to extend the sequences of atoms to explore the rules' search space as follows:
\begin{enumerate}
\item \texttt{Add Dangling Atom}.\\
  This operator adds a positive atom to the rule. One of the two arguments of the atom should be a fresh new variable. The other argument is a shared variable, which appears in some other atoms of the rule.
\item \texttt{Add Instantiated Atom}.\\
  This operator adds a positive atom to the rule, in which one argument of the atom is constant (entity) and the other argument is a shared variable with the rule.
\item \texttt{Add Closing Atom}.\\
  This operator adds a positive atom to the rule, in which both arguments of the atom are shared variables with the rule.
\end{enumerate}

\begin{algorithm}[H]
\DontPrintSemicolon
$queue\leftarrow \langle[]\rangle$\\
Execute in parallel:\\
\While{$\neg$queue.isEmpty()}{    
    \textit{rule $\leftarrow$ queue.dequeue()}\\
    \tcc{Computes rule statistics and output if necessary.}
    \If{rule.isClosed()}{
        \textit{stats $\leftarrow$ computeStatistics(rule)}\\
        \eIf{stats.isEligibleForOutput()}{
            output($rule$)
        }{
            continue while loop
        }
    }
    \tcc{Applies operators to explore more new rules.}
    \ForEach{operator o}{
        \ForEach{newRule $\in$ o(rule)}{
            \If{newRule.hasGoodFormat()}{
                \tcc{Check whether there exists some version of the rule in queue.}
                \If{newRule $\notin$ queue}{ 
                    \textit{queue.enqueue(newRule)}
                }
            }
        }
    }    
}
\caption{AMIE's mining algorithm.}
\label{algor:amie}
\end{algorithm}



\subsubsection{AMIE}
\subsection{Non-monotonic rule learning}
\begin{itemize}
\item Propositionalization (as trial) ISWC2016
\item ILP2016

\end{itemize}


\leanparagraph{CARL}