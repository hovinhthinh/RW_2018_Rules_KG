\section{ Rule Learning for Knowledge Graph Completion}
\label{sec:rules_kg_completion}
In this section we first describe the possible learning tasks that could be performed over KGs and then dwell into the details of the relational association rule learning from incomplete KGs. 
\subsection{Rule Learning Tasks}
\label{sec:rules_learning_tasks}
Rule learning is an important sub-field of machine learning research area, which focuses on symbolic methods for intelligent data analysis. Hereby symbolic, we mean methods that employ some kind of description language in which the learned knowledge is expressed. One of the main attractions of rule induction is that the rules are much more transparent and easier to interpret than, e.g., a regression model or trained neural network.

First-order learning approaches are also referred to as %\emph{relational data mining (RDM)}, \emph{relational learning
%(RL)} or
 \emph{inductive logic programming (ILP)}, since the patterns they discover are expressed in
relational formalisms of first-order logic (see \cite{DBLP:books/daglib/0021868} for overview).

Rule learning approaches can be characterized along several dimensions \cite{DBLP:conf/semweb/SazonauS17}: 
\begin{itemize}
\item \emph{type of the data source}, e.g., KG, database, text, oracle (a domain expert), true and false facts over a certain target predicate (often referred to as positive and negative examples respectively)
\item \emph{type of the output knowledge}, e.g., Horn rules, description logic class descriptions, class inclusions of various expressivity, etc.
\item \emph{method used}, e.g., natural language processing, machine learning, association rule mining, theory revision, oracle-based exact learning techniques, etc.
\item \emph{data (in)completeness assumption}, e.g., OWA, CWA, partial completeness assumption, etc.
\item \emph{availability and type of background knowledge}, e.g., DL ontology, set of datalog rules.
\end{itemize}

The most prominent setting that has been extensively studied in the context of inductive logic programming concerns the extraction of a hypothesis in a certain language, given a set of positive and negative examples and a logical background theory in the form of a logic program, e.g., \cite{foil,golem,quickfoil}. To get an idea of this classical ILP task, consider the following example.

\begin{example}
Suppose that you possess information about some of the relationships between people in your family and their genders.
However, you do not know what the relationship $\mi{fatherOf}$ actually means. 
You might have the following beliefs, i.e., background knowledge.
\smallskip

{\leftline{$B = \left\{
            \renewcommand{\arraystretch}{1.1}
            \begin{array}{@{\,}l@{~~}l@{}}
              \mbox{(1) } \mi{parent (john, mary)};
               \mbox{(2) }\mi{male(john)};
              \mbox{(3) }\mi{parent (david, steve)};\\
              \mbox{(4) }\mi{ male(david)};
              \mbox{(5) }\mi{parent (kathy, ellen)};
              \mbox{(6) }\mi{ female (kathy)};
            \end{array}%
            \!\right\}$}}
\smallskip

Moreover, you are given the following positive and negative examples.
\smallskip

\noindent $\mi{E^+=\{fatherOf(john, mary), fatherOf(david, steve)\}}$\\
$\mi{E^-=\{fatherOf(kathy, ellen), fatherOf(john, steve)\}}$\\



One of the possible hypothesis that can be induced from the above knowledge reflecting the meaning of the $\mi{fatherOf}$ relation is given as follows:\\
$\mi{Hyp: fatherOf(X, Y)\leftarrow parentOf(X,Y), male(X)}$. This hypothesis is consistent with the background theory $B$, and together with B it entails all of the positive example, none of the negative ones, i.e., $\mi{Hyp \cup B \models B^+}$ and $\mi{H \cup B \not \models E^-}$. The classical ILP task concerns the extraction of such hypothesis. \qed
\end{example}

While a significant amount of research has been devoted to the problem of inducing logical theories from a set of positive and negative examples and the background knowledge (as exemplified above), there are several important obstacles that prevent one from employing the off-the-shelf ILP algorithms for solving the rule-based KG completion problem from Definition~\ref{def:kgcomp}. 

First, the target predicates ($\mi{fatherOf}$ from the above example) can
not be easily identified, since we do not know which parts of the considered KG need to
 be completed. A standard way of addressing this issue would be just to learn rules for all
 the different predicate names occurring in the KG. Unfortunately, this is unfeasible
 given the huge size of KGs. Second, the negative examples are not available,
 and they can not be easily obtained from, e.g., domain experts due to - once again
 - the huge size of KGs. % A natural solution to cope with this issue is to learn rules
% from positive examples only \cite{DBLP:conf/ilp/Muggleton96}. 

To overcome the above obstacles, it turns out to be appropriate to treat
the KG completion problem as an unsupervised relational learning task \cite{amie}.
In fact, association rules in their original propositional form have been earlier applied to deduce missing types for entities in \cite{typeinduction} and to
infer the KG schema in \cite{statisticalschema}. These works directly employ the famous Apriori algorithm for mining frequent itemsets from transaction databases.
%Third, the definition of a language bias turns out to be
% cumbersome since the schema of the KG is usually not available.

In the rest of this section, we describe approaches that rely on \emph{relational association rule learning} techniques for extraction of \emph{Horn rules} from incomplete KGs. 
Association rule mining concerns the discovery of frequent patterns in a data set and the subsequent transformation of these patterns into rules
(see, e.g., \cite{DBLP:conf/ilp/DehaspeR97} as the seminal work in this direction). % In the following we adapt basic notions in relational association rule mining to our case of interest.

The standard relational rule learning techniques usually proceed in two 
steps: rule construction and rule evaluation. While the main concern of the rule construction phase is how to mine frequent patterns from the KG, 
%and transform them into the form of rules, 
rule evaluation phase deals with measuring rule quality %from 
using some scoring function computed based on the rule statistics over the given KG. These statistics are used not only for ranking the outputting rules, but also for pruning inappropriate rule candidates. Below, we summarize some general techniques that have been introduced to tackle the mentioned rule learning steps.

\subsection{Rule Construction}
% Traditional rules learning systems in the context of Inductive Logic Programming (ILP) \cite{probfoil,DBLP:conf/ijcai/RaedtDTBV15,DBLP:conf/clima/CorapiSIR11} are either memory-expensive or requires the availability of negative examples, which is hard to get due to the large KG size. In contrast, other unsupervised relational 
% association rule learning systems deduce logical rules from the KG by mining frequent patterns and casting them into implications. Most of the  existing methods tailored towards Open World Assumption (OWA) rely only on the available graph and exploit sophisticated rule measures \cite{amie,op,rumis}.

We now briefly summarize some of the state-of-the-art methods %rule mining systems, 
for rule construction, most of which % which combine rule learning and reasoning for knowledge graph completion under OWA.
%Most of these systems only 
extract so-called \emph{closed} rules,
i.e., rules, in which every variable appears at least twice. Restriction to closed rules % is imposed to 
ensures the actual prediction  of a fact by a rule, but not just its existence~\cite{amie}.

\begin{example}
%\ds{TODO: insert an example of a closed and a non-closed rule, say a few words, why closed rules make sense}
An example of non-closed rule learned from the KG in Figure~\ref{rdf} is % , a non-closed rule learned from this graph can be:
\[\exists Z \mi{livesIn(Y,Z)} \leftarrow \mi{isMarriedTo(X,Y)} \]  which states that married people 
%then he/she should 
live in some place. Unlike $r_1$, this rule cannot infer the exact living place of a person of interest is thus less interesting. \qed% for the KG completion. %location 
%which specifies his living location based on the spouse.
\end{example}

The most prominent examples of systems that are specifically tailored towards inducing rules from KGs are AMIE \cite{amie}, %OP, \cite{op} 
and RDF2Rules \cite{rdf2rules}.
\subsubsection{AMIE.}
AMIE \cite{amie} is a state-of-the-art Horn rule mining system.
Apart from a KG, it expects from the user a support threshold and maximum
rule length. The algorithm maintains a queue of rules, which initially stores a single rule with an empty body for every KG relation. 
Rules are removed from the queue and refined by adding literals to the body according to a language bias that specifies allowed rule forms (e.g., based on the user-provided rule length). The system then estimates the support of the rule, and if it exceeds the given threshold, the rule is output to the user and also added to the queue for
possible further processing.
%Apart from the algorithm being used to construct rules, AMIE also introduces a novel rule measure namely PCA confidence, which is based on the Partial Closed world Assumption (PCA), stating that data of the knowledge graph is added in batch \cite{amie}. In particular, with every $p(s,o) \in \cG$, the assumption states that:
%\[\forall o' : p(s,o') \in \cG^i \Rightarrow p(s,o') \in \cG\]
%Intuitively, if the KG contains some $p$-object of $s$, then it also contains all possible $p$-objects of $s$. Formally, PCA confidence is defined as follows:\thi{pca conf here}
%\[conf_{pca}=.\]
%This measure is then exploited by AMIE to mine positive rules using its introduced algorithm. 
Refinement of a rule relies on the following set of mining operators used to extend the sequences of atoms in the rule body:
\begin{itemize}
\item \textit{add dangling atom}: add a new positive atom with one fresh variable, i.e., variable not appearing elsewhere in the rule;
\item \textit{add instantiated atom}: add a positive atom with one argument being a constant and the other one being a shared variable, i.e., variable already present in another rule atom;
\item \textit{add closing atom}:  add a positive atom with both of its arguments being shared variables.

\end{itemize}
%\begin{algorithm}[t]
%\DontPrintSemicolon
%$queue\leftarrow \langle[]\rangle$\\
%Execute in parallel:\\
%\While{$\neg$queue.isEmpty()}{    
%    \textit{rule $\leftarrow$ queue.dequeue()}\\
%%    \tcc{Computes rule statistics and output if necessary.}
%    \If{rule.isClosed()}{
%        \eIf{rule is not pruned for outputting}{
%            output($rule$)
%        }{
%            continue while loop
%        }
%    }
%%    \tcc{Applies operators to explore more new rules.}
%    \ForEach{operator o}{
%        \ForEach{newRule $\in$ o(rule)}{
%%            \If{newRule.hasGoodFormat()}{
%%                \tcc{Check whether there exists some version of the rule in queue.}
%                \If{newRule $\notin$ queue}{ 
%                    \textit{queue.enqueue(newRule)}
%%               }
%            }
%        }
%    }    
%}
%\caption{AMIE's mining algorithm.}
%\label{algor:amie}
%\end{algorithm}
% These mining operators are then applied to extract rules from KGs. The algorithm maintains a queue consisting of intermediate rules to be processed. At the beginning, the queue contains only an empty rule. At each step, one rule is taken from the head of the queue, then being checked for outputting. Then, mining operators are applied to explore new more rules.
% Checking for outputting is the process of collecting rule statistics (e.g. \textit{support}, \textit{confidence}), and then checking whether these metrics pass some defined threshold. Apart from that, the expansion of rules must meet the other two requirements: the increasing of rule quality, and the language bias. In particular, firstly, adding an atom into the rule must increase its quality (e.g. \textit{confidence}). Secondly, the rules being outputted must be \textit{closed} and number of atoms of the rule does not exceed some threshold.

% To compute the rule's statistics, we must find all instantiations of variables in a rule in the given KG. Several options have been proposed depending on how the KGs are stored: either by using SQL, SPARQL or using in-memory database techniques \cite{amie}.
The implementation of AMIE employs a variety of techniques from the database community, which allow it to achieve high scalability.

\subsubsection{RDF2Rules.}
While AMIE mines one rule at a time, RDF2Rules \cite{rdf2rules} parallelizes this process by extracting \emph{frequent predicate cycles} (FPCs) of %some 
a certain length $k$, which have the following form:
\[\theta = (X_1, p_1^{d_1}, X_2, p_2^{d_2},\dotsc, X_k, p_k^{d_k}, X_1)\]
where, $X_i$s are variables to appear in the rules, $p_i$s are predicates between these variables, and $d_i$s $\in \{0,1\}$ reflect the direction of the edges in the KG labeled by the respective predicates. To extract FPCs, the algorithm first mines the \emph{frequent predicate paths} (FPPs) of the form:
\[\theta = (X_1, p_1^{d_1}, X_2, p_2^{d_2}, ...,X_k, p_k^{d_k}, X_{k+1})\]
of length $k$, which could be mined recursively based on FPPs of length $k-1$. 
FPCs are then created from FPPs by merging the last variable $X_{k+1}$ with the first one $X_1$.

After mining FPCs, rules are extracted from the FPCs by choosing one %a 
predicate to be in    %as 
the head, and collecting the rest into the rule's  body. 
%of the rule. 
Formally, the  $j$-th rule is generated from the FPC as follows:
\[r_j: p_j^{d_j}(X_j,X_{j+1}) \leftarrow \underset{i \in [1,k], i \ne j}{\bigwedge} p_i^{d_i}(X_i,X_{i+1}) \]

RDF2Rules is capable of accounting for unary predicates (i.e., types of entities), which are neglected in AMIE for scalability reasons. % The above generated rules are without \textit{type} information.
The unary predicates are added to the constructed rule at the last stage after analyzing the 
frequent types for FPCs corresponding to a given rule.
% Nevertheless, comparing to AMIE, even though RDF2Rules can mine rules faster, the forms of rule it can learn are restricted, s
While RDF2Rules performs the rule extraction faster then AMIE due to an effective pruning strategy
used in the process of mining FPCs, the supported rule patterns are also more restrictive. 

\subsection{Rule Evaluation}
Most of state-of-the-art KG-based positive rule mining systems %are different 
differ from each other with respect to the employed %at the rule %metric 
%that they introduce to quantify 
rule ranking function. % quality and how to exploit it in learning rules. 
%Basically, we can plug different rule metrics into these mining systems to work under different situations.
The ranking metrics from datamining such as support and confidence (see, e.g., \cite{metrics-summary} for overview of others) presented in Section~\ref{sec:reasoning} have been designed for datasets that operate primarily under the CWA, and they can be counterintuitive for the KGs, in which facts are largely missing. 

\begin{example}
For instance, consider a KG $\cG'$ in Figure~\ref{fig:fam_grad} \cite{carl}, which presents information about scientific families.
The heavily biased rule from Section~\ref{sec:intro}: $\mi{r_1':\;hasChild(X,Y)\leftarrow worksAt(X,Z), educated(Y,Z)}$ can be mined from it along with a good one $\mi{r_2':\,hasSibling(X,Z)\leftarrow hasFather(X,Y),hasChild(Y,Z)}$, stating that people with the same father are likely siblings. The standard rule measures such as confidence reflect a counterintuitive rule preference. Indeed, we have $\mi{conf(\mi{r_1'})}=\frac{2}{8}$, while
 %we have that 
$\mi{conf(\mi{r_2'})}=\frac{1}{6}$. \qed
\end{example}

 % For instance, standard confidence $conf$ works under the Closed World Assumption.
% Apart from that, there also exist other measures introduced to quantify the quality of rules (see
%). 
 \input{figures/kg2}
% Given $r:\mi{H\leftarrow B, \naf\ E}$, with $H=\mi{h(X,Y)}$ and $B,E$ involving variables from $\vec{Z}\supseteq X,Y$, and also consider the example rules $r_1$, $r_2$, KG $\cG_1$ in Figure \ref{rdf}, we have:
\subsubsection{PCA Confidence.} Proposed by AMIE \cite{amie}, this measure considers KGs under the Partial Completeness Assumption (PCA), saying that data of the knowledge graph is added in batch \cite{amie}. In particular, with every $p(s,o) \in \cG$, the assumption states that:
\[\forall o' : p(s,o') \in \cG^i \implies p(s,o') \in \cG\]
Intuitively, if the KG contains some $p$-object of $s$, then it also contains all possible $p$-objects of $s$. Formally, \textit{PCA confidence} is defined as follows:
\[
\mi{conf_{pca}}(r, \cG) := \frac{\textit{r-supp}(r, \cG)}{\#(X,Y): \exists \vec{Z}: B \in \cG, E \notin \cG  \wedge \exists Y': h(X,Y')\in \cG}
\]
\begin{example}
We have $conf_{pca}(r_1,\cG_1) = \frac{3}{4}$, since we do not know any place where $lucy$ and $dave$ live. Similarly, $conf_{pca}(r_2),\cG_1) = \frac{3}{3}$.\qed
\end{example}
\subsubsection{Conviction.} \textit{Conviction} is shown to guarantee the high predictive power \cite{Azevedo2007} by measuring the intensity of rule's implication \cite{metrics-summary}, which is given by:
\begin{align*}
\textit{conv}(r,\cG) & := \frac{1 - \textit{rel-supp}(H, \cG)}{1-\textit{conf}(r,\cG)}
\end{align*}
where $\textit{rel-supp}(H, \cG)$ is the relative support of the head, measured by:
\begin{align*}
\textit{rel-supp}(H, \cG) = \dfrac{\#(X,Y):h(X,Y)\in \cG}{(\#X:\exists Y:h(X,Y)\in \cG)\times(\#Y:\exists X:h(X,Y)\in \cG)}
\end{align*}
\begin{example}
We have $\textit{rel-supp}(livesIn, \cG_1) = \frac{10}{10 \times 4} = \frac{1}{4}$, so $conv(r_1,\cG_1) = \frac{1-\frac{1}{4}}{1-\frac{3}{6}} = \frac{3}{2}$ and $conv(r_2,\cG_1) = \frac{1-\frac{1}{4}}{1-\frac{3}{4}} = 3$.\qed
\end{example}
\subsubsection{Soft Confidence.} Introduced by RDF2Rules \cite{rdf2rules}, \textit{soft confidence} is also tailored to work under Open World Assumption, measured by:
\[conf_{st}(r, \cG) = \frac{\textit{r-supp}(r, \cG)}{\textit{b-supp}(r,\cG) - \sum_{e \in U_r}P(e,p,\cG)} \]
where $U_r$ is the set of entities that previously have no relations of $p$, but have new predicted relations of $p$ by the rule, and $P(e,p,\cG)$ is the probability of entity $e$ having relation $p$ in $\cG$, approximated  using entity \textit{type} information \cite{rdf2rules}:
\[P(e,p,\cG)  = max_{t \in T_{e,\cG}}\frac{|Inst_p(t, \cG)|}{|Inst(t, \cG)|}{}\]
Here, $T_{e,\cG}$ contains all $type$ of entity $e$, $Inst(t, \cG)$ contains all entities of type $t$, and $Inst_p(t, \cG)$ is similar to $Inst(t, \cG)$, but restricts to only entities that have relation $p$.
Intuitively, soft confidence is designed to avoid the underfitting of standard confidence and overfitting of PCA confidence by also taking into account the probability of entities having the head predicate $P(e,p, \cG)$ in the unknown part of the rule.
\begin{example}
Consider KG $\cG_1$, we have $U_{r_1} = \{lucy, dave\}$, $U_{r_2} = \{lucy\}$. Moreover, $P(dave,livesIn,\cG_1) = \frac{1}{2}$ since $dave$ has only 1 type $researcher$, in which there are totally 2 researchers ($dave$, $alice$) but only $alice$'s living place is known to $\cG_1$ ($amsterdam$). In contrast, $P(lucy,livesIn,\cG_1) = 0$ because $lucy$ has no $type$ information.
Based on these numbers, we have $conv(r_1,\cG_1) = \frac{3}{6-\frac{1}{2}} = \frac{6}{11}$ and $conv(r_2,\cG_1) = \frac{3}{4-0} = \frac{3}{4}$.
\qed
\end{example}
\subsubsection{Completeness-aware Rule Measures.}  
In the solutions for the rule-based KG completion problem discussed so far, no external meta-information from outside of the KG about potential existence of certain types of facts was exploited. However, this knowledge is obviously useful, and furthermore, it is even available on the Web
in the form of Cardinality Statements, e. g., Brad has three children or Mary is a citizen of two countries. If a given KG mentions just a single Bradâ€™s child, we could be aiming at extracting rules that predict the missing
one. Since such existential information is beneficial not only for guided rule learning but also for increasing the scope of KGs and estimating their recall.

Thus, recent work CARL \cite{carl} focused on the improvements of rule scoring functions by making use of these extra (in-)completeness meta-data.

Overall, for a given fact $\tuple{john, hasChild, mary}$, CARL takes into account the following two numerical statements: the number of (1) children of $john$ and (2) incoming edges to $mary$, which in practice can be obtained using web extraction techniques \cite{cardinality-extraction-iswc-2016}. Since template (2) could be rewritten as the instances of the template (1) through the inverse relations, these meta-data statements could be formalized as follows:
\[\mi{num}(p,s, \cG^i) = \# o : p(s,o) \in \cG^i\]
indicating the total number of objects $o$ for a given subject $s$ and predicate $p$. Based on this, the number of missing objects $o$ in the available graph $\cG$ can be retrieved:
\[\mi{miss}(p,s,\cG) = \mi{num(p,s,\cG^i)} - \#o : p(s,o) \in \cG\]
Given a KG and its related cardinality statements of the above form, CARL defines two indicators for each given rule, reflecting the number of new 
predictions made by $\mi{r}$ in incomplete ($\mi{npi(r)}$) and, respectively, complete ($\mi{npc(r)}$) KG parts:
\begin{align*}
\mi{npi}(r, \cG) = \sum_X min(\#Y: h(X,Y)\in \cG_r\backslash \cG, \mi{miss}(h,X,\cG))
\end{align*}
\vspace{-\topsep}
\vspace{-\topsep}
\begin{align*}
\mi{npc}(r, \cG) = \sum_X max(\#Y: h(X,Y)\in\cG_r\backslash \cG - \mi{miss}(h,X,\cG), 0)
\end{align*}
Using these indicators, a class of completeness-aware rules measures have been proposed by CARL as follows:
%\begin{itemize}
% \input{figures/kg2}
%\item 

\noindent \textbf{Completeness Confidence.} First, incompleteness information is used to determine whether to consider an instance in the unknown part of the rule as a counterexample or not. Formally, the \emph{completeness confidence} is defined as follows:
\begin{align*}
\mi{conf_{comp}}(r,\cG) := \frac{\textit{r-supp}(r,\cG)}{\textit{b-supp}(r,\cG) - \mi{npi}(r,\cG)}
\end{align*}
\begin{example}
Consider the KG $\cG'$ in Figure \ref{fig:fam_grad}
and the following cardinality statements for it:\\
$\mi{num(hC,john,\cG'^i)}\!=\!\mi{num(hC,mary,\cG'^i)}\!=3$; $\mi{num(hC,alice,\cG'^i)}\!=\!1$; \\
$\mi{num(hC,carol,\cG'^i)}\!=\!\mi{num(hC,dave,\cG'^i)}\!=\!0$;\\
$\mi{num(hS,alice,\cG'^i)}\!=\!\mi{num(hS,carol,\cG'^i)}\!=\!\mi{num(hS,dave,\cG'^i)}\!=\!2$;\\ 
$\mi{num(hS,bob,\cG'^i)}\!=\!3$;\\
where $hC$, $hS$ stand for $hasChild$ and $hasSibling$, correspondingly. We have:\\
$\mi{miss(hC,mary,\cG')}\!=\!\mi{miss(hC,john,\cG')}\!=\!\mi{miss(hC,alice,\cG')}\!=\!1$;\\ 
$\mi{miss(hC,carol,\cG')}\!=\!\mi{miss(hC,dave,\cG')}\!=\!0$;\\
$\mi{miss(hS,bob,\cG')}\!=\mi{miss(hS,carol,\cG')}\!=\!2$;\\
$\mi{miss(hS,alice,\cG')}\!=\!\mi{miss(hS,dave,\cG')}\!=\!1$;\\
%Also consider the following two extracted rules: 
For the rules $r_1'$ and $r_2'$ introduced above we have
% \vspace{-\topsep}
% \begin{align*}
% -\ r_3 &: hasChild(X,Y) \leftarrow worksAt(X,Z), educatedAt(Y,Z)\\
% -\ r_4 &: hasSibling(X,Z) \leftarrow hasFather(X,Y), hasChild(Y,Z)
% \end{align*}
 $\mi{conf_{comp}(r_1', \cG')}=\frac{2}{6}$ and $\mi{conf_{comp}(r_2', \cG')}=\frac{1}{2}$, which establishes the desired rule ranking.
\qed
\end{example}
%\item

\noindent \textbf{Completeness Precision and Recall.} In the spirit of information retrieval, the notions of \emph{completeness precision} and \emph{completeness recall} are defined to measure rule quality based on their predictions in complete and incomplete KG parts:
\begin{align*}
\mi{precision_{comp}}(r,\cG)=1-\frac{\mi{npc}(r,\cG)}{\textit{b-supp}(r,\cG)},\;\;\;
\mi{recall_{comp}}(r,\cG)=\frac{\mi{npi}(r,\cG)}{\sum_X \mathit{miss}(h,X,\cG)}
\end{align*}
Intuitively, rules having high precision are rules that predict few facts in complete parts, while rules having high recall are rules that predict many facts in incomplete ones. Rule scoring could also be based on any weighted combination of these two metrics.
%The \emph{recall measure} is similar to classical support measures, but now expresses how many facts on KG parts known to be incomplete, are generated by the rule (the more the better). The \emph{precision measure}, in turn, assesses how many of the generated facts are definitely wrong, namely those in complete parts (the more of these, the worse the rule). In fact, this is an upper bound on the precision, as the other facts cannot be evaluated.
\begin{example}
We have $\mi{npi(r_1', \cG')}\!=\!2$, $\mi{npc(r_1', \cG')}\!=\!4$, while $\mi{npi(r_2',\cG')}\!=\!4$, $\mi{npc(r_2,\cG')}\!=\!1$, resulting in $\mi{precision_{comp}(r_1,\cG')}\!=\!0.5$, $\mi{recall_{comp}(r_1',\cG')}\!\approx\!0.67$,and $\mi{precision_{comp}(r_2',\cG')}\!\approx\!0.83$, $\mi{recall_{comp}(r_2',\cG')}\!\approx\!0.67$.
\qed
\end{example}
%\item 

\noindent\textbf{Directional Metric.} If rule mining does make use of completeness information, and both do not exhibit any statistical bias, then intuitively the rule predictions and the (in)complete areas should be statistically independent. On the other hand, correlation between the two indicates that the rule-mining is \emph{(in)completeness-aware}. Hence, \emph{directional metric} is proposed following this intuition by measuring the proportion between predictions in complete and incomplete parts:
\begin{align*}
\mi{dm}(r,\cG) := \frac{\mi{npi}(r,\cG)-\mi{npc}(r,\cG)}{2\cdot(\mi{npi}(r,\cG)+\mi{npc}(r,\cG))}+0.5
\end{align*}
Since the real-world KGs are often highly incomplete, it might be reasonable to put more weight on predictions in complete parts. This can be done by multiplying predictions made in complete parts by a certain factor. This leads to the consideration of the weighted combination of a existing association rule measure $rm$, e.g., standard confidence or conviction, and 
the directional metric, using a weighting factor $\beta \in [0..1]$. Formally:
\begin{align*}
\mi{weighted\_dm}(r,\cG)=\beta \cdot \mi{rm}(r,\cG) + (1-\beta) \cdot \mi{dm}(r,\cG) 
\end{align*}
\begin{example}
We have $\mi{dm(r_1',\cG')}\approx 0.33$ and $\mi{dm(r_2',\cG')}=0.8$. With weighted directional metric using standard confidence ($rm = conf$), for $\beta=0.5$, we get $\mi{weighted\_dm(r_1',\cG')} \approx 0.29$ and $\mi{weighted\_dm(r_2',conf,\cG')} \approx 0.48$. \qed
\end{example}
%\end{itemize}

%\subsubsection{OP (Ontological Pathfinding).}
\subsubsection{Optimized Rule Evaluation}
% \thi{i think we should remove this section and just add citation}.\ds{shifted this part to rule evaluation}
% Learning rules from knowledge graph consists of two phases: constructing the rules and examining their quality based on the KG.
Most of state-of-the-art rule mining systems parallelize only the rule construction phase, while the quality of the rules are determined in a single thread. Huge size og KGs such as YAGO or Freebase %might 
%contain %hundreds million of entities and 
% billions of facts, thus  
%between them, Hence, 
prohibits their storage in %it is often impossible to store these KGs in 
a single machine. Therefore, % these rule mining systems either cannot scale to this size to
%the process of determine the rules' 
the rule quality estimation %, or they have to assign this task 
is usually delegated to some third-party database management system.
In practice this might not always be effective. % such as SQL, SPARQL \cite{amie}, which might not always be effective.

The focus of a recent % the novel 
 \emph{ontological pathfinding} (OP) \cite{op} algorithm is % not at how to find the candidate rules in the knowledge graph, but rather at
% how to 
the efficient examination of the rule's quality. % The rule construction step of OP algorithm relies on the relational pathfinding method . The only difference is that, instead of finding paths on the entity-relations graph, OP looks at the domain-range schema graph \cite{op}.
After candidate rules are constructed relying on a variation of \cite{DBLP:conf/aaai/RichardsM92}, their quality is determined via a sequences of parallelization and optimization methods including KG partitioning, joining and pruning strategies.

%\ds{Maybe we could insert other optimized evaluation methods here?} 



%%Recent works, e.g., \cite{cardinality-extraction-iswc-2016} focused on the task of extracting such cardinality information from text.We now discuss possible ways of making use of such information in rule scoring and ranking, which are core steps in association rule learning. A variety of measures for ranking rules have been proposed, with prominent ones being confidence, conviction and lift.  The existing (in-)completeness-aware rule measure in the KG context (the PCA confidence \cite{amie}) has two apparent shortcomings: First,  it only counts as counterexamples those %objects pairs $(x,y)$ for which at least one $h(x,y')$ %other facts 
%%with the head predicate $\mi{h}$ 
%%holds is in $\cG^a$ for some $\mi{y'}$ and a rule's head predicate $h$. This means it may incorrectly give high scores to rules predicting facts for very incomplete relations, e.g., \emph{place of baptism}. Second, it is not suited for data in non-functional relations that is not added in batches, such as awards, where the important ones are added instantly, while others much slower or even possibly never. 
%
%
%%Before dwelling into the details of our approach we discuss the formal representation of such meta-data. 
%
%%\leanparagraph{Cardinality Statements}
%%Overall, one can think of 6 different cardinality templates obtained by fixing subject, predicate or object in a triple and report the number of respective facts that hold in $\cG^i$. 
%%The lattice of possible basic (in)completeness templates on the fact level is presented in Fig.~\ref{fig:cs} 
%%on an example triple $\langle\mi{john\;hasChild\;mary}\rangle$. By fixing subject, predicate or object in a triple overall we obtain 6 different templates.
% %statements for these templates 
%% Ideally, we would be willing to possess and exploit numerical statements for all of these templates. For example,
%E.g., for $\mi{\tuple{john\;hasChild\;mary}}$ we %can construct the following cardinality assertions: 
%can count
%(1) children of $\mi{john}$ %has $\mi{n}$ children; 
%(2) edges from $\mi{john}$ to $\mi{mary}$; % there are $n$ edges; 
%(3) incoming edges to $\mi{mary}$; % has $n$ incoming $\mi{hasChild}$ edges; 
%(4) %there are $\mi{n}$ 
%facts with $\mi{john}$ as a subject; (5) %there are $n$ 
%facts over $\mi{hasChild}$ relation; (6) %there are $\mi{n}$ 
%facts with $\mi{mary}$ as an object. 
%
%In practice, numerical statements for templates (1) and (3) can be obtained using web extraction techniques \cite{cardinality-extraction-iswc-2016}, from functional properties of relations or from crowd-sourcing. For other templates things get trickier; one might be able to learn  
%them from the data or they could be defined by domain experts in topic-specific KGs. We leave this issue for future work, and focus here only on templates (1) and (3), which could be rewritten as the instances of the template (1) provided that inverse relations can be expressed in a KG. For instance, $\# s: \mi{hasChild}(s,\mi{john})=\# o: \mi{hasParent}(\mi{john},o)$ for the predicates $\mi{hasChild}$ and $\mi{hasParent}$, which are %in an 
%inverses of one another. % relation. 
%
%We represent the (in)completeness meta-data using cardinality statements by reporting (the numerical restriction on) the absolute number of facts over a certain relation in the ideal graph $\cG^i$. More specifically, we define the partial function $num$ that takes as input a predicate $\mi{p}$ and a constant $\mi{s}$ and outputs a natural number corresponding to the number of facts in $\cG^i$ over $\mi{p}$ with $\mi{s}$ as the first argument: 
%
%\begin{equation}\label{eq:num}
%\mi{num}(p,s) := \# o : p(s,o) \in \cG^i 
%\end{equation}
%
%Naturally, the number of missing facts for a given $p$ and $s$ can be obtained as
%
%\begin{equation}\label{eq:miss}
%\mi{miss}(p,s) := \mi{num(p,s)} - \#o : p(s,o) \in \cG^a %\setminus \cG^a
%\end{equation}
%
%\begin{example}
%\label{ex:cardinality}
%Consider the KG in Fig.~\ref{fig:fam_grad}.
%%and the rules $\mi{r1}$ and $\mi{r_2}$ from Example~\ref{ex:conf},
%%along with the following 
%%The following 
%and the following cardinality statements for it: %it might be available:
%\vspace{-\topsep}
%\begin{itemize}
%\setlength{\parskip}{0pt}
%\setlength{\itemsep}{0pt plus 1pt}
%\item $\mi{num(hasChild,john)}\!=\!\mi{num(hasChild,mary)}\!=3$; $\mi{num(hasChild,alice)}\!=\!1$;\\  $\mi{num(hasChild,carol)}\!=\!\mi{num(hasChild,dave)}\!=\!0$;
%\item $\mi{num(hasSibling,bob)}\!=\!3$;
%      $\mi{num(hasSibling,alice)}\!=\!\mi{num(hasSibling,carol)}\!=\!\mi{num(hasSibling,dave)}\!=\!2$.
%\end{itemize}
%\vspace{-\topsep}
%We then have:
%\vspace{-\topsep}
%\begin{itemize}
%\setlength{\parskip}{0pt}
%\setlength{\itemsep}{0pt plus 1pt}
%\item $\mi{miss(hasChild,mary)}\!=\!\mi{miss(hasChild,john)}\!=\!\mi{miss(hasChild,alice)}\!=\!1$;\\
%      $\mi{miss(hasChild,carol)}\!=\!\mi{miss(hasChild,dave)}\!=\!0$; 
%\item $\mi{miss(hasSibling,bob)}\!=\mi{miss(hasSibling,carol)}\!=\!2$;\\ 
%      $\mi{miss(hasSibling,alice)}\!=\!\mi{miss(hasSibling,dave)}\!=\!1$.\qed
%\end{itemize}
%\end{example}
%
%
%We are now ready to 
%define the \emph{completeness-aware rule scoring problem}.
%%\begin{problem}[Completeness-aware rule scoring] 
%Given a KG and a set of 
%%(in-)-complete\-ness
%cardinality statements, \emph{completeness-aware rule scoring} aims to score rules not only by their predictive power on the known KG, but also wrt.\ the number of wrongly predicted facts  
%in complete areas and the number of newly predicted 
%facts in known incomplete areas.
%%\end{problem}
%
%In the following we discuss and compare  
%three novel approaches for completeness-aware rule scoring. These are (i) the \emph{completeness confidence}, (ii) \emph{completeness precision} and \emph{recall}, 
%and (iii) \emph{directional metric}.
%Henceforth, all examples 
%consider the KG in Fig.~\ref{fig:fam_grad}, 
%rules from Ex.~\ref{ex:conf}, and cardinality statements  described in Ex.~\ref{ex:cardinality}.
%
%\leanparagraph{Completeness Confidence} In this work we propose to explicitly rely on incompleteness information in determining whether to consider an instance as a counterexample for a rule at hand or not.
%
%To do that, we first define two indicators for  a given rule $r: %\vec{H}
%\mi{h(X,Y)}\leftarrow \vec{B}$, %with $\vec{H}=h(X,Y)$, 
%reflecting the number of new 
%predictions made by $\mi{r}$ in incomplete ($\mi{npi(r)}$) and, respectively, complete ($\mi{npc(r)}$) KG parts:
%
%
%
%\begin{equation}
%\mi{npi}(r) := \sum_x min(\#y: h(x,y)\in \cG^a_r\backslash \cG^a, \mi{miss}(h,x))
%\end{equation}
%\vspace{-\topsep}
%\begin{equation}
%\mi{npc}(r) := \sum_x max(\#y: h(x,y)\in\cG^a_r\backslash \cG^a - \mi{miss}(h,x), 0)
%\end{equation}
%
%Note that summation is done exactly over those entities for which $\mi{miss}$ is defined.
%Exploiting these additional indicators 
%for %a given 
%$r:\,h(X,Y)\leftarrow \vec{B}$ we obtain the following \emph{completeness-aware confidence}:
%
%\begin{equation}\label{eq:comp_conf}
%\mi{conf_{comp}}(r) := \frac{\mi{supp}(r)}{\mi{supp}(\vec{B}) - \mi{npi}(r)}
%\end{equation}
%
%\begin{example}\label{ex:fam_grad}
%\label{ex:conf_comp}
%%Consider the KG in Fig.~\ref{fig:fam_grad}, rules $\mi{r1}$ and $\mi{r_2}$ from Example~\ref{ex:conf}, and cardinality statements mentioned in Example~\ref{ex:cardinality}.
%Obviously, the rule $\mi{r_2}$ %is
%should be preferred over $\mi{r_1}$. For our novel %This desired rule ranking is achieved by exploiting our novel 
%completeness confidence, we get %giving 
%$\mi{conf_{comp}(r_1)}=\frac{2}{6}$ %{5}$ 
%and $\mi{conf_{comp}(r_2)}=\frac{1}{2}$, resulting in the desired rule ordering,  which is not achieved by %is in contrast to 
%existing measures. %while the %previously introduced 
%The existing %ranking 
%metrics result in an incorrect rule ordering 
%%(see Ex.~\ref{ex:conf} and~\ref{ex:conf_pca}).
%\qed
%%%%%% OLD EXAMPLE %%%%%
%%\begin{example}\label{ex:fam_grad}
%%Consider the KG in Fig.~\ref{fig:fam_grad} along with the following cardinality statements:\\ $\mi{num(hasChild,mary)=num(hasChild,john)=3,num(hasChild,alice)=0}.$ 
%%Assume that the rules $\mi{r1}$ and $\mi{r_2}$ were mined from this KG.
%
%%\begin{itemize}
%%\item $\mi{r_1:\,hasChild(X,Y)\leftarrow worksAt(X,Z),graduateOf(Y,Z)}$
%%\item $\mi{r_2:\,hasChild(X,Y)\leftarrow hasParent(Y,X)}$;
%%\end{itemize}
%
%%Obviously, rule $\mi{r_1}$ is preferred over $\mi{r_2}$. This desired rule ranking in achieved by exploiting our novel completeness confidence, while the previously introduced ranking metrics result in an incorrect rule ordering.
%%\begin{itemize}
%%\item $\mi{conf(r_1)=2/3,conf(r_2)=2/5}$
%%\item $\mi{conf_{pca}(r_1)=1,conf_{pca}(r_2)=2/5}$
%%\item $\mi{conf_{comp}(r_1)=1/3,conf_{comp}(r_2)=1}$ \qed
%%\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%\end{example}
%
%%The proposed metric generalizes %over 
%Our completeness confidence generalizes both 
%the standard %confidence 
%and the PCA confidence:
%
%\begin{proposition}
%For every KG $\cG$ and rule $r$ it holds that 
%\begin{itemize}
%\item[(i)] under the Closed World Assumption (CWA) $\mi{conf_{comp}(r)=conf(r)}$;
%\item[(ii)] under the Partial Completeness Assumption (PCA) $\mi{conf_{comp}(r)=conf_{pca}(r)}$.
%\end{itemize}
%\end{proposition}
%
%\begin{proof}
%\textbf{(i)} Under the CWA, it holds that for all $ p\in \mathbf{R},\,s\in \cC: \mi{miss}(p,s) = 0$. Thus, for all rules $r$, we have that $\mi{npi}(r) = 0$, and hence, $\mi{conf_{comp}(r)}=\mi{conf(r)}$.
%\smallskip
%
%\noindent \textbf{(ii)} Under the PCA, it is assumed that for all $p\in \mathbf{R}$ and $s \in \cC$ it holds that 
%$\mi{miss}(p,s) = 0$ if $\exists o: p(s,o)\in \cG^a$. We extend the PCA by assuming that $miss(p,s)=+\infty$ for KG parts for which cardinality statements are unavailable, which is a reasonable assumption given the overall incompleteness of the available KG, i.e., 
%%and otherwise, 
%$\mi{miss}(p,s) = +\infty$. 
%%, since the number of missing facts is unrestricted. 
%Hence, for all $r$ we have
%$\mi{npi(r)=\sum_{x}predict(r,x)}$, where
%
%\begin{center}
%$predict(r,x)=
%\begin{cases}
%0, \text{ if } \exists y: h(x,y)\in \cG^a\\
%\#y: h(x,y) \in \cG^a_r\backslash \cG^a, \text{ if } \forall y': h(x,y')\not\in \cG^a\\
%\end{cases}$
%\end{center}
%From this we get
%
%\begin{center}
%$\mi{conf_{comp}(r)=\dfrac{supp(r)}{supp(\vec{B})-\sum_{x: \forall y': h(x,y')\not\in\cG^a}\#y: h(x,y)\in \cG^a_r\backslash \cG^a}}$
%\end{center}
%
%The denominator of the latter formula counts all rule body and subtracts from them those, for which the head $h(x,y)$ is predicted and $\forall y':h(x,y')\not \in \cG^a$. Hence, we end up counting only  body substitutions with $h(x,y')\in \cG^a$ for at least  one $y'$, i.e., $\mi{\#(x,y):\exists \vec{Z}:\vec{B}\wedge \exists y': h(x,y')\in \cG^a}$, from which the result follows. \qed
%
%\end{proof}
%
%
%
%In other words, if %we assume that 
%the graph is known to be fully complete, i.e., for all $p \in\cR,s\in\cC$ we have
%$\mi{miss}(p,s)=0$ , then $\mi{conf_{comp}}$ is the same as the standard confidence. Similarly, if  $\mi{miss}(p,s)= 0$ for such $p,s$ pairs that at least one 
%fact $p(s,\_)\in \cG^a$ exists and  $\mi{miss}(p,s) = +\infty$ for the rest,  
%then $\mi{conf_{comp}}$ is the same as the PCA confidence.
%
%\leanparagraph{Completeness Precision and Recall} Further developing the idea of scoring rules based on their predictions in complete and incomplete KG parts, we propose to consider the notions of  \emph{completeness precision} and \emph{recall}\footnote{For brevity we skip the word "completeness" if clear from the context.} for rules defined in the spirit of information retrieval. Intuitively, rules having high precision are rules that predict few facts in complete parts, while rules having high recall are rules that predict many facts in incomplete ones. Rule scoring could then be based on any weighted combination of these two metrics.
%
%Formally, we define the precision and recall of a rule $\mi{r: h(X,Y)\leftarrow \vec{B}}$ as follows:
%
%\begin{equation}\label{eq:precision}
%\mi{precision_{comp}}(r)=1-\frac{\mi{npc}(r)}{\mi{supp}(\vec{B})}
%\end{equation}
%
%\begin{equation}\label{eq:recall}
%\mi{recall_{comp}}(r)=\frac{\mi{npi}(r)}{\sum_s \mathit{miss}(h,s)}
%\end{equation}
%
%The \emph{recall measure} is similar to classical support measures, but now expresses how many facts on KG parts known to be incomplete, are generated by the rule (the more the better). The \emph{precision measure}, in turn, assesses how many of the generated facts are definitely wrong, namely those in complete parts (the more of these, the worse the rule). In fact, this is an upper bound on the precision, as the other facts cannot be evaluated.
%
%\begin{example}
%\label{ex:prec_recall}
%%Consider the KG in Fig.~\ref{fig:fam_grad}, rules $\mi{r1}$ and $\mi{r_2}$ from Example~\ref{ex:conf}, and cardinality statements from Example~\ref{ex:cardinality}. 
%It holds that $\mi{npi(r_1)}\!=\!2$, %1$, 
%$\mi{npc(r_1)}\!=\!4$, %3$, 
%while $\mi{npi(r_2)}\!=\!4$, $\mi{npc(r_2)}\!=\!1$, resulting in $\mi{precision_{comp}(r_1)}\!=\!0.5$, 
%$\mi{recall_{comp}(r_1)}\!\approx\!0.67$, %0.5$, 
%and $\mi{precision_{comp}(r_2)}\!\approx\!0.83$, $\mi{recall_{comp}(r_2)}\!\approx\!0.67$, which lead to the expected relative rule ordering. \qed
%\end{example}
%%%%%% OLD EXAMPLE %%%%%
%%\begin{example}
%%Consider the KG in Fig.~\ref{fig:fam_grad} and the rules $\mi{r_1}$ and $\mi{r_2}$ from Example~\ref{ex:conf}. It holds that $\mi{npi(r_2)=3}$, $\mi{npc(r_2)=0}$, while $\mi{npi(r_1)=0}$ and $\mi{npc(r_1)=1}$. From this we obtain $\mi{precision(r_2)=recall(r_2)=1}$, and $\mi{precision(r_1)=0}$, $\mi{recall(r_1)=0}$, leading to the expected relative rule ordering. \qed
%%\end{example}
%%%%%%%%%%%%%%%%%%%%%%%%
%
%\leanparagraph{Limitations}
%While precision and recall are insightful when there are sufficiently many predictions made in (in-)complete %/incomplete 
%parts, they fail when the number of (in-)completeness statements in comparison with the KG size is small. Consider, for instance, a rule that predicts 1000 new facts over $\mi{hasChild}$ relation, out of which 2 are in complete, and 2 are in incomplete parts, and 
%overall 
%1 million children are missing. 
%%in total. 
%This would imply a precision of 99.8\%, and a recall of 0.0002\%, both of which are 
%not very informative.
%
%Therefore, next we propose to look at the difference between  
%expected numbers of predictions in complete and incomplete parts, or simply at their ratio.
%
%\leanparagraph{Directional Bias} If rule mining does make use of completeness information, and both do not exhibit any statistical bias, then intuitively the rule predictions and the (in)complete areas should be statistically independent. On the other hand, correlation between the two indicates that the rule-mining is \emph{(in)completeness-aware}. 
%
%\begin{example}
%Suppose in total a given KG stores 1 million humans, and we know that 10,000 (1\%) of these are missing some children (incompleteness information), while we also know that 1000 of the persons are definitely complete for children (0.1\%). Let the set of rules mined from a KG predict 50,000 new facts for the $\mi{hasChild}$ relation. Assuming independence between predictions and (in)completeness statements, we would expect 1\% out of 50,000, i.e., 500 facts to be predicted in the incomplete areas and 0.1\%, i.e., 50 in the complete KG parts. If instead we find 1000 children predicted for people that are missing correspondingly many children, and 10 for people that are not missing these, the former deviates from the expected value by a factor of 2, and the latter by a factor of 5.
%\end{example}
%%
%%
%Following the intuition from the above example, we propose to look at the extent of the non-independence to quantify the (in)completeness-awareness of rule mining. Let us consider predictions made by rules in a given KG, where \textit{E(\#facts)} is the expected number of predictions and $\alpha=0..1$ is the weight given to completeness versus incompleteness. Then the directional coefficient of a rule $r$ is defined as follows:
%
%\begin{equation}\label{eq:direct_coef}
%\mi{direct\_coef}(r) := \alpha \cdot \frac{E(\mi{npc}(r))}{\mi{npc}(r)} + (1-\alpha) \cdot \frac{\mi{npi}(r)}{E(\mi{npi}(r))}
%\end{equation}
%Unlike the other measures that range from 0 to 1, the directional coefficient takes values between 0 and infinity, where 1 is the default. If the ratio between the KG size and the size of the (in)complete parts is the same as the ratio between the %size of 
%predictions in the (in)complete parts and their total number, i.e.,
%%number of predictions, i.e., 
%if the directional coefficient is 1, then the statements do not influence the rule at all.
%The higher is the \emph{directional coefficient}, the more ``\emph{completeness-aware}'' the rules are.
%
%In practice, expected values might be difficult to compute, and statistical independence is a strong assumption. An alternative that does not require knowledge about expected values is to directly measure the proportion between predictions in complete and incomplete parts. We call this the \emph{directional metric}, which is computed as
%%
%\begin{equation}\label{eq:direct_metric}
%\mi{direct\_metric}(r) := \frac{\mi{npi}(r)-\mi{npc}(r)}{2\cdot(\mi{npi}(r)+\mi{npc}(r))}+0.5\\
%\end{equation}
%%
% The metric is based on the same ideas as the directional coefficient, but does not require knowledge about the expected number of predictions in complete/incomplete KG parts. It is designed to range between 0 and 1 again, thus allowing convenient weighting with other $[0, 1]$  measures.
%The directional metric of a rule that predicts the same number of facts in incomplete as in complete parts is %, has a value of 
%0.5, a rule that predicts twice as many facts in incomplete parts has a value of 0.66, and so on.
%
%Since the real-world KGs are often highly incomplete, it might be reasonable to put more weight on predictions in complete parts.
%This can be done by multiplying predictions made in complete parts by a certain factor. We propose to consider the combination of a weighted existing association rule measure, 
%e.g., confidence or conviction and 
%the directional metric, %i.e.,
%with the weighting factor  %is 
%$\beta=0..1$. Using confidence, we obtain  
%\begin{equation}\label{eq:direct_metric_score}
%\mi{weighted\_dm}(r)=\beta \cdot \mi{conf}(r) + (1-\beta) \cdot \mi{direct\_metric}(r) 
%\end{equation}
%
%
%\begin{example}
%We get $\mi{direct\_metric(r_1)}{\approx} 0.33$ and $\mi{direct\_metric(r_2)}{=}0.8$. %Furthermore, %assuming 
%For $\beta=0.5$ and %standard 
%confidence %from Ex.~\ref{ex:conf}, %we get 
%$\mi{weighted\_dm(r_1)} \approx 0.29$ and $\mi{weighted\_dm(r_2)} \approx 0.48$. \qed
%\end{example}
%
%\leanparagraph{Acquisition of Numerical Statements}
%\label{sec:acquisition-numerical}
%As we have shown, exploitation of numerical (in-)completeness statements is very beneficial for rule quality assessment. 
%A natural question is where to acquire such statements from in real-world settings.  
%Various works have shown that numerical 
%assertions can be 
%frequently found on the Web~\cite{rdfcomp}, %can be 
%obtained via crowd-sourcing~\cite{DarariREN16}, text mining~\cite{paramita-acl-2017} or completeness rule mining~\cite{galarragapredicting}. 
%We believe that mining %rules about 
%numerical correlations concerning KG edges and then 
%assembling %these 
%them into rules %to rules about completeness, 
%is a valuable and a %more 
%modular approach to obtain further completeness information, which we sketch in what follows. 
%
%We start with an available KG $\cG^a$ and some statements of the form (\ref{eq:num}).
%
%
%%\leanparagraph{Approach}
%%We now sketch an approach for mining rules that can be applied to predict numerical restrictions on facts of a certain form using the available cardinality statements and the data in the KG as input. 
%
%\leanparagraph{Step 1} For every cardinality  $\mi{num(p,s)}=k$, we create the facts $p_{\leq k}(s)$ and $p_{\geq k}(s)$. For the pairs $p\in\mathbf{R},s\in\cC$  with no available cardinality statements we construct the facts $p_{\geq \# o: p(s,o)\in \cG^a}(s)$,  encoding that outgoing $p$-edges from $s$ might be %some facts over $p$ with $s$ being the first argument might be 
%missing in $\cG^a$, as the graph is believed to be incomplete by default.
%Here, $p_{card}$ with $\mi{card\in \{\leq \_, \geq \_\}}$ are fresh unary predicates not present in $\Sigma_{\cG^a}$, which describe (bounds on) the number of outgoing $p$-edges for a given constant. We store all constructed facts over $p_{\mi{card}}$ in %a temporary set 
%$\cS$.
% 
%We then complete the domain of each $p_{\mi{card}}$ predicate as follows. For every $p_{\leq k}(s)\in \cS$, if $p_{\leq k'}(s')\in\cS$ for some $s'\in \cC$ and $k' > k$, we construct the rule $ p_{\leq k'}(X)\leftarrow p_{\leq k}(X).$ Similarly, for every $p_{\geq k}(s)\in\cS$, if $p_{\geq k'}(s')\in \cS$ where $k' < k$, we create $p_{\geq k'}(X)\leftarrow p_{\geq k}(X)$.
%%introduced unary predicate 
%The constructed rules are then applied to the facts in $\cS$ to obtain an extended set $\cG^{\mi{card}}$ of facts over $p_{\mi{card}}$. The latter step is crucial when using a rule mining system that is not doing arithmetic inferences (like $x>4$ implies $x>3$).
%%by exhaustively applying the two rules %$p_{\geq k}(s) \leftarrow p_{\geq k+1}(s)$
%%$p_{\geq k}(X) \leftarrow p_{\geq k'}(X)$ where $k < k'$
%%and $p_{\leq k}(X)\leftarrow p_{\leq k'}(X)$ where $k > k'$.
%%$p_{\leq k+1}(s) \leftarrow p_{\leq k}(s)$ 
%%until saturation.
%%This process materialize fully all "interesting" predicated: it is only interesting to consider $p_{\leq 0}$ and the predicates $p_{\leq k+1}$ such that $\{ x \mid p_{\leq k+1}(x) \} \neq \{ x \mid p_{\leq k}(x) \}$ because, if not, then $\{ x \mid p_{\leq k+1}(x) \} = \{ x \mid p_{\leq k}(x) \}$ and, so, does not brings any new information (as we obviously have $\{ x \mid p_{\leq k+1}(x) \} \subseteq \{ x \mid p_{\leq k}(x) \}$). The same idea holds for $(p_{\geq k})_{k \in \mathbb{N}}$.\tptcomment{Previous sentences updated}
%%We denote the set of all such additional facts as $\cG^{\mi{card}}$.
%
%\leanparagraph{Step 2} We then use such a standard rule learning system, AMIE \cite{amie}, on $\cG^a \cup \cG^{\mi{card}}$ to mine rules like:
% 
%\vspace{-\topsep}
%\small{
% \begin{itemize}
%%\begin{minipage}{0.3\linewidth}
%\item[(1)] $\mi{p_{card}(X)\leftarrow p'_{card}(X)}$
%\item[(2)] $\mi{p_{card}(X)\leftarrow p'_{card}(X), p''_{card}(X)}$
%\item[(3)] $\mi{p_{card}(X)\leftarrow p'_{card}(X), r(X,Y)}$
%%\end{minipage}
%%\begin{minipage}{0.7\linewidth}
%\item[(4)] $\mi{p_{card}(X)\leftarrow p'_{card}(X), r(X,Y)},\mi{p''_{card}(Y)}$
%\item[(5)] $\mi{p_{card}(X)\leftarrow r(X,Y), p''_{card}(Y)}$
%%\end{minipage}
%\end{itemize}
%}\normalsize
%\vspace{-\topsep}
%\noindent We rank the obtained %se 
%rules based on confidence %based on standard %association 
%%rule measures 
%and select the top %$n$ rules 
%ones into the set $\cR$.
%
%\leanparagraph{Step 3} Finally, in the last step we use the obtained ruleset $\cR$ to derive further numerical statements together with weights assigned to them. For that we compute $\cG'=\bigcup_{r\in \cR}\{\cG^{card}\cup\cG^{a}\}_{r}$. The weights of the statements are inherited from the rules that derived them. We then employ two simple heuristics: (i) Given multiple rules predicting the same fact, the highest weight for it is kept. We then post-process predictions made by different rules for the same subject-predicate pair as follows. 
%(ii) If $p_{\leq k}(s),p_{\geq k'}(s)\in \cG'$ for $k'>k$, we remove from $\cG'$ predictions with the lowest weight thus resolving the conflict on the numerical bounds. %, and thus end up with a graph, in which none of the bounds on the number of edges represented by the dedicated facts contradict each other. 
%
%From the obtained graph we reconstruct cardinality statements as follows.
%\vspace{-\topsep}
%\begin{itemize}
%\item Given $p_{\leq k}(s),\mi{p_{\geq k}(s)}\in \cG'$ with weights $w$ and $w'$ %assigned to them, 
%we create a cardinality statement $\mi{num(p,s)=k}$ with the weight $min(w,w')$. % and add it to the set $\cS$. 
%\item If $p_{\leq k}(s),p_{\geq k'}(s) \in \cG'$ for $k'<k$, then we set $k' \leq \mi{num(p,s)} \leq k$.
%\item Among two facts $p_{\leq k}(s), p_{\leq k'}(s)$ (resp. $p_{\geq k}(s)$, $p_{\geq k'}(s)$) with $k<k'$ (resp. $k>k'$) the first ones are kept and represented similar to \ref{eq:num}. 
%\end{itemize}
%
%Regular facts in $\cG'$ are similarly translated into their numerical representations.
%%Note that we could end up with an infinite number of $p_{\leq k}$ unary predicates. But it is only interesting to consider $p_0$ and the predicates $p_{\leq k+1}$ such that $\{ x \mid p_{\leq k+1}(x) \} \neq \{ x \mid p_{\leq k}(x) \}$ because, if not, then $\{ x \mid p_{\leq k+1}(x) \} = \{ x \mid p_{\leq k}(x) \}$ and, so, does not brings any new information (as we obviously have $\{ x \mid p_{\leq k+1}(x) \} \subseteq \{ x \mid p_{\leq k}(x) \}$). The same idea holds for $(p_{\geq k})_{k \in \mathbb{N}}$.
%
%
%%%%%% Old KG %%%%%
%\iffalse
%\scriptsize
%\begin{table}[t]
%\begin{center}
%\renewcommand*{\arraystretch}{0.95}
%\begin{tabular}{|l|l|l|l|}
%\hline
%&  $\mi{hasBrother_{\geq 1}}$ &$\mi{hasSister_{\geq 1}}$&
%$\mi{hasSibling_{\geq 2}}$\\\hline
%$\mi{ann}$ & $\checkmark$ &$\checkmark$ &$\checkmark$\\ \hline
%$\mi{kate}$ & $\checkmark$ &$\checkmark$ &$\checkmark$\\ \hline
%$\mi{lola}$ & $\checkmark$ &$\checkmark$ &$\checkmark$\\ \hline
%$\mi{john}$ & $\checkmark$ &$\checkmark$ &\\ \hline
%\end{tabular}
%\caption{Meta-data from Example~\ref{ex:card}}
%\label{tab:inc}
%\end{center}
%\end{table}
%\normalsize
%\fi
%%%%%%%%%%%%%%%%%%%%
%
%%%%%% Old KG %%%%%
%\iffalse
%\begin{figure}[t]
%\begin{center}
%\includegraphics[width=.44\textwidth]{figures/fam}
%\caption{Example KG: family}
%\label{fig:fam}
%\end{center}
%\end{figure}
%\fi
%%%%%%%%%%%%%%%%%%%%
%
%%\simoncomment{This example may raise questions whether our language is good, as it would be better to learn parameterized rules such as c.parent.children=n $\rightarrow$ c.siblings=n-1, instead of c.parent.children=3 $\rightarrow$ c.siblings=2. Can we find another one?}
%
%\begin{example}
%Consider the KG in Fig.~\ref{fig:fam_grad}
%%and the rules $\mi{r1}$ and $\mi{r_2}$ from Example~\ref{ex:conf},
%%along with the following 
%%The following 
%and the following cardinality statements for it: $\mi{num(hasChild,john)\!=\!num(hasSibling,bob)}\!=\!3$.  %construct
%%We generate, between, others, 
%Among others, $\cG^{\mi{card}}$ contains the facts:
%%We generate the following graph with numerical facts 
%%for $\mi{hasChild}$ and $\mi{hasSibling}$ relations and obtain % extended version of the graph: 
%$%\cG^{\mi{card}}=\{
%\mi{hasChild_{\geq 3}(john)},
%\mi{hasSibling_{\geq 3}(bob)},
%\mi{hasChild_{\geq 2}(mary)},
%\mi{hasChild_{\geq 2}(john)},\\ 
%\mi{hasSibling_{\geq 2}(bob)},
%\mi{hasSibling_{\geq 1}(dave)}$, and
%$\mi{hasSibling_{\geq 1}(alice)}$. %,\cdots\}$.
%%On %this 
%On the graph $\cG^a\cup \cG^{\mi{card}}$, the confidence of $\mi{hasSibling}_{\geq 2}(X)\,{\leftarrow}\, \mi{hasFather}(X, Y), \mi{hasChild}_{\geq 3}(Y)$ %has a confidence of 
%is $\frac{1}{3}$ and
%1 for
%$\mi{hasSibling_{\geq 1}(X)\,{\leftarrow}\, hasFather(X, Y),hasChild_{\geq 3}(Y)}$. %has  %a 
%%confidence of $1$.
%\qed
%\end{example}
%
%%  From $\mi{hasParent(john, alice)}, hasChild_{\leq 3}$ and the rule $\mi{r_1}$ we obtain\\ $\mi{hasSibling_{\leq 2}(john)}$ with confidence 2/3, while from the facts in Tab.~\ref{tab:inc} and $\mi{r_2}$ we get $\mi{hasSibling_{\geq 2}(john)}$ with confidence 3/4. Since the facts that we have derived do not contradict each other, we can assume that the exact number of siblings for $\mi{john}$ is 2 with the confidence $min(2/3, 3/4) = 2/3$.
% 
% 
%%  The completeness knowledge from above would be encoded as $\mi{hasChild_{\leq 3}(tom)}$,\linebreak $\mi{hasChild_{\leq 3}(mary),  hasChild_{\leq 3}(alice)}$, $\mi{hasChild_{\geq 3}(tom), hasChild_{\geq 3}(mary)}$, $\mi{hasChild_{\geq 3}(alice)}$ and $\mi{hasSibling_{\geq 2}(pete)}$, $\mi{hasSibling_{\geq 2}(bob)}$. From this data we mine a rule of the form~(5):
%% \begin{center}
%% $\mi{r_1:\, hasSibling_{\leq 2}(X)\leftarrow hasParent(X,Y), hasChild_{\leq 3}(Y)}$
%% \end{center}
%%  stating that normally the number of persons siblings is at most 2 given that his parents have at most 3 children.
%%\end{example}
%
% Ideally, provided that sufficiently many similar numerical correlations about %for different 
% edge numbers %values 
%are extracted, one can induce more general hypothesis involving arithmetic functions like the number of person's siblings is bounded by the number of his parents' children plus 1 or the sum of person's brothers and sisters equals the number of his siblings.  %However, that will require complex induction using mathematical functions, which 
% We leave these more complex generalizations for future work. Similarly, the employed heuristic provide potential for more advanced voting/weighting schemes and inconsistency resolution in the case of conflicting cardinality assertions.
%
