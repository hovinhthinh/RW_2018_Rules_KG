% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %
% % MASTER FILE START
% %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{beamer}
\usepackage{etex}
\mode<presentation> {
\usetheme{Singapore} 
\setbeamercovered{invisible}
\setbeamertemplate{navigation symbols}{} 
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% PACKAGES
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[absolute,overlay]{textpos}
\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
\graphicspath{{./figures/}}
\usepackage{cancel}
\usepackage{url}               % url typeset correctly
\usepackage{named}
\usepackage{tikz}
\usepackage{picture}
\usepackage{algorithm,algorithmic}
\usepackage{multirow}
\usepackage{proof}
\usepackage{transparent}
\usepackage{url}
\usepackage{hyperref}	
\newcommand*\rot{\rotatebox{60}}
\usepackage{color, colortbl}
\usepackage[first=0,last=9]{lcg}
\newcommand{\ra}{\rand0.\arabic{rand}}
\newcommand\FrameText[1]{%
  \begin{textblock*}{\paperwidth}(261pt,239pt)
    \raggedright #1\hspace{.5em}
  \end{textblock*}}
%\setbeamertemplate{mini frames}{}
\definecolor{LightCyan}{rgb}{1,0.88,1}

\setlength{\inferLineSkip}{4pt}
%\usepackage[inference]{semantic}
\usetikzlibrary{shapes,arrows,snakes,backgrounds,%
matrix,patterns,arrows,decorations.pathmorphing,decorations.pathreplacing,%
positioning,fit,calc,decorations.text, automata%
}
\newcommand{\hilightgray}[1]{\colorbox{gray!38}{#1}}
\newcommand{\hilightgreen}[1]{\colorbox{darkgreen!38}{#1}}

\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{darkbl}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}
\definecolor{darkgreen}{rgb}{0,0.46,0}
\definecolor{lightbluebeamer}{rgb}{0,0,0.1}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 
\setbeamertemplate{blocks}[rounded][shadow=false]
\newlength{\Size}

%%% Grid on the slides

% \usepackage[texcoord,grid,gridunit=mm,gridcolor=red!10,subgridcolor=green!10]
% {eso-pic}

\usepackage{enumerate}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsmath}
\usepackage{color}
\usepackage[absolute,overlay]{textpos}
\usepackage{cancel}

\mode<article>
{
\usepackage{fullpage}
}

\def\uminus{\setbox0=\hbox{$\cup$}\rlap{\hbox
    to\wd0{\hss\raise0.3ex\hbox{$\scriptscriptstyle{-}$}\hss}}\box0}
\def\cminus{\setbox0=\hbox{$\cap$}\rlap{\hbox
    to\wd0{\hss\raise0.3ex\hbox{$\scriptscriptstyle{-}$}\hss}}\box0}
\definecolor{light-gray}{gray}{0.45}

\usepackage{soul}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CUSTOM BEAMER STYLE
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setbeamertemplate{blocks}[rounded][shadow=false]
% setup margin
\beamersetleftmargin{0.5cm}
\beamersetrightmargin{0.5cm}

% setup symbols
\setbeamertemplate{bibliography item}[book]
\setbeamertemplate{navigation symbols}{} % turn off navigation symbols

% setup font shapes of various elements
\setbeamerfont{frametitle}{series=\bfseries}
%\setbeamercolor{alerted text}{series=\bfseries}

% put number of frames at the bottom
\setbeamertemplate{footline}[frame number]


\usepackage[scaled]{helvet}

\newtheorem{proposition}[theorem]{Proposition}


\setbeamercolor{alerted text}{fg=purple}

\newcommand{\makeoverview}{%
  \begin{frame}
    \frametitle{Outline}
    \tableofcontents
  \end{frame}
}

\newif\ifshowtoc
\showtoctrue% toggles to show the toc

\AtBeginSection{%
\ifshowtoc
\begin{frame}
    \tableofcontents[currentsection, subsectionstyle=show/show/hide]
\end{frame}
\fi
}

\newcommand{\makereferences}[1]{%
  \begin{frame}[allowframebreaks,allowdisplaybreaks]
    \frametitle{References}
    \bibliography{#1}
  \end{frame}
}



%%%%%%%%%%%%%% SPACING COMMANDS 

\newcommand{\bs}{\bigskip}
\newcommand{\ms}{\medskip}
\newcommand{\s}{\smallskip}


%%%%%%%%%%%%%% SPECIFIC MACROS

\newcommand{\implied}{\mbox{:-}}
\def\bi{\begin{itemize}}
\def\ei{\end{itemize}}
\usepackage{etoolbox}

\usepackage{tikz}

\usetikzlibrary{shapes,arrows,snakes,backgrounds,%
matrix,patterns,arrows,decorations.pathmorphing,decorations.pathreplacing,%
positioning,fit,calc,decorations.text, automata%
}
\tikzset{%
  dots/.style args={#1per #2}{%
    line cap=round,
    dash pattern=on 0 off #2/#1
  }
}

\newrobustcmd*{\myfilledtriangle}[1]{\tikz{\filldraw[draw=#1,fill=#1] (0,0) --
(0.2cm,0) -- (0.1cm,0.2cm);}}

\newrobustcmd*{\mytriangle}[2]{\tikz{\filldraw[very thick, dots=6 per 1cm, style=dotted,draw=#1,fill=#2] (0,0) --
(0.2cm,0) -- (0.1cm,0.2cm) -- (0,0);}}
\definecolor{lightblue}{HTML}{D4E1F5}
\definecolor{darkred}{HTML}{632E2E}

\def\HU{{\mathit H\!U}}
\definecolor{lightbl}{HTML}{66B2FF}
\definecolor{lightred}{HTML}{FF9999}
\definecolor{lightgr}{HTML}{97d077}
\definecolor{darkbl}{HTML}{000099}
\newcommand\HB{\ensuremath{{\it H\!B}}}
\newcommand{\nbls}{\vspace*{-1\baselineskip}}
\newcommand{\weak}{\ensuremath{\mathit{weak}}}
\newcommand{\FLP}{\ensuremath{\mathit{flp}}}
\newcommand{\wred}[3]{\ensuremath{{#1^{#2,#3}_{\mi{weak}}}}}
\newcommand{\flpred}[3]{\ensuremath{{#1^{#2,#3}_{\mi{flp}}}}}
\newcommand{\citeY}[1]{\citeyear{#1}}
\newcommand{\naf}{{\it not}\,}
\newcommand{\NP}{\ensuremath{\mathrm{NP}}}
\newcommand{\SigmaP}[1]{{\Sigma}_{#1}^{P}}
\newcommand{\wrt}[0]{w.r.t.\ }
\newcommand{\tuple}[1]{\ensuremath{\langle#1\rangle}}
\renewcommand{\vec}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\dlliteplugin}{{\fontencoding{OT1}\fontfamily{cmss}\selectfont{dlliteplugin}}}
\newcommand{\hnbls}{\vspace*{-.5\baselineskip}}
\newcommand{\bl}[1]{\textcolor{blue}{#1}}
\newcommand{\gr}[1]{\textcolor{darkgreen}{#1}}
\usepackage{mathtools}
\newcommand{\prg}{\mathcal{P}}
\newcommand{\gre}[1]{\textcolor{darkgreen}{#1}}
\newcommand<>{\red}[1]{{\color#2[rgb]{1,0,0}#1}}
\newcommand{\dllite}{\ensuremath{DL}\text{-}\ensuremath{Lite}}
\newcommand{\el}{\ensuremath{\mathcal{EL}}}
\newcommand{\specialcell}[2][l]{\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
   \newcommand*\circled[1]{%
      \tikz[baseline=(C.base)]\node[draw,circle,inner sep=1pt](C) {#1};\!
    }
   \newcommand*\circledbl[1]{%
      \tikz[baseline=(C.base)]\node[draw,circle,fill=blue!10,inner sep=1.7pt](C) {#1};\!
    }

\usepackage{color}
\newcommand{\hilightbl}[1]{\colorbox{darkblue!18}{#1}}
\newcommand{\hilightred}[1]{\colorbox{red!18}{#1}}

\setbeamercolor{uppercolblue}{fg=black,bg=darkbl!25}
\setbeamercolor{lowercolblue}{fg=black,bg=darkbl!0}
\setbeamercolor{lowercoldarkblue}{fg=black,bg=darkbl!15}


\setbeamercolor{uppercolgreen}{fg=black,bg=darkgreen!35}
\setbeamercolor{lowercolgreen}{fg=black,bg=darkgreen!12}

\setbeamercolor{uppercolred}{fg=black,bg=red!30}
\setbeamercolor{lowercolred}{fg=black,bg=red!12}

\def\cA{\ensuremath{\mathcal{A}}}
\def\cG{\ensuremath{\mathcal{G}}}
\def\cT{\ensuremath{\mathcal{T}}}
\def\cI{\ensuremath{\mathcal{I}}}
\def\cC{\ensuremath{\mathcal{C}}}
\def\cO{\ensuremath{\mathcal{O}}}
\def\cR{\ensuremath{\mathcal{R}}}
\def\cP{\ensuremath{\mathcal{P}}}
\newcommand{\dlvhex}{\textsf{dlvhex}}
\usepackage{appendixnumberbeamer}

\definecolor{darkblue}{rgb}{0.0, 0.62,0.9}

\newcommand\hex{{\sc hex}}

\catcode`\@=11 % as in plain.tex
\long\def\blank#1{\bl@nk#1@@..\bl@nk}%
\long\def\bl@nk#1#2@#3#4\bl@nk{#3#4}
\catcode`\@=12

\long\def\test#1{\begingroup \toks0{[#1]}%
  \newlinechar`\/\message{/\the\toks0:
  \if\blank{#1}EMPTY\else NOT empty\fi%
}\endgroup}



\newcommand{\mi}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\mb}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\dlatom}[3]{\ensuremath{{\operatorname{DL}}{[#1;#2]}{(#3)}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% DOCUMENT PROPERTIES
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\title{Rule Induction and Reasoning over Knowledge Graphs}
 \author[Stepanova, Gad-Elrab, Vinh Ho]{\underline{Daria Stepanova}\inst{1,2}, Mohamed Gad-elrab\inst{1}, Vinh Thinh Ho\inst{1}}
\institute[shortinst]{ \inst{1} Max Planck Institute for Informatics, Saarbr\"{u}cken, Germany \\
\inst{2} Bosch Center for Artificial Intelligence, Renningen, Germany}
 \titlegraphic{
  \centering
\includegraphics[height=.7cm]{logo_mpi_430}\includegraphics[height=1cm]{bosch}

}

\date{25.09.2018}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% DOCUMENT START
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

\frame{\titlepage}


\addtocounter{framenumber}{-1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeoverview

\section{Motivation}
% \begin{frame}\frametitle{Knowledge Graphs}
% \centerline{\emph{\bl{``Semantically enriched machine processable data''}}}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.5,0.5)
% \put(45,-22){\includegraphics[width=.78\textwidth]{know3_}}
% \end{picture}
% \end{frame}


\begin{frame}\frametitle{Semantic Web Search}

\alt<2->{\begin{picture}(0.5,0.5)
\put(-13,-135){\includegraphics[width=1.1\textwidth]{semsearch3}}
\end{picture}}{
\begin{picture}(0.5,0.5)
\put(-13,-115){\includegraphics[width=1.1\textwidth]{lpwoao}}
\end{picture}}


\end{frame}


% \begin{frame}\frametitle{Knowledge Graphs}
%  \alt<2->{


% \begin{picture}(0.5,0.5)
% \put(217,-130){\includegraphics[width=.41\textwidth]{rf_wiki2}}
% \end{picture}
% \begin{picture}(0.5,0.5)
% \put(-5,-120){\includegraphics[width=.65\textwidth]{kg_general1}}
% \end{picture}


% }{\begin{picture}(0.5,0.5)
% \put(23,-135){\includegraphics[width=.85\textwidth]{rf_wiki}}
% \end{picture}}
% \end{frame}

% \begin{frame}\frametitle{Problem: Inconsistency}
% %\alt<2>{
% \includegraphics[width=1\textwidth]{kg_problem1}
% %}{\includegraphics[width=1\textwidth]{kg_er}}

% \end{frame}

% \begin{frame}\frametitle{Semantic Web Search}
% \includegraphics[width=1.02\textwidth]{lproger}
% \end{frame}


\begin{frame}\frametitle{Semantic Web Search}
\bigskip

% Google KG \alert{misses} Roger's living place, but contains his wife's Mirka's.. 
% \bigskip

\begin{center}
\includegraphics[width=1.02\textwidth]{lproger}
\end{center}
\end{frame}

% \begin{frame}\frametitle{Inconsistency and Incompleteness in KGs}
% \bigskip

% \alt<2>{\includegraphics[width=1\textwidth]{kg_inc2}}{\includegraphics[width=1\textwidth]{kg_inc1}}
% \end{frame}



\begin{frame}\frametitle{Semantic Web Search}

\begin{center}
\includegraphics[width=.8\textwidth]{wofrf}
\end{center}
\end{frame}


\begin{frame}\frametitle{Semantic Web Search}
\bigskip

\begin{center}
\includegraphics[width=0.9\textwidth]{lpmirka}
\end{center}
\end{frame}



\begin{frame}\frametitle{Human Reasoning}
\begin{center}
\begin{columns}
\begin{column}{.49\textwidth}
  $\gr{\mi{livesIn(Y,Z)\leftarrow marriedTo(X,Y),}}$ \\
      $\phantom{\mi{livesIn(Y,Z)\leftarrow }}\mi{\gre{livesIn(X,Z)}}$\\$\phantom{\mi{livesIn(Y,Z)\leftarrow }}$\bigskip

 
 $\gr{\mi{marriedTo(mirka,roger)}}$\bigskip

  $\gr{\mi{livesIn(mirka, bottmingen)}}$
------------------------------------\bigskip

  \uncover<2->{\gr{$\mi{livesIn(roger,bottmingen)}$}\bigskip

% \includegraphics[width=.6\textwidth]{rf_in_bottmingen}
}
\end{column}
\begin{column}{.49\textwidth}

  \emph{Married people live together}\bigskip\bigskip\bigskip


  \emph{Mirka is married to Roger}\bigskip\smallskip

  \emph{Mirka lives in Bottmingen
------------------------------------\bigskip

}
  \uncover<2->{\emph{Roger lives in Bottmingen} \bigskip
\bigskip

% \includegraphics[width=.6\textwidth]{bottmingen}
}
\end{column}
\end{columns}
\uncover<2->{\includegraphics[width=.6\textwidth]{rogerInBot}}
%\begin{picture}(0.5,0.5)
    % \put(50,-136){
%}
   % \end{picture}
\smallskip

\uncover<3->{But where can a machine get such rules from?}
\end{center}
\end{frame}

\begin{frame}\frametitle{Inducing Rules from KGs}
\begin{center}
\alt<2->{\includegraphics[width=.8\textwidth]{kg_}}{\includegraphics[width=.8\textwidth]{kg}}
\bigskip

$\gre{livesIn(Y,Z)\leftarrow isMarriedTo(X,Y),livesIn(X,Z)}\uncover<2->{,\alert{\naf\,researcher(Y)}}$
\end{center}
\end{frame}

\begin{frame}\frametitle{Applications of Rule Learning}
\begin{itemize}
\item \bl{Fact prediction}
\bs

\item \bl{Data cleaning}
\bs

\item  \bl{Domain description}
\bs

\item \bl{Finding trends in KGs} $\dotsc$
\end{itemize}
\end{frame}

% \begin{frame}\frametitle{Extracting Rules from Knowledge Graphs}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.5,0.5)
% \put(43,-35){\includegraphics[width=0.75\textwidth]{hr_learn}}
% \end{picture}
% \bigskip
% \bigskip

% \begin{center}
% \gre{$\mi{livesIn(Y,Z)\leftarrow isMarriedTo(X,Y),livesIn(X,Z)}$}
% \end{center}
% \end{frame}


% \begin{frame}\frametitle{Extracting Rules from Knowledge Graphs}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.5,0.5)
% \put(43,-35){\includegraphics[width=0.75\textwidth]{rdf6}}
% \end{picture}
% \bigskip
% \bigskip

% \begin{center}
% \gre{$\mi{livesIn(Y,Z)\leftarrow isMarriedTo(X,Y),livesIn(X,Z), \alert{\naf\ researcher(Y)}}$}
% \end{center}
% \end{frame}


% \begin{frame}\frametitle{Motivation}
% \begin{beamerboxesrounded}[upper=uppercolred,lower=lowercolred,shadow=true]{\textbf{\alert{Important problems}} of KGs:}

%  \medskip
%  \begin{itemize}
%  \item[\alert{\circled{1}}] \alert{Inconsistency} (covered in the morning!)
%  \medskip

%  \item[\alert{\circled{2}}] \alert{Incompleteness} (focus of this lecture)
%  \end{itemize}
%  \end{beamerboxesrounded}
% \bigskip
% \bigskip
% \bigskip
% \pause 

% \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{In this tutorial:}
% \bigskip

%  \begin{itemize}
%  \item[] \bl{Inductive learning of rules from KGs and their application for KG completion and commonsense knowledge discovery}
%  \end{itemize}
% \bigskip

%  \end{beamerboxesrounded}
% \end{frame}




%\subsection{Knowledge Graphs}

%\section{Horn Rules}

% \frame{\frametitle{}
% \begin{center}
% \bl{\Huge{Horn Logic Programming}}
% \end{center}


% \begin{tikzpicture}[remember picture,overlay]
%     \node[xshift=-90.5mm,yshift=-110,anchor=north east] at (current page.north east){%
%     \includegraphics[width=15mm]{horn}};

% \end{tikzpicture}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% $\;\;\;\;\;\;\;\;\;\;\;\;\;$Alfred Horn
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\subsection{Positive Logic Programs}
% \begin{frame}
% \frametitle{Syntax}


% \bs
% \bi
% \item Assume a vocabulary $\Phi$ comprised of nonempty finite sets of 
% \begin{itemize}
% \item constants (e.g., \gre{$\mi{frankfurt}$})
% \item variables (e.g., \gre{$X$})
% \item predicate symbols (e.g., \gre{$\mi{connected}$})
% \end{itemize}
% \bs
% \pause

% \item A \bl{term} is either a variable, a constant, or inductively built from other terms using function symbols.
% \bs
% \pause

% \item An \bl{atom} is an expression of form \bl{$p(t_1,\ldots{},t_n)$}, where 


% \bi
% \item \bl{$p$} is a \bl{predicate symbol} of \bl{arity $n \ge 0$} from $\Phi$, and 
% \item \bl{$t_1,\ldots{},t_n$} are terms. 
% \ei
% (e.g., \gre{$\mi{connected(frankfurt)}$})
% \bs
% \pause

% \item A \bl{term} or an \bl{atom} is \emph{ground} if it contains no variable.\\
% (e.g., \gre{$\mi{connected(frankfurt)}$ is ground}, \gre{$\mi{connected(X)}$} is nonground.)
% \end{itemize}

% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}
%\subsection{Horn Rules}
\begin{frame}
  \frametitle{Horn Rules}
\bigskip

\small{ \bl{\textbf{Rule:} }
$\underbrace{a}_{\Large{\bl{\text{head}}}}\; \leftarrow\; \underbrace{b_1,\, \dotsc,\, b_m.}_{\bl{\text{body}}} $

\bigskip
\bigskip

\small{\bl{\textbf{Informal semantics:}} } If $b_1,\dotsc, b_{m}$ are true, then $a$ must be true.\bigskip
\bigskip

\small{\bl{\textbf{Logic program:}} } Set of rules 

%\small{\bl{\textbf{Closed World Assumption (CWA):} }} facts not known to be true are false
\bigskip
\bigskip

}
\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\alt<2->{Example: non-ground rule}{Example: ground rule}}
\medskip
\small{
\alt<2->{\gre{\%\,Married people live together}\\
$\mi{livesIn(Y,Z)}\leftarrow\mi{isMarried(X,Y)}, \mi{livesIn(X,Z)}$
\bigskip
\bigskip

% \gre{\%\,Constraint: ensure that none is a parent of himself}\\
% $ \bot \leftarrow \mi{parent(X,Y),parent(Y,X)}$
}{\gre{\%\,If Mirka is married to Roger and lives in B., then Roger lives there too}\\
$\mi{livesIn(roger,bottmingen)}\leftarrow\mi{isMarried(mirka,roger)}, \mi{livesIn(mirka,bottmingen)}$
\bigskip

% \gre{\%\,Constraint: It cannot be the case that Roger is a parent of Leo and vice versa }\\
% $ \bot \leftarrow \mi{parent(roger,leo),parent(leo,roger)}$
}}
\end{beamerboxesrounded}

\bigskip



\end{frame}


% \begin{frame}
% \frametitle{Horn Rules}


% %%\normalsize

% \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Def.: \textbf{Horn rule}}
% A \bl{Horn rules} $r$ is an expression of the form
% %
% %
% \begin{equation}
%  \label{eq:clause}
%  \bl{a \leftarrow b_1,\ldots,b_m,}
% \end{equation}
% %
% where $a$, $b_1$, \ldots, $b_m$ are atoms.
% %  of a first-order language $L$.
% \begin{itemize}
%             \item  $a$ is the \bl{head} of the rule
%             \item  $b_1,\ldots,b_m$ is the  \bl{body} of the rule.
% \item
% If $m=0$, the rule is a \bl{fact} (written shortly $a$)
% \end{itemize}
% \end{beamerboxesrounded}

% \bs
% % \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{Example:}
% % Ground rule: \gre{$$}
% % \end{beamerboxesrounded}

% Intuitively, (\ref{eq:clause}) can be seen as material implication
% \begin{center}
% \bl{$\forall \vec{x}\; b_1\land\cdots\land b_m \rightarrow a$}, where \bl{$\vec{x}$}
% \end{center}
% is the list of all variables occurring in (\ref{eq:clause}).

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \frametitle{Nonmonotonic Rules}
\bigskip

\small{ \bl{\textbf{Rule:} }
$\underbrace{a}_{\Large{\bl{\text{head}}}}\; \leftarrow\; \underbrace{b_1,\, \dotsc,\, b_m,\,\bl{not} \,b_{m+1},\,\dotsc,\,\bl{not} \,b_n.}_{\bl{\text{body}}} $

}
\bigskip
\bigskip

\small{\bl{\textbf{Informal semantics:}} } If $b_1,\dotsc, b_{m}$ are true and \bl{none} of $b_{m+1},\dotsc,b_n$ is \bl{known}, \phantom{\textbf{Informal semantics:\;\;\;}}then  $a$ must be true.\bigskip
\bigskip

\bl{\textbf{Closed World Assumption (CWA):} } facts not known to be true are false
\bigskip
\bigskip


\alt<2->{\bigskip
 \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\large{\bl{$\naf$}} \normalsize{is different from} \large{\bl{$\mathbf{\neg}$}}\normalsize{!}}
\gre{\% At a rail road crossing cross the road if \textbf{no train is known} to approach''}\\
$\mi{walk}\leftarrow \mi{at(L), crossing(L), \naf\ train\_approaches(L)}$
\bigskip

\gre{\% At a rail road crossing cross the road if \textbf{no train} approaches}\\
$\mi{walk}\leftarrow \mi{at(L), crossing(L), \neg train\_approaches(L)}$


\end{beamerboxesrounded}}{\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{Example: nonmonotonic rule}
\small{
\medskip

\gre{\% Two married live together unless one is a researcher}\\
$\mi{livesIn(Y,Z)}\leftarrow\mi{isMarried(X,Y)}, \mi{livesIn(X,Z)},\naf\ \mi{researcher(Y)}$
\bigskip

% \gre{\% Disjunctive knowledge: a parent $X$ is either a father or a mother}\\
% $\mi{father(X,Y)}\lor \mi{mother(X,Y)}\leftarrow \mi{parent(X,Y)}$
% \bigskip

%\gre{\% Constraint: ensure that none is a parent of himself}\\
%$ \bot \leftarrow \mi{parent(X,Y),parent(Y,X)}$
}

\end{beamerboxesrounded}
}
\bigskip



\end{frame}


\begin{frame}
\frametitle{Herbrand Semantics}

{\small
\medskip

%\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Def.: \textbf{Herbrand universe, base, interpretation}}

%\small
\textbf{\bl{Herbrand universe}} of a logic program $P$, $\bl{HU(P)}$ is the  set of all constants appearing in $P$.
\bs

\textbf{\bl{Herbrand base}} of $P$, \bl{$\HB(P)$} is the set of all ground
atoms which can be formed from predicates and constants of $P$.

\bs
\textbf{\bl{(Herbrand) interpretation}} of $P$, \bl{$I$} is a subset of the Herbrand base.

%\end{beamerboxesrounded}
\bs



\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{Example: Herbrand universe, base, interpretation}
\medskip
$P=\left\{      \begin{array}{l@{\qquad}}
         \mbox{(1) }\mi{isMarriedTo(mary,john)}\;\;\; \mbox{(2) }\mi{livesIn(mary,ulm)}\\[0.35ex]
\mbox{(3) }\mi{livesIn(Y,Z)\leftarrow isMarriedTo(X,Y), livesIn(X,Z), \naf\ researcher(Y)}
      \end{array}
\right\}
$

% $P=\{isMarriedTo(mirka, roger). \;livesIn(mirka, bottmingen).$ \s

%$\phantom{P=\{}livesIn(Y,Z)\leftarrow isMarriedTo(X,Y), livesIn(X,Y), \naf\ researcher(Y).\}$\s
\pause
\s

 $\mi{HU(P)=\{mirka,roger,bottmingen\}}$\s
\pause
\s

 $\mi{HB(P)=\{isMarriedTo(mirka,mirka),isMarriedTo(mirka,roger),\dotsc}$\\$\phantom{HB(P)=\{}\mi{livesIn(mirka,bottmingen),livesIn(roger,bottmingen),\dotsc\}}$\s
\pause
\s

 $I_1=\emptyset, I_2=\{\mi{isMarriedTo(mirka, roger),livesIn(bottmingen,bottmingen)}\}, \dotsc$

\end{beamerboxesrounded}

}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

% \begin{frame}
% \frametitle{Example}

% % \begin{example}[Program $P_1$]

% % \nbls

% \ms
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

% Program $P$:
% {\small
% \begin{align*}
% \gre{p(X,Y,Z)   \implied  p(X,Y,Z'), h(X,Y), t(Z,Z',r).} \\
% \gre{h(X,Z')  \implied p(X,Y,Z'), h(X,Y), t(Z,Z',r).} \\
%               \gre{p(0,0,b).} \qquad \gre{h(0,0).} \qquad  \gre{t(a,b,r). }
% \end{align*}
% }

% \nbls
% \pause

% \bi
% \item
%  Constant symbols: \gre{$0$, $a$, $b$,  $r$.}%;\; \qquad 

% % \bigskip
% \pause

% \item
% Herbrand universe $\HU(P)$: \qquad \gre{$\{ 0, a, b, r\}$}\pause
% % \bs
% %
% \item ~\\[-0.8\baselineskip]
% $\begin{array}{@{}r@{~}l}
% \text{Herbrand base }\HB(P): \qquad \gre{\{} & \gre{p(0,0,0), p(0,0,a), \ldots , p(r,r,r),}\\ 
%                     & \gre{h(0,0), h(0,a), \ldots,  h(r,r,r),} \\
%                     & \gre{t(0,0,0), t(0,0,a), \ldots ,t(r,r,r) \}}
% \end{array}
% $

% \ms
% \pause

% \item
% Some Herbrand interpretations:

% \s

% \qquad \gre{$I_1 = \emptyset$;~ \quad $I_2 = \HB(P)$;~\quad $I_3 = \{ h(0,0), t(a,b,r),
% p(0,0,b)\}$.}%; \ldots
% % \end{example}
% \ei
% \end{beamerboxesrounded}
% \end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

% \begin{frame}
% \frametitle{Grounding Example}

% % \begin{example}[Program $P_2$]
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

% {\small
% $\gre{P}=\{livesIn(mirka,b).\; isMarriedTo(mirka,roger).\\
% livesIn(Y,Z)   \leftarrow  livesIn(X,Y), isMarriedTo(Y,Z), \naf\ researcher(Y). \}$
% }

% \nbls
% \pause
% \bigskip
% \bigskip

% \gre{The ground instances of the rule are}

% %
% \small{$X=Y=Z=m$\\
% $livesIn(m,m) \leftarrow  livesIn(m,m), isMarriedTo(m,m), \naf\;researcher(m).$ \bigskip

% $X=Y=r, Z=b$ \\
% $livesIn(r,b) \leftarrow  livesIn(r,r), livesIn(r,b), \naf\;researcher(r). $\bigskip

% $X=Y=Z=b$\\
% $livesIn(b,b) \leftarrow  livesIn(b,b), isMarriedTo(b,b), \naf\;researcher(b).$  }
% \end{beamerboxesrounded}

% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Answer Set Semantics}

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Def.: \bl{\textbf{Herbrand models, answer sets}}}
\bs
\bi
\item An interpretation $I$ is a \bl{(Herbrand) model} of (or satisfies)

\begin{itemize}
% \item \bl{a ground (variable-free) clause $C = a \implied b_1,\ldots,b_m, \naf\ b_{m+1},\dotsc, \naf\ b_n$},  symbolically $I\models C$,
% if either $\{b_1,\ldots,b_m\} \nsubseteq I$ or $a \in I$;
% %  \hfill ($I\models C$)

% \bs
% \item a rule ground rule $r:a\leftarrow b_1,\dotsc,b_m,\naf\ b_{m+1},\dotsc,b_m$ if  $\{b_1,\dotsc,b_m\}\subseteq I$ and $\{b_{m+1},b_n\}\cap I=\emptyset$ imply $a \in I$ (written $I\models r$).
% \bs

\item \bl{ground rule $r:a\leftarrow b_1,\dotsc,b_m,\naf\ b_{m+1},\dotsc,\naf\ b_n$}, if  $\{b_1,\dotsc,b_m\}\subseteq I$ and $\{b_{m+1},b_n\}\cap I=\emptyset$ imply $a \in I$ (written $I\models r$).
\bs
\pause

 \item \bl{a nonground rule $r$}, symbolically $I\models r$,
 if $I\models r$ for every  $r\in grnd(C)$;
%  \hfill ($I\models C$)
   \bs
\pause

\item \bl{a program $P$}, symbolically $I\models P$,
if $I\models C$ for every clause $C$ in $P$.
%  \hfill ($I\models P$)

\end{itemize}
\bs
\item  Minimal model (answer set): none of its subsets is a model.
\ei
% We write $I\models C$ and $I\models P$ to denote that $I$ is a model of $C$ or $P$, respectively.
\end{beamerboxesrounded}
% \bs

% \visible<2->{
% \begin{proposition}
% For every positive logic program $P$, $\HB(P)$ is a model of $P$.
% \end{proposition}
% }
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Example}

% \begin{example}[Program $P_2$]
\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

\gre{Consider program $P$:}
{\small
\begin{align*}
livesIn(m,b). \qquad isMarriedTo(m,r). \qquad bornIn(m,b). \\
livesIn(Y,Z)   \leftarrow  livesIn(X,Y), isMarriedTo(Y,Z), \naf\ researcher(Y). \\
livesIn(X,Y)\leftarrow bornIn(X,Y).
\end{align*}
}

\small{
\alt<5->{
\gre{Which of the following interpretations are minimal models of $P$?}
\begin{itemize}
\item[$\gre{\bullet}$] $I_1=\HB(P)$ \visible<6->{\red{\textbf{no}}}
\item[$\gre{\bullet}$] $I_2=\{\mi{livesIn(m,b),isMarriedTo(m,r),livesIn(r,b),bornIn(m,b)}\}$ \visible<7->{\gre{\textbf{yes}}}
\end{itemize}}{\gre{Which of the following interpretations are models of $P$?}
\begin{itemize}
  \item[$\gre{\bullet}$]  $I_1 = \emptyset$  \visible<2->{ \red{\textbf{no}}}
  \item[$\gre{\bullet}$]  $I_2 = \HB(P)$  \visible<3->{ \gre{\textbf{yes}}}
  \item[$\gre{\bullet}$]  $I_3 = \{\mi{livesIn(m,b),isMarriedTo(m,r),livesIn(r,b)}\}$ \visible<4->{ \red{\textbf{no}}}
\end{itemize}}}
\bigskip
\pause



% \end{example}
\end{beamerboxesrounded}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Minimal Model Semantics}

% \begin{frame}
% \frametitle{Minimal Model Semantics}

% \begin{itemize}
% \item A logic program has multiple models in general.

% \item Select one of these models as the canonical model.

% \item Commonly accepted: truth of an atom in model $I$ should be
%    ``founded'' by clauses.
% \end{itemize}
 
% \bs

% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

% \textbf{Given:}
% $$\gre{P_1 = \{ a \leftarrow b.}\quad \gre{\ b \leftarrow c.}\quad \gre{\ c \},}$$
% truth of \gre{$a$} in the model \gre{$I=\{ a, b , c\}$}  is ``founded''.

 
% \bs

% \textbf{Given:}
% $$\gre{P_2 = \{ a \leftarrow b}.\quad \ \gre{b \leftarrow a.}\quad \ \gre{c \},}$$
% truth of \gre{$a$} in the model \gre{$I=\{ a, b , c\}$}  is not founded.
% \end{beamerboxesrounded}


% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}
% \frametitle{Minimal Model Semantics (cont'd)}
% \bs

% \bl{Occam's razor principle}: prefer models with the smallest true-part.

% \bs
% \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Def: \textbf{Minimal models}}
% A model $I$ of $P$ is \bl{minimal}, if there exists no
%   model $J$ of $P$ such that $J \subset I$.
% \end{beamerboxesrounded}


% \bs
% % \pause

% \begin{theorem}
% Every positive logic program $P$ has a single minimal model.
% \end{theorem}

% \ms


% \end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}
% \frametitle{Example}
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

% \begin{itemize}
%                 \item
% For \gre{$P_1 = \{\; a \leftarrow b.\quad \ b \leftarrow c.\quad \ c \; \}$},
% we have \gre{$LM(P_1) = \{ a,b, c\}$}.

% \bs

% \item For
% \gre{$P_2 = \{\; a \leftarrow b.\quad \ b \leftarrow a.\quad \ c \;\}$},
% we have \gre{$LM(P_2) = \{ c\}$}.

% \bs

% %\item For 
% %$$\begin{array}{r@{}l}
% %P_2 = \{&p(X,Y,Z) \implied  p(X,Y,Z'), h(X,Y),
% %t(Z,Z',r).\\
% %& h(0,0)\},
% %\end{array}$$
% %  we have $LM(P_2) = \{ h(0,0)\}$.

% \bs

% \item For $P$ from above,
% {\small
% \begin{align*}
% \gre{p(X,Y,Z)   \leftarrow  p(X,Y,Z'), h(X,Y), t(Z,Z',r).} \\
% \gre{h(X,Z')  \leftarrow p(X,Y,Z'), h(X,Y), t(Z,Z',r).} \\
%               \gre{p(0,0,b).} \qquad \gre{h(0,0).} \qquad  \gre{t(a,b,r). }
% \end{align*}
% }
%  we have
% \gre{$$LM(P) = \{  h(0,0), t(a,b,r), p(0,0,b), p(0,0,a), h(0,b)\}.$$}
% \end{itemize}
% % \end{example}
% \end{beamerboxesrounded}
% \end{frame}

%\subsection{Nonmonotonic Rules}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}
\frametitle{Answer Set Programs}
\begin{itemize}
\item[]\uncover<1->{\bl{Evaluation} of ASP programs is model-based }%\footnote{unlike in prolog, which is based on theorem proving}}%\uncover<3->{, it consists of 2 steps:}
\begin{itemize}
\uncover<2->{\item[1.]\bl{Grounding}: substitute all \bl{variables with constants} in all possible ways }
\uncover<4->{\item[2.]\bl{Solving}: compute a \bl{minimal model (answer set) $I$} satisfying all rules}
\end{itemize}
\end{itemize}
\bigskip

\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\textbf{Answer set program (ASP)} is a set of nonmonotonic rules}
\bigskip

$\gr{
      \begin{array}{l@{\qquad}}
         \mbox{(1) }\mi{isMarriedTo(mary,john)}\;\;\; \mbox{(2) }\mi{livesIn(mary,ulm)}\\[0.35ex]
         \mbox{(3) }\mi{livesIn(\alt<3->{\mi{john,ulm}}{\bl{Y,Z}})} \leftarrow \alt<3->{\mi{isMarriedTo(mary,john)}}{\mi{isMarriedTo(\bl{X,Y})}},\mi{livesIn(\alt<3->{mary,ulm}{\bl{X,Z}})},\\
\phantom{\mbox{(3) }\mi{livesIn(john,ulm)}\leftarrow}\naf\,researcher(\alt<3->{john}{\bl{Y}})\\
          \uncover<5->{\\[0.35ex]\bl{\mbox{(4) }\mi{researcher(john)}}}
      \end{array}
    }$
\medskip

\uncover<5->{\small{$\phantom{\mi{I{=}\{\mi{isMarriedTo(mary,john),livesIn(mary,ulm)}}}\bl{\mi{researcher(john)}}$}}
\uncover<4->{
\small{$\gr{\mi{I{=}\{\mi{isMarriedTo(mary,john),livesIn(mary,ulm)},\alt<5->{\cancel{\mi{livesIn(john,ulm)}}}{\mi{livesIn(john,ulm)}}\}}}$}

\uncover<4>{\medskip

\bl{CWA:} \gr{$\mi{researcher(john)}$} can not be derived, thus it is false}}

\end{beamerboxesrounded}
\uncover<6->{\begin{center}Particularly suited for reasoning under incompleteness!\end{center}}
\end{frame}


% \begin{frame}
% \frametitle{Answer Set Semantics}
% \bigskip

% \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Def.: \bl{\textbf{Answer sets}}}
% \begin{itemize}
% \item An interpretation $I$ is a \bl{Herbrand model} of a rule $r:a\leftarrow b_1,\dotsc,b_m,\naf\ b_{m+1},\dotsc,b_m$ if  $\{b_1,\dotsc,b_m\}\subseteq I$ and $\{b_{m+1},b_n\}\cap I=\emptyset$ imply $a \in I$ (written $I\models r$).
% \bs

% \item \bl{Answer set} is a minimal model of a nonmonotonic logic programs.
% \end{itemize}
% \end{beamerboxesrounded}
% \bs
 
%\begin{itemize}
% \item[] \only<2,3>{\bl{Evaluation} of ASP programs is model-based, it consists of 2 steps:
%\begin{itemize}
%\item[1.] \bl{Grounding}: substitute all variables with constants in all possible ways 
%\item[2.] \bl{Solving}: compute a minimal \bl{model (answer set) $I$} satisfying all rules
%\end{itemize}
%}
%\end{itemize}
%\bigskip

% \pause 

% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}
% \bigskip

% \small{$P = \left\{
%       \begin{array}{l@{\qquad}}
%          \mbox{(1) }\mi{livesIn(alex,ulm)};\; \mbox{(2) }\mi{isMarried(alex,mat)};\\
%          \mbox{(3) }\mi{livesIn(\alt<3->{\mi{mat,ulm}}{Y,Z})} \leftarrow \mi{isMarried(\alt<3->{alex,mat}{X,Y}),livesIn(\alt<3->{alex,ulm}{X,Z})},\\ 
%          \phantom{\mbox{(3) }\mi{livesIn(\alt<3->{mat,ulm}{Y,Z})} \leftarrow }\naf\ \mi{researcher(\alt<3->{\mi{mat}}{Y})}; \only<3->{\\[0.35ex]\bl{\mbox{(4) }\mi{researcher(mat)}}}
%          % \only<4>{\\[0.35ex]\mbox{(5) }\bot \leftarrow \mi{livesIn(Y,Z_1),livesIn(Y,Z_2),Z_1\neq Z_2}.}
% %\only<6>{\\[0.35ex]\alt<7>{\mbox{(5) }\mi{livesIn(mat,golm)}}{\alert{\mbox{(5) }\mi{livesIn(mat,golm)}}}\\[0.35ex]}\only<5>{\alert{\mbox{(6) }\mi{researcher(\alt<3>{\mi{mat}}{Y})}}}
%       \end{array}
%     \right\}$

% \only<2->{\bigskip\bigskip

% $\mi{I{=}\{\mi{livesIn(alex,ulm),isMarried(alex,mat)},\alt<3->{\cancel{\mi{livesIn(mat,ulm)}},\bl{\mi{researcher(mat)}}}{\mi{livesIn(mat,ulm)}}\}}$\bigskip

% \only<2>{\bl{CWA:} $\mi{researcher(mat)}$ can not be derived, thus it is false}}
% }
% \end{beamerboxesrounded}
% \medskip

% \only<4>{\bl{Nonmonotonicity}: adding facts might lead to loss of consequences!}
% \end{frame}

\section{Rule Learning}


\begin{frame}\frametitle{Reasoning with Incomplete Information}
\small{
\begin{columns}
\begin{column}{0.3\textwidth}
\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\begin{center}\bl{Default Reasoning}\end{center}}
\begin{center}\bigskip\bigskip


Assume normal state of 
affairs, unless there is 
evidence to the 
contrary\bigskip\bigskip

\gre{\emph{By default married people live together.}}\bigskip\bigskip
\end{center}
\end{beamerboxesrounded}
\end{column}
\begin{column}{0.3\textwidth}
\uncover<2->{\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\begin{center}\bl{Abduction}\end{center}}
\begin{center}\bigskip\bigskip

Choose between 
several explanations  
that explain an 
observation\bigskip\bigskip

\gre{\emph{John and Mary live together. They must be married.}}
\end{center}
\end{beamerboxesrounded}}
\end{column}
\begin{column}{0.3\textwidth}
\uncover<3->{\alt<4->{\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercoldarkblue,shadow=true]{\begin{center}\bl{Induction}\end{center}}
\begin{center}\bigskip\bigskip

Generalize a rule from a 
number of similar 
observations\bigskip\bigskip

\gre{\emph{\emph{Given many examples of spouses living together generalize this knowledge.}}}
\end{center}
\end{beamerboxesrounded}}{\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\begin{center}\bl{Induction}\end{center}}
\begin{center}\bigskip\bigskip

Generalize a 
number of similar 
observations into a hypothesis\bigskip\bigskip

\gre{\emph{Given many examples of spouses living together generalize this knowledge.}}
\end{center}
\end{beamerboxesrounded}}}
\end{column}

\end{columns}}
\end{frame}


%\subsection{ILP}


\begin{frame}\frametitle{History of Inductive Learning}
\begin{itemize}
%\item \bl{Philosophy:} \\
%Aristotle, Hume, Miller, Popper, Peirce, ...\bigskip

\item \bl{AI \& Machine Learning 1960s-70s:} \\
Banerji, Plotkin, Vere, Michalski, ...\bigskip

\item \bl{AI \& Machine Learning 1980s:} \\
Shapiro, Sammut, Muggleton, ...\bigskip

\item \bl{Inductive Logic Programming 1990s:} \\
Muggleton, Quinlan, De Raedt, ...\bigskip

\item \bl{Statistical Relational Learning 2000s:} \\
Getoor, Koller, Domingos, Sato, ...
\end{itemize}
\end{frame}





\begin{frame}\frametitle{Learning from Examples }
\smallskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Inductive Learning from Examples \cite{DBLP:journals/ngc/Muggleton91}}
 \smallskip

\textbf{Given:} 
 \begin{itemize}
\item \bl{$\mi{E^+:}$} positive examples (ground facts) over a relation $p$
\item \bl{$\mi{E^-:}$} negative examples (ground facts) over $p$
 \item \bl{$\mi{T:}$} background theory (a set of facts and possibly rules)
\item \bl{Language bias:} syntactic restrictions on the definition of $p$
 \end{itemize}

\bigskip

 \uncover<2->{\noindent \textbf{Find:} 
 \begin{itemize}
\item \bl{$\mi{Hyp:}$} hypothesis defining $p$ such that 
\begin{itemize}
\item \bl{$\mi{Hyp}$} ''covers'' all positive examples given \bl{$B$}, i.e., \\
\bl{$\mi{\forall e\in E^+:\; T\cup Hyp \models e}$}
\medskip

\item \bl{$Hyp$} does not ``cover'' any negative examples given \bl{$B$}, i.e., \\
\bl{$\mi{\forall e\in E^-:\; T \cup Hyp \not \models e}$}
\end{itemize}
\end{itemize}}
 \end{beamerboxesrounded}
\end{frame}

\begin{frame}\frametitle{Example}
 \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}

 \smallskip
\small{
 \textbf{Given:} 
 \begin{itemize}
\item[\gre{$\bullet$}] $\gre{E^+}=\{\mi{fatherOf(john,mary),fatherOf(david,steve)}\}$
\item[\gre{$\bullet$}] $\gre{E^-}=\{\mi{fatherOf(kathy,ellen),fatherOf(john,steve)}\}$ 
 \item[\gre{$\bullet$}] $\gre{T}=\{\mi{parentOf(john,mary),male(john),}$\\$\phantom{T=\{}\mi{parentOf(david,steeve),male(david),}$\\$\phantom{T=\{}\mi{parentOf(kathy,ellen),female(kathy)}\}$
\item[\gre{$\bullet$}] \gre{Language bias}: Horn rules with 2 body atoms
 \end{itemize}
\bigskip
\bigskip

\pause

\textbf{Possible hypothesis:}
\begin{itemize}
\item[\gre{$\bullet$}] $\gre{\mi{Hyp}}:\;\mi{fatherOf(X,Y)\leftarrow parentOf(X,Y),male(X)}$
\end{itemize}}

 \end{beamerboxesrounded}
\end{frame}

\begin{frame}\frametitle{Learning from Interpretations}
\smallskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{Inductive Learning from Interpretations \cite{DBLP:journals/ai/RaedtD94}}
 \smallskip

\textbf{Given:}
 \begin{itemize}
\item \bl{$\mi{I:}$} interpretation, i.e., a set of facts over various relations
\item \bl{$\mi{T:}$} background theory, i.e., a set of facts and possibly rules
\item \bl{Language bias:} syntactic restrictions on the target hypothesis
 \end{itemize}

\bigskip

 \uncover<2->{\noindent \textbf{Find:} 
 \begin{itemize}
\item \bl{$\mi{Hyp:}$} hypothesis, such that \bl{$\mi{I}$} is a minimal model of \bl{$\mi{Hyp \cup T}$}
\end{itemize}}
 \end{beamerboxesrounded}
\end{frame}

\begin{frame}\frametitle{Example}

 \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{Inductive Learning from Interpretations \cite{DBLP:journals/ai/RaedtD94}}
 \smallskip

 \textbf{Given:} 
 \begin{itemize}
\item[\gre{$\bullet$}] $\mi{\gre{I}=\{isMarriedTo(mirka,roger), livesIn(mirka,b),}$\\$\phantom{I=\{}\mi{livesIn(roger,b), bornIn(mirka,b)\}}$
\item[$\gre{\bullet}$] $\mi{\gre{T}=\{isMarriedTo(mirka,roger);\,bornIn(mirka,b);}$\\$\phantom{I=\{}\mi{livesIn(X,Y)\leftarrow bornIn(X,Y)}\}$
\item[$\gre{\bullet}$] \gre{Language bias}: Horn rules
 \end{itemize}

\bigskip

 \uncover<2->{\noindent \textbf{Possible Hypothesis:} 
 \begin{itemize}
\item[$\gre{\bullet}$] $\mi{\gre{Hyp}:livesIn(Y,Z)\leftarrow isMarriedTo(X,Y),bornIn(X,Z)}$
\end{itemize}}
 \end{beamerboxesrounded}
\end{frame}

\begin{frame}\frametitle{Common Techniques in ILP}

\begin{itemize}
\item \bl{Generality ($\succeq$)}: essential component of symbolic learning systems\\
\item \bl{Genaralization as $\theta$-subsumption}
\begin{itemize}
\item \bl{Atoms}: $\mi{a\succeq b}$ iff a substitution $\theta$ exists such that $a\theta =b$ \\
\pause
\gre{$\mi{person(X)\succeq person(roger)},\;\;\theta=\{X/roger\}$}
\pause
\item \bl{Clause}: $C\succeq D$ iff $\theta$ exists, s.t. $C\theta \subseteq D$\\
\pause
\gre{$\mi{\{worksAt(X,Y)}\} \succeq \{\mi{worksAt(Z,luxUni),researcher(Z)}\},$\\\pause
$ \gre{\theta=\{X/Z,Y/uniLux\}}$}
\pause
\end{itemize}
\item \bl{Generalization as entailment}
\begin{itemize}
\item \bl{Logic program}: $\mi{Hyp1}\succeq \mi{Hyp2}$ iff $\mi{Hyp1}\models \mi{Hyp2}$\\\pause

 \small{\gre{$\underbrace{\mi{person(X)\leftarrow researcher(X)}}_{\mi{Hyp1}}$} 
\alt<9->{\gre{$\underbrace{\mi{person(X)\leftarrow researcher(X),alive(X)}}_{\mi{Hyp2}}$}}{\gre{$\underbrace{\mi{person(mat)\leftarrow researcher(mat)}}_{Hyp_2}$}}}\\
\uncover<8,10->{\centerline{$\gre{\mi{Hyp1\succeq Hyp2}}$}}
\smallskip

\uncover<11->{\item \bl{Relative entailment}: $\mi{Hyp1 \succeq Hyp2}$ wrt $T$ iff $\mi{Hyp1\cup T \models Hyp2}$}
\uncover<12->{$\gre{\mi{livesIn(roger,bottmingen})}$ \alt<14->{$\succeq$}{?} $\mi{\gre{livesIn(roger,switzeland)}}$\\
\uncover<13->{$\gre{\mi{T:\,livesIn(X,switzerland)\leftarrow livesIn(X,bottmingen)}}$}
}
\end{itemize}
\end{itemize}

% \bs
% \pause
% \pause

% \item \bl{Clause refinement} \cite{clauseref}: e.g., MIS, FOIL, etc.
% \begin{itemize}
% \item Explore clause search space from general to
% specific or vice versa to find a hypothesis that covers all examples.
% \end{itemize}
% \end{itemize}

% %\begin{beamerboxesrounded}[upper=uppercolgren,lower=lowercolgreen,shadow=true]{}
% \begin{center}
% \includegraphics[width=0.7\textwidth]{ref_graph}
% \end{center}
% %\end{beamerboxesrounded}
% \uncover<3->{\begin{itemize}
% \item \bl{Inverse entailment} \cite{DBLP:journals/ngc/Muggleton95}: e.g., Progol
% \end{itemize}}
\end{frame}


\begin{frame}\frametitle{Common Techniques in ILP}

\begin{itemize}
\item \bl{Clause refinement} \cite{clauseref}: e.g., MIS, FOIL, etc.
\begin{itemize}
\item Explore clause search space from general to
specific or vice versa to find a hypothesis that covers all examples.
\end{itemize}
\end{itemize}

%\begin{beamerboxesrounded}[upper=uppercolgren,lower=lowercolgreen,shadow=true]{}
\begin{center}
\includegraphics[width=0.7\textwidth]{ref_graph}
\end{center}
%\end{beamerboxesrounded}
\uncover<2->{\begin{itemize}
\item \bl{Inverse entailment} \cite{DBLP:journals/ngc/Muggleton95}: e.g., Progol, etc.
\begin{itemize}
\item Properties of deduction to make hypothesis search space finite
\end{itemize}
\end{itemize}}
\end{frame}



\begin{frame}\frametitle{Zoo of Other ILP Tasks}
ILP tasks can be classified along several dimensions:
\smallskip
\small{
% \begin{columns}
% \begin{column}{0.69\textwidth}
\begin{itemize}
\item \bl{type of the data source}, 
e.g., positive/negative examples, interpretations, answer sets \cite{ILASP_system}
\pause 

\item \bl{type of the output knowledge}, 
e.g., rules, DL ontologies \cite{dllearner}
\pause

\item \bl{the way the data is given as input}, 
e.g., all at once, incrementally \cite{ILED}

\pause 

\item \bl{availability of an oracle},
 e.g., human in the loop

\pause

\item \bl{quality of the data source},
e.g.,  noisy \cite{sigmailp}

\pause 

\item \bl{data (in)completeness},
 e.g., OWA vs CWA...

\pause
 
\item \bl{background knowledge},
e.g., DL ontology \cite{d2016ontology}, hybrid theories \cite{DBLP:journals/tplp/Lisi10}
\end{itemize}
% \end{column}
% \begin{column}{0.29\textwidth}
% \end{column}
% \end{columns}
}
\end{frame}


% \begin{frame}\frametitle{Common Techniques in ILP}
% \begin{itemize}

% \begin{itemize}
% \item Translate the induction problem into deduction
% \item $\mi{T \wedge Hyp \models E}$
% \item $\mi{T\wedge \overline{E} \models \overline{Hyp}}$
% \item $\mi{T \wedge E \models \bot \models Hyp}$
% \item $\mi{Hyp\models \bot}$
% \end{itemize}
% \end{itemize}
% \bs

% \begin{center}
% \includegraphics[width=1\textwidth]{ref_graph}
% \end{center}
% \end{frame}


\begin{frame}\frametitle{Rule Induction from Knowledge Graphs}
\bigskip

\begin{center}
What is the most suitable ILP task for the KG setting?
\end{center}

\begin{center}\includegraphics[width=0.7\textwidth]{kg}\\
\pause 
Probably learning from interpretations..
\end{center}


\end{frame}


\begin{frame}\frametitle{\alt<3->{Ideal Setting}{\alt<2->{Example}{Declarative Programming}}}
\alt<3->{\begin{picture}(0.5,0.5)
    \put(20,-120){\includegraphics[width=0.86\textwidth]{asp_25}}
\end{picture}
}{\alt<2->{
 \begin{picture}(0.5,0.5)
 \put(20,-135){\includegraphics[width=0.9\textwidth]{asp_2}}
 \end{picture}
\put(36,65){\text{\small{Graph 3-colorability}}}

\begin{picture}(0.5,0.5)
\put(23,115){\includegraphics[width=0.32\textwidth]{graph}}
\end{picture}
\begin{picture}(0.5,0.5)
\put(208,115){\includegraphics[width=0.32\textwidth]{graph_col}}
\end{picture}
\put(85,70){$
\tiny{
\begin{array}{@{\,}l@{~\,}}
\mi{node(1\dotsc 6)};\;\;\;\;\mi{edge(1,2)};\;\;\;\; \dotsc\\[0.35ex]
\mi{col(V,red)}\leftarrow \naf\;\mi{col(V,blue)}, \naf\;\mi{col(V,green)},\mi{node(V)};\\[0.35ex]
\mi{col(V,green)}\leftarrow \naf\;\mi{col(V,blue)},\naf\;\mi{col(V,red)},\mi{node(V)};\\[0.35ex]
\mi{col(V,blue)}\leftarrow \naf\;\mi{col(V,green)},\naf\;\mi{col(V,red)},\mi{node(V)};\\[0.35ex]
\bot\leftarrow \mi{col(V,C)},\mi{col(V,C')},C \neq C';\\[0.35ex]
\bot \leftarrow \mi{col(V,C)},\mi{col(V',C)}, \mi{edge(V,V')}\\[0.35ex]
\end{array}}
$}
 \put(215,0){\tiny{$\begin{array}{@{\,}l@{~\,}}
\mi{node(1\dotsc 6)};\;\;\;\;\mi{edge(1,2)};\dotsc\\ \mi{col(1, red),col(2,blue)},\\ \mi{col(3,red),col(4,green)},\\ \mi{col(6,green),col(5,blue)}\end{array}$}}
}{
\begin{picture}(0.5,0.5)
\put(20,-120){\includegraphics[width=0.86\textwidth]{asp_1}}
\end{picture}
}}
\end{frame}


%\subsection{KG Challenges}
\begin{frame}\frametitle{\alt<2->{Specialities of KGs}{Classical ILP for KGs}}
\bs 

\only<1>{\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{ILP Goal}''The goal of ILP is to develop a correct (and complete) algorithm which efficiently computes hypotheses.'' \cite{DBLP:journals/tocl/Sakama05}
 \end{beamerboxesrounded}}
\bigskip
\bigskip

\only<1>{\begin{beamerboxesrounded}[upper=uppercolred,lower=lowercolred,shadow=true]{Knowledge Graphs}
 But the world knowledge is complex, and this might not always be possible in the context of KGs due to several issues...
 \end{beamerboxesrounded}}


\only<2,3>{\begin{itemize}
\item[] \textbf{\bl{Open World Assumption}}: negative facts cannot be easily derived
\medskip
\pause 

\emph{Maybe Roger Federer is a researcher and Albert Einstein was a ballet dancer?}
\pause
\end{itemize}
\bigskip
\begin{center}
\includegraphics[width=0.86\textwidth]{owa_einstein}
\end{center}}
\end{frame}


%\begin{frame}\frametitle{Rule Induction}
%\alt<2>{\begin{picture}(0.5,0.5)
%\put(20,-190){\includegraphics[width=0.86\textwidth]{asp_4}}
%\end{picture}

%\begin{picture}(0.5,0.5)
%\put(209,-35){\includegraphics[width=0.258\textwidth]{kg0}}
%\end{picture}
% \put(26,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{livesIn(Y,Z)}\leftarrow \mi{isMarried(X,Y)}, \\
% \phantom{\mi{livesIn(Y,Z)}\leftarrow} \mi{livesIn(X,Y)}, \\ \phantom{\mi{livesIn(Y,Z)}\leftarrow}\naf\ \mi{researcher(Y)}\end{array}
% $}}}
%  \put(209,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{\gr{isMarriedTo}(brad,ann)};\\ \mi{\gr{isMarriedTo}(john,kate)};\\ \mi{\gr{isMarriedTo}(bob,alice)};\\ \mi{\gr{isMarriedTo}(clara, dave)}; \\ \mi{\gr{livesIn}(brad,berlin};\\ \dotsc\\ \mi{researcher(alice)};\\ \mi{researcher(dave)}\end{array}$}}}
% }{
%  \begin{picture}(0.5,0.5)
%\put(20,-120){\includegraphics[width=0.86\textwidth]{asp_3}}
%\end{picture}
%}
%\end{frame}


\begin{frame}\frametitle{Challenges of Rule Induction from KGs} 
\begin{itemize}
\item[] \textbf{\bl{Data bias}}: KGs are extracted from text, which typically mentions only popular entities and interesting facts about them.
\medskip

\begin{center}
\emph{\bl{``Man bites dog phenomenon''}}\footnote{\url{https://en.wikipedia.org/wiki/Man_bites_dog_(journalism)}}
\end{center}
\end{itemize}
\bigskip
\begin{center}
\includegraphics[width=0.5\textwidth]{man_bites_dog} 
\end{center}
\end{frame}

\begin{frame}\frametitle{Challenges of Rule Induction from KGs}
\begin{itemize}
\item[] \textbf{\bl{Huge size}}: Modern KGs contain billions of facts \\
\emph{E.g., Google KG stores 70 billion facts}
\end{itemize}
\bigskip
\begin{center}
\includegraphics[width=0.5\textwidth]{hugekg}
\end{center}
\end{frame}

\begin{frame}\frametitle{Challenges of Rule Induction from KGs}
\begin{itemize}
\item[] \textbf{\bl{World knowledge is complex}}, none of its ``models'' is perfect
\end{itemize}
\bigskip
\begin{center}
\includegraphics[width=0.5\textwidth]{noperfectmodel}
\end{center}

\end{frame}

%\subsection{Association Rules}
\begin{frame}\frametitle{Exploratory Data Analysis}
\smallskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Question:}}}
How can we still learn rules from KGs, which do not perfectly fit the data, but still reflect interesting correlations that can predict sufficiently many correct facts?
\end{beamerboxesrounded}
\bigskip

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Answer:}}} Relational association rule mining! Roots in classical datamining.
\end{beamerboxesrounded}

\begin{center}
\includegraphics[width=0.3\textwidth]{eda}
\end{center}
\end{frame}


\begin{frame}\frametitle{Association Rules}
\bigskip

\begin{itemize}
\item \bl{Classical data mining task:} Given a transaction database, find out products (called itemsets) that are frequently bought together and form recommendation rules.
\end{itemize}

%\begin{table}
% \begin{tabular}{| c | c | c | c | c |} 
% \hline
%  $\mi{Apple}$& $\mi{Beer}$& $\mi{Cola}$&$\mi{Donuts}$&$\mi{Eggs}$\\ 
% \hline
% $p1$&&&&\\
% $p2$&&&&\\
% $p3$&&&&\\
% $p4$&&&&\\
% $p5$&&&&\\
% \hline
% \end{tabular}
%\label{table:nonlin} 
%\end{table}
\bs

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{}
\begin{center}
\includegraphics[width=0.3\textwidth]{assrules}

\ms

Out of 4 people who bought apples, 3 also bought beer.
\end{center}
\end{beamerboxesrounded}
\end{frame}


\begin{frame}\frametitle{Some Rule Measures}
%  \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{Def.:} (relative) support and confidence}
% \begin{itemize}
% \item \bl{Support}: frequency of an itemset
% \item \bl{Confidence}: conditional probability of rule head given its body
% \end{itemize}
% \end{beamerboxesrounded}
% \bs

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\bl{Support, confidence, lift}}
\begin{columns}
\begin{column}{0.23\textwidth}
\includegraphics[width=2\textwidth]{supp}

\uncover<2->{\includegraphics[width=2.5\textwidth]{conf}}

\uncover<3->{\includegraphics[width=2.5\textwidth]{lift}}
\end{column}
\begin{column}{0.77\textwidth}
\rightline{
\includegraphics[width=0.44\textwidth]{assrules}
}
\end{column}
\end{columns}
\end{beamerboxesrounded}
\end{frame}

%\subsection{Relational Association Rules}

\begin{frame}\frametitle{Frequent Itemset Mining}
\begin{itemize}
\item A=apple, B=beer... Frequent patterns are in green.
\item Monotonicity: any superset of an infrequent pattern is infrequent\\
At the heart of Apriori algorithm
\end{itemize}
\begin{center}
\includegraphics[width=1\textwidth]{apriori}
\end{center}
\end{frame}


\begin{frame}\frametitle{How to Apply this to Relational Data?}
\begin{itemize}
\item \bl{DOWNGRADING DATA}: Can we change the
representation from richer representations to simpler
ones? (So we can use systems working with simpler
representations)\bs \bs

\item \bl{UPGRADING SYSTEMS}: Can we develop systems that work
with richer representations (starting from systems for
simpler representations)?
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Downgrading the Data}
\begin{itemize}
\item \textbf{\bl{Propositionalization}} \cite{propos}: transform a KG into a transaction database
\end{itemize}
\small{\begin{table}
\begin{tabular}{| c | c | c | c | c | c |} 
\hline
& \gre{$\mi{bornInUS}$}& \gre{$\mi{livesInUS}$}&\gre{$\mi{isMarriedToSinger}$} &$\mi{researcher}$&$\mi{sportsman}$ \\ [0.5ex]  
\hline 
$\mi{p1}$ & \gre{$\checkmark$} & \gre{$\checkmark$}  &  & & \gre{$\checkmark$}\\
[1.5ex] 
$\mi{p2}$ &\gre{$\checkmark$}  & \gre{$\checkmark$}  &  &\gre{$\checkmark$}&  \\
[1.5ex]
$\mi{p3}$ & \gre{$\checkmark$} & \gre{$\checkmark$} &  & & \\
[1.5ex]
$\mi{p4}$ & \gre{$\checkmark$}  & \gre{$\checkmark$}   &  &  &\\
[1.5ex]
$\mi{p5}$ & \gre{$\checkmark$}  &   & \gre{$\checkmark$}  & &\\
[1.5ex]
$\mi{p6}$ & \gre{$\checkmark$}  &   &\gre{$\checkmark$}   &  & \gre{$\checkmark$}\\
[1.5ex]
$\mi{p7}$ & \gre{$\checkmark$}  &   &  &\gre{$\checkmark$}  & \\
[1.5ex]
$\mi{p8}$ & \gre{$\checkmark$}  &\gre{$\checkmark$}   &   & &  \\
\end{tabular}
\label{table:nonlin} 
\end{table}}
\end{frame}



\begin{frame}\frametitle{Upgrading the Systems}
\begin{itemize}
\item Start from existing system for simpler 
representation
\bs
\bs 

\item Extend it for use with richer representation 
(while trying to keep the original system as a 
special case)
\end{itemize}
\end{frame}




\begin{frame}\frametitle{Relational Association Rule Mining}
\begin{itemize}
\item \bl{WARMER} \cite{warmer}
\item Upgrade frequent itemsets to frequent conjunctive queries
\uncover<2->{\begin{itemize}
\item traverse the lattice 
\item get frequent CQs based on user-specified value
\item split into body and head
\item rank based on a rule measure, e.g., confidence
\end{itemize}}
\end{itemize}
\bs

\alt<2->{\begin{center}
\includegraphics[width=.8\textwidth]{cq_lattice}
\end{center}}{\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}
\gre{CQ: return all people with their spouses and living places}
\begin{center}
$q_1(X,Y,Z):-\mi{isMarriedTo(X,Y) \wedge livesIn(X,Z)}$
\end{center} 

\gre{Output}: 6 tuples, i.e., $\mi{supp(q_1)=6}$ 
\bs

\gre{CQ: return all people with their spouses and living places}
\begin{center}
$q_2(X,Y,Z):- \mi{isMarriedTo(X,Y) \wedge livesIn(X,Z) \wedge livesIn(Y,Z)}$
\end{center} 

\gre{Output}: 3 tuples, i.e., $\mi{supp(q_2)=3}$ 
\end{beamerboxesrounded}}
\end{frame}

\begin{frame}\frametitle{Horn Rule Mining from KGs}
\smallskip
\begin{center}
\alt<4->{\bl{AMIE} \cite{amie}: PCA confidence\\PCA: If at least 1 living place of Alice is known, then all are known.}{\bl{WARMER}: confidence \\CWA: Whatever is not known is false.}
\end{center}
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip

\alt<4->{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg1_pca}}\end{picture}}{
\alt<3->{
\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg2}}\end{picture}
}{\alt<2->{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg1}}\end{picture}}{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg0}}\end{picture}}}}
\begin{center}
\visible<2->{\rightline{\gr{$\mi{conf(r)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=$\alt<4>{$\dfrac{2}{3}$}{$\dfrac{2}{4}$}}}}
\bigskip

\uncover<2->{\normalsize{\textcolor{darkgreen}{$r:\;\mi{livesIn(X,Z)}\leftarrow \mi{isMarriedTo(Y,X),livesIn(Y,Z)}$}}}
 \end{center}

\end{frame}

\begin{frame}\frametitle{AMIE}

\bl{\textbf{Language bias:}} \bl{safe} and \bl{closed} rules 
\begin{itemize}
\item[] \bl{safe:} every head variable must appear in the body
\item[] \bl{closed:} every variable must appear in at least two atoms
\end{itemize}
\bs
\bs
\pause

\bl{\textbf{Algorithm steps:}}

\begin{itemize}
\item maintain a rule queue, starting from an empty rule
\bigskip

\item for each rule:
\begin{itemize}
\item[1.] process the rule \\
\uncover<2->{- compute statistics: \bl{$\mi{supp, conf_{PCA}}$}\\
- filter rules based on statistics and output rule}
\bigskip

\item[2.] extend the queue by applying refinement operators\\
\uncover<3->{- add dangling atom\\
- add closing atom\\
- add instantiated atom (with constant)}
\end{itemize}

\end{itemize}
\end{frame}



\begin{frame}\frametitle{Refinement Operators}
%\begin{picture}(0.5,0.5)\put(-30,-100){
%\alt<3->{\includegraphics[width=1\textwidth]{figures/refinement_operators2}}{\alt<2->{\includegraphics[width=1\textwidth]{figures/refinement_operators1}}{\includegraphics[width=1\textwidth]{figures/refinement_operators0}}}}
%\end{picture}
\begin{picture}(0.5,0.5)\put(-52,-130){
\leftline{\includegraphics[width=1.3\textwidth]{refinement_operators_amie}}
}
\end{picture}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\end{frame}




\begin{frame}\frametitle{Other Related Works}
\begin{itemize}
\item \bl{RDF2Rules} \cite{rdf2rules}
\begin{itemize}
\item Optimized for cycles (even more restricted language bias)
\end{itemize}
\bs
\bs

\item \bl{Ontology path finding} \cite{op}
\begin{itemize}
\item Parallelizations of the rule evaluation stage
\end{itemize}
\bs

\item \bl{Comparison of rule measures for KGs} \cite{metrics-summary}
\bs

\item \bl{Neural-based rule mining methods} \cite{DBLP:conf/nips/YangYC17}
\begin{itemize}
\item reduce the rule learning problem to algebraic operations
on neural-embedding-based representations of a given KG
\end{itemize}
\end{itemize}
\end{frame}





\section{Exception-awareness}
\begin{frame}\frametitle{Nonmonotonic Rule Mining}
\smallskip

\bl{Nonmonotonic rule mining} from KGs: \alert{OWA} is a challenge!
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip
 \bigskip

\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg3}}\end{picture}

%\visible<2->{\rightline{\gr{$\mi{conf(r)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=$\alt<4>{$1$}{$\dfrac{2}{4}$}}}}
\bigskip
\bigskip
\begin{center}
\normalsize{\gre{$r:\;\mi{livesIn(X,Z)}\leftarrow \mi{isMarriedTo(Y,X),livesIn(Y,Z)},$}\,\alert{$\naf\ researcher(X)$}}
 \end{center}

\end{frame}




% \begin{frame}\frametitle{Nonmonotonic Rule Mining}
% \alt<2>{\begin{picture}(0.5,0.5)
% \put(20,-190){\includegraphics[width=0.86\textwidth]{asp_4}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(209,-35){\includegraphics[width=0.258\textwidth]{kg0}}
% \end{picture}
% \put(26,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{livesIn(Y,Z)}\leftarrow \mi{isMarried(X,Y)}, \\
% \phantom{\mi{livesIn(Y,Z)}\leftarrow} \mi{livesIn(X,Y)}, \\ \phantom{\mi{livesIn(Y,Z)}\leftarrow}\naf\ \mi{researcher(Y)}\end{array}
% $}}}
%  \put(209,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{\gr{isMarriedTo}(brad,ann)};\\ \mi{\gr{isMarriedTo}(john,kate)};\\ \mi{\gr{isMarriedTo}(bob,alice)};\\ \mi{\gr{isMarriedTo}(clara, dave)}; \\ \mi{\gr{livesIn}(brad,berlin};\\ \dotsc\\ \mi{researcher(alice)};\\ \mi{researcher(dave)}\end{array}$}}}
% }{\begin{picture}(0.5,0.5)
% \put(20,-120){\includegraphics[width=0.86\textwidth]{asp_3}}
% \end{picture}}
% \end{frame}


\begin{frame}\frametitle{Horn Theory Revision}
\bigskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Quality-based Horn Theory Revision}}}

 \smallskip

 \textbf{Given:} 
 \begin{itemize}
 \item Available KG 
\uncover<2->{ \item Horn rule set}
 \end{itemize}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

 \uncover<3->{\noindent \textbf{Find:} }
 \begin{itemize}
\uncover<3->{ \item Nonmonotonic revision of Horn rule set}\uncover<4->{\\ with better 
 predictive quality}
 \end{itemize}
 \end{beamerboxesrounded}
\begin{picture}(0.5,0.5)\put(143,45){\alt<4>{\includegraphics[width=0.58\textwidth]{big_pic_4}}{\alt<3>{\includegraphics[width=0.58\textwidth]{big_pic_3}}{\alt<2>{\includegraphics[width=0.58\textwidth]{big_pic_2}}{\includegraphics[width=0.58\textwidth]{big_pic_1}}}}}\end{picture}
\end{frame}

\begin{frame}\frametitle{Avoid Data Overfitting}
\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{How to distinguish exceptions from noise?}\bigskip

\small{$
            \renewcommand{\arraystretch}{1.1}
             \begin{array}{@{\,}l@{~~}l@{}}
               \mi{\gr{r1:\,livesIn(X,Z) \leftarrow isMarriedTo(Y,X),livesIn(Y,Z),}\, \alert{\naf\ researcher(X)}}\\
              \visible<2->{\phantom{r1:\,}\mi{\,not\_livesIn(X,Z) \leftarrow isMarriedTo(Y,X),livesIn(Y,Z),researcher(X)}\\[2.75ex]}
              \visible<3->{\mi{\gr{r2:\,livesIn(X,Z)\leftarrow bornIn(X,Z),\,}\alert{\naf\ moved(X)}}}\\
              \visible<3->{\phantom{r1:\,}\mi{\,not\_livesIn(X,Z)}\leftarrow bornIn(X,Z),moved(X)}
             \end{array}$\bigskip

\uncover<4>{$\{\gr{\mi{livesIn(c,d)}},\mi{not\_livesIn(c,d)}\}$ are conflicting predictions\bigskip

\textbf{Intuition:} Rules with good exceptions should make few conflicting predictions
}}
\end{beamerboxesrounded}
\end{frame}

\begin{frame}\frametitle{Horn Theory Revision}

\bigskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Quality-based Horn Theory Revision}}}

 \smallskip

 \textbf{Given:} 
 \begin{itemize}
 \item Available KG 
 \item Horn rule set
 \end{itemize}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

 \noindent \textbf{Find:} 
 \begin{itemize}
 \item Nonmonotonic revision of Horn rules, such that \\
\begin{itemize}
\item number of \bl{conflicting predictions} is \textbf{minimal} \smallskip

\item average \bl{conviction} %$\mi{conv(r,\text{KG})=\dfrac{1-supp(r,\text{KG})}{1-conf(r,\text{KG})}}$ 
is \textbf{maximal}
\end{itemize}
 \end{itemize}
 \end{beamerboxesrounded}
\begin{picture}(0.5,0.5)\put(143,68){\includegraphics[width=0.58\textwidth]{big_pic_4}}\end{picture}
%\textcolor{gray}{\tiny{M. Gad-Elrab, D. Stepanova, J. Urbani, G. Weikum. Exception-enriched Rule Learning from Knowledge Graphs, ISWC 2016}}

\tiny{M. Gad-Elrab, D. Stepanova, J. Urbani, G. Weikum. Exception-enriched Rule Learning from Knowledge Graphs. \emph{ISWC2016}}\\
\tiny{D. Tran{,}\,D. Stepanova{,}\,M. Gad-Elrab{,}\,F. Lisi{,}\,G. Weikum. Towards Nonmonotonic Relational Learning from KGs{.}\,\emph{ILP2016}}
\end{frame}

\begin{frame}\frametitle{Nonmonotonic Rule Mining from KGs}
\bl{\textbf{Goal:}} learn nonmonotonic rules from KG\\
\bl{\textbf{Approach:}} revise association rules learned using data mining methods
\medskip

\includegraphics[width=1.02\textwidth]{nmlearn}

\end{frame}

\begin{frame}\frametitle{Approach Description}
\begin{center}
\includegraphics[width=.8\textwidth]{approach}
\end{center}
\end{frame}


\begin{frame}\frametitle{Exception Candidates}
\begin{picture}(0.5,0.5)\put(40,-183,5){\includegraphics[width=0.75\textwidth]{kg_advanced3}}
\end{picture}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip


\leftline{\gr{$r{:}\,\mi{livesIn(X,Z)}\,{\leftarrow}\, \mi{isMarriedTo(Y,X)\,{,}\,livesIn(Y,Z)}$}}
\FrameText{\alert{$\left\{\begin{array}{@{}l@{}}
 \mbox{}\small{\mi{{\naf}\,researcher(X)}}\\
\mbox{}\small{\mi{{\naf}\,artist(Y)}}\end{array}\right\}$}}
\end{frame}



\begin{frame}\frametitle{Exception Ranking}

\begin{center}
$\mi{\gr{rule1}\;\;\; \alert{\{\underline{\mathbf{e_1}},e_2,e_3, \dotsc\}}}$\\
 $\mi{\gr{rule2}\;\;\; \alert{\{e_1,\underline{\mathbf{e_2}},e_3, \dotsc\}}}$\\
 $\mi{\gr{rule3}\;\;\; \alert{\{\underline{\mathbf{e_1}},e_2,e_3, \dotsc\}}}$\\
\end{center}

\begin{beamerboxesrounded}[upper=uppercolred,lower=lowercolred,shadow=true]{}
\small{Finding globally best revision is expensive, exponentially many candidates!}
\end{beamerboxesrounded}
\begin{itemize}


\item \bl{Naive ranking:} for every rule inject exception that results in the highest conviction
\medskip

\item \bl{Partial materialization (PM):} apply all rules apart from a given one, inject exception that results in the highest average conviction of the rule and its rewriting

% \only<2>{
% $\gr{r1 \dotsc \dotsc \dotsc} \{\alert{\underline{\mathbf{e_1}},e_2,e_3, \dotsc}\}$\\
% \hilight{$\gr{r2 \dotsc \dotsc \dotsc} \{\alert{e_1,e_2,e_3, \dotsc}\}$\\
% $\gr{r3 \dotsc \dotsc \dotsc} \{\alert{e_1,e_2,e_3, \dotsc}\}$\\}}

\medskip

\item \bl{Ordered PM (OPM):} same as PM plus ordered rules application
\medskip

\item \bl{Weighted OPM:} same as OPM plus weights on predictions
\end{itemize}
\bigskip

\end{frame}

\begin{frame}\frametitle{Experiments}
\vspace{-.4cm}
\begin{itemize}
\item \bl{Approximated ideal KG}: original KG 
\smallskip

\item \bl{Available KG}: for every relation randomly remove 20\% of facts from approximated ideal KG
\smallskip

\item \bl{Horn rules}: $\mi{h(X,Y)\leftarrow p(X,Z),q(Z,Y)}$ 
\smallskip

\item \bl{Exceptions}: $\mi{e_1(X),e_2(Y),e_3(X,Y)}$
\smallskip

\item \bl{Predictions} are computed using \bl{answer set solver} DLV % \footnote{\tiny{\url{http://dlvsystem.com}}}
\end{itemize}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\bigskip
\bigskip

\visible<1>{\begin{picture}(0.5,0.5)\put(55,63){\includegraphics[width=0.75\textwidth]{big_pic_exp}}
\end{picture}}

\visible<2>{\vspace{-5,5cm}\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\textbf{Examples of revised rules:}}

 \begin{tabular}{l}
\footnotesize{

Plots of films in a sequel are written by the same writer, unless a film is American}\\
        \footnotesize{$\gr{r_1:  \mi{writtenBy(X, Z)}  \leftarrow
        \mi{hasPredecessor(X, Y)},\mi{writtenBy(Y, Z)},}$ \alert{$ not$  $\mi{american\_film(X)} $}}\\   
\\     
\footnotesize{
Spouses of film directors appear on the cast, unless they are silent film actors
}\\
      \footnotesize{ 
$\gr{r_2:  \mi{actedIn(X, Z)}  \leftarrow
        \mi{isMarriedTo(X, Y)},\mi{directed(Y, Z)},}$ \alert{$ not$  $\mi{silent\_film\_actor(X)} $}} \\
    
 \end{tabular} 
\end{beamerboxesrounded}      }



\end{frame}

\section{Incompleteness}

% \begin{frame}\frametitle{Reasonable Rules}
% \bigskip

% \uncover<2->{
% \small{\emph{\gr{ \uncover<3->{$\checkmark$} People with the same parents are likely siblings}}}
% }

% \uncover<4->{\alt<4>{
% \bl{Standard confidence}
% }{
% \small{\bl{PCA confidence}}}}
% \uncover<5->{\cite{amie}}

% \alt<-2>{
% \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl1}}\end{picture}
% }{\alt<3>{
% \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl3}}\end{picture}
% }{
% \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl2}}\end{picture}
% }}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<4->{\rightline{\gr{$\mi{conf(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}$}}}
% \bigskip

% \uncover<5->{
% \rightline{\gr{$\mi{conf_{pca}(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasChild}(Z, \_)\in \cG\}|}}=\dfrac{2}{2}$}}}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<2->{\centerline{\gr{$\mi{r_1:\;hasSibling(Z,Y) \leftarrow hasChild(X,Y),hasParent(Z,X)}$}}}
% \bigskip
% \end{frame}


% \begin{frame}\frametitle{Erroneous Rules due to Data Bias}
% \bigskip

% \uncover<2->{
% \small{\emph{\uncover<3->{\textbf{\huge{\alert{$\times$}}}}\normalsize{\gr{People working and studying at the same institute are likely relatives}}}}
% }

% \alt<1>{\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works0}}
% \end{picture}}{\alt<2>{\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works2}}
% \end{picture}}{\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works1}}
% \end{picture}}}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<3->{\rightline{$\gr{\mi{conf(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}}$}}
% \bigskip

% \uncover<3->{\rightline{$\gr{\mi{conf_{pca}(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasSibling}(Z, \_)\in \cG\}|}}=\dfrac{2}{2}}$}}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<2->{\centerline{\gr{$\mi{r_2:\;hasChild(X,Z)\leftarrow worksAt(X,Y),educatedAt(Z,Y)}$}}}

% \end{frame}

\begin{frame}\frametitle{Reasonable Rules}
\bigskip

\uncover<3->{
\small{\emph{\gr{ \uncover<3->{$\checkmark$} People with the same parents are likely siblings}}}
}

%\uncover<5->{\alt<5>{
%\begin{center}\bl{CWA}\end{center}
%}{
%\begin{center}\small{\bl{PCA}}\end{center}}}

\alt<1>{
\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl1}}\end{picture}
}{\alt<-3>{
\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl4}}\end{picture}
}{\alt<4>{
\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl3}}\end{picture}
}{
\begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_sibl2}}\end{picture}
}}}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<5->{\rightline{\gr{$\mi{conf(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}$}}}
\bigskip

\uncover<6->{
\rightline{\gr{$\mi{conf_{pca}(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasSibling}(X, \_)\in \cG\}|}}=\dfrac{2}{2}$}}}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<3->{\centerline{\gr{$\mi{r_1:\;hasSibling(X,Z) \leftarrow hasParent(X,Y),hasChild(Y,Z)}$}}}
\bigskip
\end{frame}


\begin{frame}\frametitle{Erroneous Rules due to Data Bias}
\bigskip

\uncover<3->{
\small{\emph{\uncover<3->{\textbf{\huge{\alert{$\times$}}}}\normalsize{\gr{If one is studying in a university where you teach, he/she is your child}}}}
}

\alt<1>{
  \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works0}}\end{picture}
}{\alt<-3>{
  \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works3}}\end{picture}
}{\alt<4>{
  \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works2}}\end{picture}
}{
  \begin{picture}(0.5,0.5)\put(-5,-145){\includegraphics[width=.6\textwidth]{kg_works1}}
\end{picture}
}}}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<5->{\rightline{$\gr{\mi{conf(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}}$}}
\bigskip

\uncover<5->{\rightline{$\gr{\mi{conf_{pca}(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasChild}(X, \_)\in \cG\}|}}=\dfrac{2}{2}}$}}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<3->{\centerline{\gr{$\mi{r_2:\;hasChild(X,Z)\leftarrow worksAt(X,Y),educatedAt(Z,Y)}$}}}

\end{frame}





\begin{frame}\frametitle{Exploiting Meta-data in Rule Learning}
\bigskip

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]
{}\begin{center}\textbf{\bl{Goal:}} make use of cardinality constraints on edges of the KG to improve rule learning. \end{center}
\end{beamerboxesrounded}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip\bigskip
\bigskip
\bigskip
\bigskip

\bigskip
\bigskip
\bigskip

\begin{picture}(0.5,0.5)\put(40,-10){\includegraphics[width=0.83\textwidth]{problem_pic}}
\end{picture}
\bigskip
\bigskip

\tiny{T. Pellissier-Tanon, D. Stepanova, S. Razniewski, P. Mirza, G. Weikum. Completeness-aware rule learning from KGs. \emph{ISWC2017}.}

\end{frame}

\begin{frame}\frametitle{Cardinality Statements}

\begin{itemize}
\item \bl{$\mi{num(p, s)}$}: Number of outgoing \bl{$p$}-edges from \bl{$s$} in the ideal KG
\item \bl{$\mi{miss(p,s)}$}: Number of missing \bl{$p$}-edges from \bl{$s$} in the available KG
\item If \bl{$\mi{miss(p,s)}=0$}, then \bl{$\mi{complete(p,s)}$}, otherwise \bl{$\mi{incomplete(p,s)}$}
\end{itemize}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\begin{columns}
\begin{column}{0.59\textwidth}
\begin{picture}(0.5,0.5)\put(10,-57){\includegraphics[width=\textwidth]{ex1}}\end{picture}
\end{column}
\begin{column}{0.39\textwidth}
\gr{$\mi{\;\;num(hasChild, john)=3}$}\\
\gr{$\mi{\;\;miss(hasChild,john)=1}$}\\
\gr{$\mi{\;\;incomplete(hasChild,john)}$}
\end{column}
\end{columns}
\end{frame}


\begin{frame}\frametitle{Cardinality Constraints on Edges}
\begin{itemize}
\item \bl{Mining cardinality assertions from the Web} \cite{cardinality-extraction-iswc-2016}
\begin{itemize}
\item \emph{\textcolor{darkgreen}{``... John has \textbf{2} children ...''}}
\end{itemize}
\bigskip


\item \bl{Estimating recall of KGs by crowd sourcing} \cite{whatknow}
\begin{itemize}
\item \emph{\textcolor{darkgreen}{20 \% of Nobel laureates in physics are missing}}
\end{itemize}
\bigskip

\item \bl{Predicting completeness in KGs} \cite{galarragapredicting}
\begin{itemize}
\item \gr{Add $\mi{complete(john,hasChild)}$ to KG and mine rules}
\\\emph{\textcolor{darkgreen}{$\mi{complete(X, hasChild) \leftarrow child(X)}$}}
\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Related Work}
\begin{picture}(0.5,0.5)\put(2,-120){\includegraphics[width=1.01\textwidth]{relwork}}
\end{picture}
\end{frame}


\begin{frame}\frametitle{Prediction Post-processing}
Remove predictions in complete KG parts \small{\cite{galarragapredicting}}, \\
\small{i.e., constraints are set on the output not the input}

\alt<3->{\begin{picture}(0.5,0.5)\put(35,-170){\includegraphics[width=0.75\textwidth]{complapp_1_3}}
\end{picture}}{\alt<2>{\begin{picture}(0.5,0.5)\put(35,-170){\includegraphics[width=0.75\textwidth]{complapp_1_2}}
\end{picture}}{\begin{picture}(0.5,0.5)\put(35,-170){\includegraphics[width=0.75\textwidth]{complapp_1_1}}
\end{picture}}}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\uncover<4>{
\begin{beamerboxesrounded}[upper=uppercolred,lower=lowercolred,shadow=true]
{}\begin{center}\textbf{\alert{Rules}} might be still \textbf{\alert{erroneous}}.. What about other incorrect predictions? \end{center}
\end{beamerboxesrounded}
}

\end{frame}

 

\begin{frame}\frametitle{Problem Statement}
\bl{\textbf{Given:}} 
\begin{itemize}
\item KG
\item numerical statements
\end{itemize}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip 
\bigskip 


\bl{\textbf{Find:}} \textbf{\gr{rules}} which predict
\begin{itemize}
\item ``few'' facts in \textbf{\textcolor{gray}{complete areas}}
\item ``many'' facts in \textbf{\textcolor{gray}{incomplete areas}}
\end{itemize}
\begin{picture}(0.5,0.5)\put(162,22){\includegraphics[width=0.55\textwidth]{compl1}}\end{picture}
\bigskip
\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]
{}\begin{center}\textbf{\bl{Intuition:}} rank rules by taking into account numerical constraints on edge counts  in the ideal KG\end{center}
\end{beamerboxesrounded}
\end{frame}
\begin{frame}\frametitle{Rule Predictions}
\bl{$\mi{npi}(r)$}: number of facts added to incomplete areas by $r$

\bl{$\mi{npc}(r)$}: number of facts added to complete areas by $r$

\uncover<2->{
\begin{picture}(0.5,0.5)\put(-13,-165){\includegraphics[width=.6\textwidth]{kg_siblmiss}}
\end{picture}

\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<3->{
	\rightline{\gr{$npi(r_1) = 1$}}
    \rightline{\gr{$npc(r_1) = 0$}}
}


\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\uncover<3->{\centerline{\gr{$\mi{r_1:\;hasSibling(Z,Y) \leftarrow hasChild(X,Y),hasParent(Z,X)}$}}}
}
\end{frame}

\begin{frame}\frametitle{Completeness Confidence}
\bl{$\mi{conf_{comp}}$}: do not penalize rules that predict new facts in incomplete areas

\begin{center}
\large{$$\bl{\mi{conf_{comp}(r)=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|-\mi{npi}(r)}}}$$}
\end{center}

\vfill

\begin{itemize}
\item Generalizes standard confidence ($miss(r) = 0$)
\item Generalizes PCA confidence ($miss(r) \in \{ 0, +\infty\}$)
\end{itemize}

\end{frame}


\begin{frame}\frametitle{Completeness Confidence Example 1}

\begin{picture}(0.5,0.5)\put(-13,-165){\includegraphics[width=.6\textwidth]{kg_siblmiss}}
\end{picture}

\bigskip
\bigskip
\bigskip
\bigskip

\bigskip
\bigskip
 \uncover<2->{\rightline{\gr{$\mi{conf(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}$}}}
 \bigskip

 \uncover<2->{\rightline{\gr{$\mi{conf_{pca}(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasSibling}(Z, \_)\in \cG\}|}}=\dfrac{2}{2}$}}}

\bigskip
\uncover<3->{\rightline{\gr{$npi(r_1) = 1$}}}
\bigskip

\uncover<3->{\rightline{\gr{$\mi{conf_{comp}(r_1)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}| - npi(r_1)}=\dfrac{2}{3}$}}}

\bigskip
\uncover<2->{\centerline{\gr{$\mi{r_1:\;hasSibling(X,Z) \leftarrow hasParent(X,Y),hasChild(Z,X)}$}}}
\end{frame}

\begin{frame}\frametitle{Completeness Confidence Example 2}
\bigskip

\gr{$miss(hasChild, Alice) = 0$}

\begin{picture}(0.5,0.5)\put(-10,-135){\includegraphics[width=.6\textwidth]{kg_works1}}
\end{picture}

\bigskip
\bigskip
\bigskip
\uncover<2->{\rightline{\gr{$\mi{conf(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=\dfrac{2}{4}$}}}
\bigskip

\uncover<2->{\rightline{\gr{$\mi{conf_{pca}(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{{\scriptstyle |\{\mytriangle{black}{white} \mid \mi{hasChild}(Z, \_) \in \mathcal{G}\}|}}=\dfrac{2}{2}$}}}

\bigskip
\uncover<3->{\rightline{\gr{$npi(r_2) = 0$}}}
\bigskip

\uncover<3->{\rightline{\gr{$\mi{conf_{comp}(r_2)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}| - npi(r_2)}=\dfrac{2}{4}$}}}

\bigskip
\uncover<2->{\centerline{\gr{$\mi{r_2:\;hasChild(X,Z)\leftarrow worksAt(X,Y),educatedAt(Z,Y)}$}}}
\end{frame}

\begin{frame}\frametitle{Other Completeness-aware Measures}
\bigskip

\bl{$\mi{precision_{comp}:}$} penalize $r$ that predict facts in complete areas
\begin{center}
 \bl{$\mi{precision_{comp}(r)} = 1 - \dfrac{\mi{npc}(r)}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}$ }
\end{center}
\bigskip

\bl{$\mi{recall_{comp}:}$} ratio of missing facts filled by $r$
\begin{center}
\bl{ $\mi{recall_{comp}(r)} = \dfrac{\mi{npi}(r)}{\sum_s \mi{miss}(h, s)}$ }
\end{center}
\bigskip

\bl{$\mi{dir\_metric:}$} proportion of predictions in complete and incomplete parts
\begin{center}
 \bl{$\mi{dir\_metric}(r) = \dfrac{\mi{npi}(r)-\mi{npc}(r)}{2\cdot(\mi{npi}(r)+\mi{npc}(r))}+0.5$}
\end{center}
\bigskip

\bl{$\mi{wdm}:$} weighted combination of confidence and directional metric
\begin{center}
 \bl{$\mi{wdm}(r) = \beta \cdot \mi{conf}(r) + (1-\beta) \cdot \mi{dir\_metric}(r)$}
\end{center}
\end{frame}


\begin{frame}\frametitle{Experimental Setup}

\bl{2 Datasets:}
\begin{itemize}
\item WikidataPeople: 2.4M facts over 9 predicates from Wikidata
\item LUBM: Synthetic 1.2M facts
\end{itemize}
\smallskip

\uncover<1->{
\bl{Creation of ideal KG:}
\begin{itemize}
\item WikidataPeople: using hand made rules
\item LUBM: using the OWL ontology
\end{itemize}
}
\smallskip

\uncover<1->{
\bl{Steps:}
\begin{itemize}
\item Generate $num(p,x)$ using the ideal KG
\item Remove triples randomly to create the available KG
\item Mine $r(X,Z) \leftarrow p(X,Y), q(Y,Z)$ rules
\item Gold standard: ratio of facts generated in the ideal KG
\end{itemize}
}

\end{frame}


\begin{frame}\frametitle{Experimental Evaluation}
\begin{center}
\includegraphics[width=\textwidth]{graph2}
\end{center}
\end{frame}


% \begin{frame}\frametitle{Cardinality statements mining}

% \begin{itemize}
% \item Introduce $p_{\geq k}(s)$ and $p_{\leq k}(s)$ for each $num(p,s)$
% \item Introduce $p_{\geq |\{ o \mid (s,p,o) \in \mathcal{G}|}(s)$ for all $p$ and $s$
% \item Use the background rules $p_{\geq k}(s) \leftarrow p_{\geq k+1}(s)$ and $p_{\leq k+1}(s) \leftarrow p_{\leq k}(s)$.
% \item Mine rules which head is a $p_{\_}(\_)$
% \item Complete the $\mathcal{G}$ with a confidence threshold
% \item if $p_{\geq k}(s) \in \mathcal{G}_c$ and $p_{\leq k}(s) \in \mathcal{G}_c$ then $num(p,s)=k$
% \end{itemize}
% \end{frame}

% \begin{frame}\frametitle{Completeness precision and recall}

% We define a precision and a recall:
% \begin{itemize}
% \item[] $\mi{precision_{comp}(r)} = 1 - \frac{\mi{npc}(r)}{\mi{supp}(\mathbf{B})}$ (ratio of "complete" results)
% \item[] $\mi{recall_{comp}(r)} = \frac{\mi{npi}(r)}{\sum_s \mi{miss}(h, s)}$ (ratio of "incomplete" results filled)
% \end{itemize}
% \end{frame}


% \begin{frame}\frametitle{Example with precision and recall}
% \begin{picture}(0.5,0.5)\put(15,-170){\includegraphics[width=.6\textwidth]{kg_sibl2}}
% \end{picture}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<2->{\rightline{\bl{$npi(r) = 1$ $npc(r) = 0$}}}
% \uncover<3->{\rightline{\gr{$\mi{precision_{comp}(r)}=1 - \frac{0}{4}=1$}}}
% \uncover<4->{\rightline{\gr{$\mi{recall_{comp}(r)}=\frac{1}{2}$}}}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \centerline{\gr{$\mi{r:\;hasSibling(Z,Y) \leftarrow hasChild(X,Y),hasParent(Z,X)}$}}
% \centerline{\bl{$miss(hasSibling, Mary) = 2$}}
% \end{frame}

% \begin{frame}\frametitle{Directional metric}
% \begin{itemize}
% \item[] $\mi{dir\_metric}(r) = \dfrac{\mi{npi}(r)-\mi{npc}(r)}{2\cdot(\mi{npi}(r)+\mi{npc}(r))}+0.5$
% \item<2->[] \bl{Weighted:} $\mi{wdm}(r) = \beta \cdot \mi{conf}(r) + (1-\beta) \cdot \mi{dir\_metric}(r)$
% \end{itemize}
% \end{frame}

% \begin{frame}\frametitle{Example with directional metric}
% \begin{picture}(0.5,0.5)\put(15,-170){\includegraphics[width=.6\textwidth]{kg_sibl2}}
% \end{picture}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \uncover<2->{\rightline{\bl{$npi(r) = 1$ $npc(r) = 0$}}}
% \uncover<3->{\rightline{\gr{$\mi{dir\_metric}(r) = \frac{1-0}{2\cdot (1+0)}+0.5= 1$}}}
% \uncover<4->{
% 	\rightline{\gr{$\mi{wdm}(r) = 0.5 \cdot \frac{2}{4} + 0.5 \cdot 1 = \frac{3}{4}$}}
% 	\rightline{$\beta = 0.5$}
% }
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \centerline{\gr{$\mi{r:\;hasSibling(Z,Y) \leftarrow hasChild(X,Y),hasParent(Z,X)}$}}
% \centerline{\bl{$miss(hasSibling, Mary) = 2$} $\beta = 0.5$}
% \end{frame}


\section{Rules from Hybrid Sources}
\begin{frame}\frametitle{Knowledge Graph Completion}
 \begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolbl,shadow=true]{}
\begin{itemize}
\item \textbf{Given:} a KG, i.e., set of \bl{$\tuple{s\;p\;o}$} facts and possibly text
\item \textbf{Find:} missing \bl{$\tuple{s\;p\;o}$} facts
\end{itemize}
\end{beamerboxesrounded}
\bigskip
\pause

\begin{columns}
\begin{column}{.5\textwidth}
 \begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolbl,shadow=true]{\begin{center}\small{\textbf{Rule-based approaches}}\end{center}}
\smallskip
\begin{center}
  \alt<3->{\includegraphics[width=\linewidth]{rule-based2}}{\includegraphics[width=\linewidth]{rule-based}}
\medskip

\tiny{
AMIE \cite{amie}, \\ RUMIS \cite{rumis}, CARL \cite{carl}, etc.
}
\end{center}
 \end{beamerboxesrounded}
\end{column}
\pause
\pause
\begin{column}{.5\textwidth}
 \begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolbl,shadow=true]{\begin{center}\small{\textbf{Statistics-based approaches}}\end{center}}


\bigskip

\alt<6->{\includegraphics[width=\linewidth]{statistics-based3}}{\alt<5->{\includegraphics[width=\linewidth]{statistics-based2}}{\includegraphics[width=\linewidth]{statistics-based1}}}
\medskip
\begin{center}
\tiny{TransE \cite{transe}, TEKE \cite{teke},\\ RESCAL \cite{rescal}, etc.}
\end{center}
\end{beamerboxesrounded}


\end{column}

\end{columns}
\end{frame}

\begin{frame}\frametitle{Motivation}
\medskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{\begin{center}\small{\bl{\textbf{Goal:}} Combine available techniques into a hybrid method}\end{center}}
\bigskip

\begin{columns}
\begin{column}{.4\textwidth}
 \begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolbl,shadow=true]{\begin{center}\small{\textbf{Rule-based approaches}}\end{center}}
\medskip

\begin{itemize}
\item[\bl{+}] \bl{Interpretable}
\item[\bl{+}] \bl{Limited training data}
\item[\alert{-}] \alert{Local patterns}
\item[\alert{-}] \alert{Not extendable}
\end{itemize}
 \end{beamerboxesrounded}
\end{column}

\begin{column}{.4\textwidth}
 \begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolbl,shadow=true]{\begin{center}\small{\textbf{Statistics-based approaches}}\end{center}}
\medskip

\begin{itemize}
\item[\alert{-}] \alert{Hard to interpret}
\item[\alert{-}] \alert{A lot of training data}
\item[\bl{+}] \bl{Global patterns}
\item[\bl{+}] \bl{Extandable (e.g., text)}
\end{itemize}
\end{beamerboxesrounded}
\end{column}
\end{columns}
\bigskip

 \end{beamerboxesrounded}
\bigskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{\begin{center}\small{\bl{\textbf{Proposed solution}}}\end{center}}
Precompute KG embedding and treat the result as an oracle, which can be queried any time during rule construction.
 \end{beamerboxesrounded}
\bigskip

\begin{center}\tiny{T. Vinh Ho, D. Stepanova, M. Gad-Elrab, E. Kharlamov, G. Weikum. Rule Learning from KGs guided by Embedding Models. \emph{ISWC2018}.}\end{center}
\end{frame}




\begin{frame}\frametitle{Problem Statement}
 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{\textbf{\bl{Feedback-driven rule mining}}}

\begin{itemize}
\item \textbf{Given:} 
\begin{itemize}
\item KG 
\item Embedding model  
\item Type of rules to be learned (e.g., with(out) negation, disjunctive, etc.)
\end{itemize}
\bigskip

\item \textbf{Find:} 
\begin{itemize}
\item a set of rules of the desired type, which agree with embedding model
on predictions that they make
\end{itemize}
\end{itemize}
\end{beamerboxesrounded}
\end{frame}




\begin{frame}\frametitle{Related Work}
\begin{itemize}
\item \textbf{\bl{Constraints in embedding models}}
\begin{itemize}
\item Injecting logical formulas as constraints into embedding models
(output is still a set of predictions; unclear where they came from)
\cite{DBLP:journals/corr/abs-1711-11231}
\end{itemize}
\bigskip
\bigskip

\item \textbf{\bl{Rule mining with external support}}
\begin{itemize}

\item Interactive pattern mining
\cite{DBLP:conf/kdd/GoethalsMV11}, \\\cite{DBLP:conf/pakdd/DzyubaL17}\medskip

\item Interactive association rule mining
\cite{DBLP:conf/pkdd/SkrabalSVHMCK12}
\end{itemize}
\end{itemize}
\end{frame}





\begin{frame}\frametitle{Mine-Interact-Learn-Repeat}
\small{\begin{itemize}
\item[] Mimic \bl{``mine-interact-learn-repeat''} schema \scriptsize{\cite{DBLP:conf/pakdd/DzyubaL17}}
\uncover<2->{\item[] \small{Establish \bl{``user-in-the-loop''} inspired interaction between the
rule mining algorithm and the embedding model}}
\end{itemize}}
\begin{center}
  \includegraphics[width=.91\textwidth]{user_loop}
\end{center}
\uncover<2->{\begin{picture}(0.5,0.5)
\alt<3->{\put(281,55){\includegraphics[width=.215\textwidth]{blackbox}}
\end{picture}}{\put(292,45){\includegraphics[width=.37\textwidth]{kgembed}}
\end{picture}}
\begin{picture}(0.5,0.5)
\put(-15,70){\includegraphics[width=.25\textwidth]{kg}}
\end{picture}
\begin{picture}(0.5,0.5)
\put(105,-10){\includegraphics[width=.33\textwidth]{feedback}}
\end{picture}
\begin{picture}(0.5,0.5)
\put(125,124){\includegraphics[width=.195\textwidth]{rules}}
\end{picture}}
\end{frame}


\begin{frame}\frametitle{Research Questions}
\small{
\alt<4->{
 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{}
\begin{itemize}
\item[\bl{Q1}] \textbf{(Interact)} What kind of feedback is required/possible\\ to obtain from the ``black box''
to organize convenient and effective interaction process?
\end{itemize}
\end{beamerboxesrounded}}
{\begin{itemize}
\item[\bl{Q1}] \textbf{(Interact)} What kind of feedback is required/possible\\ to obtain from the ``black box''
to organize convenient and effective interaction process?
\end{itemize}}
\pause

\bigskip
\begin{itemize}
\item[\bl{Q2}] \textbf{(Mine)} How to adapt existing rule mining algorithms to account for feedback?
\bigskip
\pause

\item[\bl{Q3}] \textbf{(Learn)} Can anything be learnt from the feedback provided by embeddings?

\end{itemize}}
\end{frame}




\begin{frame}\frametitle{Embedding-based  Methods}
\begin{itemize}
\item \textbf{\bl{Intuition:}} For \bl{$\tuple{s,p,o}$} in KG, find \bl{$\mathbf{s,p,o}$} such that \bl{$\mathbf{s}+\mathbf{p}\approx \mathbf{o}$}
\item The ``error of translation'' of a true KG fact should be smaller by a certain margin than the ``error of translation'' of an out-of-KG one
%Embedding models output the quality of a given fact based on a 
%\vspace{-.2cm}
\medskip

\leftline{\alt<4>{\includegraphics[width=1.03\textwidth]{figures/kg_embed4}}{\alt<3>{\includegraphics[width=1.03\textwidth]{figures/kg_embed3}}{ \alt<2>{\includegraphics[width=1.03\textwidth]{figures/kg_embed2}}{\includegraphics[width=1.03\textwidth]{figures/kg_embed1}}}}}

%Used by embedding models to measure quality of a given fact (s,p,o).
% Corrupted set of facts:
% Rank of (s,p,o) is the number of unknown facts in its corrupted set, which
%have greater embedding score than (s,p,o).
 \end{itemize}
\end{frame}


\begin{frame}\frametitle{Q1 (Interact)}
Measure quality of \bl{ $r: \mi{p(X,Y)\leftarrow B}$}, based on the embedding model\bigskip

\begin{itemize}
% \item quality of a set of facts is defined using $\mi{mrr}$ measure
% \begin{center}
% \bl{$\mi{mrr(S)=\dfrac{1}{|S|}\sum\limits_{{<}s\,p\,o{>}\in S}rank({<}s\,p\,o{>})}$}
% \end{center}
% \bigskip

\item rely on average quality of predicted facts
\begin{center}
\bl{$\mi{rule\_mrr(r)}=\dfrac{1}{|predictions(r)|} \sum\limits_{{<}s\,p\,o{>}\in predictions(r)}\mi{rank({<}s\,p\,o{>})}$}
\end{center}
\end{itemize}
\bigskip
\pause

\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{\bl{Example}}
\begin{center}\bl{$\mi{livesIn(X,Y)\leftarrow actedIn(X,Z),producedIn(Z,Y)}$}\end{center}
\vspace{-.3cm}
\begin{itemize}
%\item Facts in KG: $\mi{<Kate\,livesIn\,Chicago>}, \mi{<Bob\,livesIn\,Berlin>},... $
\item rule predictions: \bl{$\mi{{<}Jack\,livesIn\,NY{>}}$,
$\mi{{<}Mat\,livesIn\,Berlin{>}}$}
\end{itemize}
% \begin{columns}
% \begin{column}{.22\textwidth}

% \small{$\mi{<Kate\,livesIn\,Chicago>}$\\
% $\mi{<Bob\,livesIn\,Berlin>}$\bigskip

% $\mi{{<}\colorbox{lightbl}{Jack}\,\mathbf{\gr{livesIn}}\,\colorbox{lightgr}{NY}{>}}$\\
% $\mi{{<}\colorbox{lightbl}{Mat}\,\mathbf{\gr{livesIn}}\,\colorbox{lightgr}{Berlin}{>}}$
% }
% \end{column}
% \begin{column}{.77\textwidth}
% \vspace{-.7cm}
\begin{center}
\uncover<2>{\scriptsize{
$\bl{rule\_mrr(r){=}}\dfrac{\bl{rank(}{<}\colorbox{lightbl}{Jack}\,\mathbf{\gr{livesIn}}\,\colorbox{lightgr}{NY}{>}\bl{)}{\bl{+}}\bl{rank(}{<}\colorbox{lightbl}{Mat}\,\mathbf{\gr{livesIn}}\,\colorbox{lightgr}{Berlin}{>}\bl{)}}{\bl{2}}$}}
\end{center}
% \bigskip

% Rule predictions are in black
% \end{column}
% \end{columns}
\end{beamerboxesrounded}
\end{frame}




\begin{frame}\frametitle{(Q1) Interact}
Measure quality of \bl{ $r: \mi{h(X,Y)\leftarrow B}$}, based on the embedding model\bigskip
\begin{itemize}
\item rely on average quality of predicted facts estimated by embeddings
\begin{center}
\bl{$\mi{rule\_mrr(r)}=\dfrac{1}{|N|} \sum\limits_{s,h,o\in N}\dfrac{1}{\mi{rank(s,h,o)}}$}
\end{center}
\bigskip

\item combination of mrr with standard rule measures over KG
\begin{center}
\bl{$\mi{embed\_conf(r)}=\lambda*conf(r)+(1-\lambda)*\mi{rule\_mrr(r)}$},
\end{center}
\begin{itemize}
\pause
\item \bl{$\lambda$}: a weighting factor
\item \bl{$\mi{conf}$}: descriptive quality based on the original KG \\
any other standard rule measure can be plugged in
\item \bl{$\mi{rule\_mrr}$}: predictive quality based on KG embedding\\
any embedding model including text-enhanced ones can be used
\end{itemize}
\bigskip

\item more complex interaction, e.g., information theoretic measures?

\end{itemize}

\end{frame}


\begin{frame}\frametitle{Research Questions}
\small{
\begin{itemize}
\item[\bl{Q1}] \textbf{(Interact)} What kind of feedback is required/possible\\ to obtain from the ``black box''
to organize convenient and effective interaction process?
\end{itemize}
\bigskip

\begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolblue,shadow=true]{}
\begin{itemize}
\item[\bl{Q2}] \textbf{(Mine)} How to adapt existing rule mining algorithms to account for feedback? 
\end{itemize}
\end{beamerboxesrounded}
\bigskip

\begin{itemize}
\item[\bl{Q3}] \textbf{(Learn)} Can anything be learnt from the feedback provided by embeddings?
\end{itemize}}
\end{frame}


\begin{frame}\frametitle{(Q2) Mine}

\bl{\textbf{Algorithm steps:}}

\begin{itemize}
\item maintain a rule queue, starting from an empty rule
\bigskip

\item for each rule:
\begin{itemize}
\item[1.] process the rule \\
\uncover<2->{- compute statistics: \bl{$\mi{rule\_mrr, embed\_conf...}$}\\
- filter rules based on statistics and output rule}
\bigskip

\item[2.] extend the queue by applying refinement operators\\
\uncover<3->{- add dangling atom\\
- add closing atom\\
- add positive unary atom\\
- add exception unary atom\\
- add exception binary atom}
\end{itemize}

\end{itemize}

% Algorithm goal:
% \bigskip

% \begin{itemize} 
% \item \bl{\textbf{Input:}} KG, embedding model
% \bigskip

% \item \bl{\textbf{Output:}} rules with:
% \begin{itemize}
% \item  unary predicates
% \item  binary predicates
% \item negated atoms in the body
% \item disjunctions in the head
% \end{itemize} 
% \bigskip

% \item Follow top-down clause search based on refinement operators \cite{DBLP:journals/ml/Quinlan90}, \cite{amieplus}
% \medskip

% \item Query embedding model at every step before rule expansion
% \end{itemize}
% \begin{center}
% \end{center}
\end{frame}


\begin{frame}\frametitle{Refinement Operators}
%\begin{picture}(0.5,0.5)\put(-30,-100){
%\alt<3->{\includegraphics[width=1\textwidth]{figures/refinement_operators2}}{\alt<2->{\includegraphics[width=1\textwidth]{figures/refinement_operators1}}{\includegraphics[width=1\textwidth]{figures/refinement_operators0}}}}
%\end{picture}
\begin{picture}(0.5,0.5)\put(-52,-130){
\leftline{\includegraphics[width=1.3\textwidth]{refinement_operators3}}
}
\end{picture}
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip\bigskip
\bigskip
\bigskip
\bigskip
\bigskip
\bigskip

\begin{beamerboxesrounded}[upper=uppercolbl,lower=lowercolblue,shadow=true]{}
\begin{itemize}
\item Exploit embedding to prune rule search space
\item Generate rule language bias dynamically
\end{itemize}
\end{beamerboxesrounded}
\end{frame}


\begin{frame}\frametitle{Open Questions}
\small{


\begin{itemize}
\item[\bl{Q1}] \textbf{(Interact)} What kind of feedback is required/possible\\ to obtain from the ``black box''
to organize convenient and effective interaction process?
\end{itemize}

\bigskip
\begin{itemize}
\item[\bl{Q2}] \textbf{(Mine)} How to adapt existing rule mining algorithms to account for feedback?
\end{itemize}
\bigskip

 \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{}
\begin{itemize}
\item[\bl{Q3}] \textbf{(Learn)} Can anything be learnt from the feedback provided by embeddings?
\begin{itemize}
\item Ideally, we want to learn the structure of most promising rules, i.e., the best rules have at most 5 atoms, 4 variables, etc..
\medskip
\end{itemize}
\end{itemize}
\end{beamerboxesrounded}
}

\end{frame}

% \begin{frame}\frametitle{Embedding-Based Hybrid Quality Function}
% \captionsetup[subfigure]{textfont=scriptsize}

%  \begin{figure}[t]
%      \centering
%       %Gad: to unify legend and save space
%      \subfloat{{\includegraphics[width=0.7\textwidth]{figures/new_exp1/legend-crop.pdf} }}\\[-1ex]
%      \setcounter{subfigure}{0}
     
%      \subfloat[Conf-HolE on FB15K]{{\includegraphics[width=0.33\textwidth]{figures/new_exp1/fb15k_hole_conf-crop.pdf} }\label{fig:fb-HoLE-Conf}}
%      \subfloat[Conf-SSP on FB15K]{{\includegraphics[width=0.33\textwidth]{figures/new_exp1/fb15k_ssp_conf-crop.pdf} \label{fig:fb-SSP-Conf}}}
%     \subfloat[PCA-SSP on FB15K]{{\includegraphics[width=0.33\textwidth]{figures/new_exp1/fb15k_ssp_pca-crop.pdf} }\label{fig:fb-SSP-PCA}}\\

    
%      \caption{$pred\_prec_{CW}$ of the \textit{top-k} rules with various $\lambda$ on FB15K.}
%      \label{fig:diff_lambda}
%  \end{figure}
% \end{frame}
% \begin{frame}\frametitle{Embedding-Based Hybrid Quality Function}
% \captionsetup[subfigure]{textfont=scriptsize}

%  \begin{figure}[t]
%      \centering
%       %Gad: to unify legend and save space
%      \subfloat{{\includegraphics[width=0.7\textwidth]{new_exp1/legend-crop.pdf} }}\\[-1ex]
%      \setcounter{subfigure}{0}

%     \subfloat[Conf-TransE on Wiki44K]{{\includegraphics[width=0.33\textwidth]{new_exp1/wiki44k_transe_conf-crop.pdf} }\label{fig:wi-TransE-Conf}}
%     \subfloat[Conf-SSP on Wiki44K]{{\includegraphics[width=0.33\textwidth]{new_exp1/wiki44k_ssp_conf-crop.pdf} }\label{fig:wi-SSP-Conf}}
%      \subfloat[PCA-SSP on Wiki44K]{{\includegraphics[width=0.33\textwidth]{new_exp1/wiki44k_ssp_pca-crop.pdf} }\label{fig:wi-SSP-PCA}} \\  
    
%      \caption{$pred\_prec_{CW}$ of the \textit{top-k} rules with various $\lambda$ on Wiki44K.}
%      \label{fig:diff_lambda}
%  \end{figure}
% \end{frame}

\begin{frame}\frametitle{Experimental Setup}
\begin{itemize}
\item \bl{Datasets}: 
\begin{itemize}
\item FB15K: 592M facts, 15M entities and 1345 relations
relations
\item Wiki44K: 250M facts, 44M entities and 100 relations
\end{itemize}
\bs

\item \bl{Ideal graph}: remove 80\% of facts for every relation
\item \bl{Embedding models}: TransE, HolE, SSP

\item For every dataset selected a model that works best

\begin{itemize}
\item Evaluate predictive capabilities of rules obtained by our system vs others
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Evaluation}
\begin{center}
\includegraphics[width=1\textwidth]{new_exp1/experiments}
\end{center}
\end{frame}

\begin{frame}\frametitle{Example Rules}
\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{Examples of rules learned from Wikidata}

 \begin{tabular}{l}
\footnotesize{

Plots of films in a sequel are written by the same writer, unless a film is American}\\
        \footnotesize{$\gr{r_1:  \mi{nationality(X, Y)}  \leftarrow
        \mi{graduatedFrom(X, Z)},\mi{inCountry(Z, Y)},}$ \alert{$ not$  $\mi{researchUni(X)} $}}\\   
\\     
\footnotesize{
Script writers stay the same across sequels, but not for TV series
}\\
      \footnotesize{ 
$\gr{r_2:  \mi{scriptwriterOf(X, Y)}  \leftarrow
        \mi{preceededBy(X, Z)},\mi{scriptWriterOf(Y, Z)},}$ \alert{$ not$  $\mi{tvSeries(Z)} $}} \\
    \\
\footnotesize{
Nobles are typically married to nobles but not in the case of Chinese dynasties
}\\
      \footnotesize{ 
$\gr{r_3:  \mi{nobleFamily(X, Y)}  \leftarrow
        \mi{spouse(X, Z)},\mi{nobleFamily(Z,Y)},}$ \alert{$ not$  $\mi{chineseDynasty(Y)} $}} \\
    
 \end{tabular} 
\end{beamerboxesrounded}
\end{frame}

\section{Further Topics}

\begin{frame}\frametitle{Commonsense Knowledge}
\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{}
``AI has seen great advances of many kinds recently, but there is one critical area
where progress has been extremely slow: ordinary commonsense.''  \cite{DBLP:journals/cacm/DavisM15}
\end{beamerboxesrounded}
\bs

\begin{itemize}
\item Questions that are easy for people but hard for machines
\bs

\begin{itemize}
\item \bl{``Who is \textbf{taller}, Prince William or \textbf{his baby son} Prince George?''}\\
\bs

\item  \bl{``Can you make a \textbf{salad} out of a \textbf{polyester shirt}?''}
\bs

\item \bl{``Can an \textbf{elephant} sit on a \textbf{tree}?''}
\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Commonsense Rule Induction from Hybrid Sources}
\bigskip

 \includegraphics[width=.25\textwidth]{dog_in_car}\uncover<2->{\includegraphics[width=.25\textwidth]{car_in_garage}}\uncover<3->{\includegraphics[width=.25\textwidth]{garage_in_house}}\uncover<4->{\includegraphics[width=.25\textwidth]{house_in_garden}}
\medskip

 \begin{columns}
 \begin{column}{.6\textwidth}
 \uncover<5->{\leftline{\includegraphics[width=.3\textwidth]{dog_in_garden}}}
%\vspace{-3.45cm}
\begin{picture}(0.5,0.5)\put(70,0){
\alt<7->{\includegraphics[width=.63\textwidth]{commonsense_kg1}}{\alt<6>{\includegraphics[width=.63\textwidth]{commonsense_kg2}}{\alt<5>{\includegraphics[width=.63\textwidth]{commonsense_kg3}}{\alt<4>{\includegraphics[width=.63\textwidth]{commonsense_kg4}}{\alt<3>{\includegraphics[width=.63\textwidth]{commonsense_kg5}}{\alt<2>{\includegraphics[width=.63\textwidth]{commonsense_kg6}}{\includegraphics[width=.63\textwidth]{commonsense_kg7}}}}}}}}
\end{picture}
% \end{column}
% \end{columns}
\uncover<7->{\begin{picture}(0.5,0.5)\put(60,85){\text{\large{\bl{+WebChild}}}}\end{picture}
}
\end{column}
\begin{column}{.4\textwidth}
% \uncover<8->{\begin{picture}(0.5,0.5)\put(160,130){\scriptsize{$\mi{larger(Y,X)\leftarrow in(X,Y)}$}}\end{picture}}
% \uncover<9->{\begin{picture}(0.5,0.5)\put(150,110){\scriptsize{$\mi{heavier(Y,X)\leftarrow on(X,Y)}$}}\end{picture}} 
% \uncover<10->{\begin{picture}(0.5,0.5)\put(130,90){\scriptsize{$\mi{has(X,wings) {\lor} round(X)\leftarrow in(X,sky)}$}}\end{picture}} 
% \uncover<10->{\begin{picture}(0.5,0.5)\put(180,80){\large{...}}\end{picture}} 
\uncover<8->{\begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolbl,shadow=true]{\textbf{\bl{Desired output:}}}
\scriptsize{\bl{$\mi{larger(Y,X)\leftarrow in(X,Y)}$\\
$\mi{heavier(Y,X)\leftarrow on(X,Y)}$\\
$\mi{has(X,wings) \lor round(X) \leftarrow in(X,sky)}$
\begin{center}$\dotsc$\end{center}
}}
\end{beamerboxesrounded}}
\end{column}
\end{columns}

%$\mi{heavier(Y,X)\leftarrow on(X,Y)}$ $\mi{has(X,wings)\leftarrow in(X,sky),flyingObject(X), not\;round(X)}$}\end{picture}}
\bigskip

\uncover<7->{WebChild KG \cite{DBLP:conf/acl/TandonMW17}}
\end{frame}

\begin{frame}\frametitle{Commonsense Rule Mining from Hybrid Sources (Text)}


\bigskip
\begin{itemize}

	\item Extracting rules from text challenges %as for~\cite{Schoenmackers:2010}
	\begin{itemize}
		\item Non-canonicalized, ambiguous and infinite set of relations.
		\item Noisy facts.
		\item Missing negative examples (OWA).
		
	\end{itemize}
\end{itemize}
\bigskip

\end{frame}

\begin{frame}\frametitle{Commonsense Rules from Text}


\bigskip
\begin{itemize}

  \item  \bl{\cite{dragoni2016}}: Guido's talk on Sunday
\bs
	\item \bl{SHERLOCK}~\cite{Schoenmackers:2010}: Early attempt to learn rules from open domain text extractions.
\bs

	\item  \bl{\cite{Gordon:2011}}: Utilizes presuppositional discourse patterns (such as statements with but, yet ... etc) to collect conditional knowledge in the form of \textit{if-then}.
\bs

\item \bl{\cite{DBLP:conf/iccs/PetrovaR16}} Mining rules from consessional statements\\
\gre{``Although he is a researcher, he never moved.''} leads to a rule \gre{``Researchers normally move frequently.''}
\bs


  \item KG + text?
\end{itemize}
\bigskip

\end{frame}


\begin{frame}\frametitle{Other Rule Types to Consider}
\bi
\item \textbf{Disjunctive:} \\
%\emph{Actors from capitals are married to actors or politicians }\\
\bl{$\mi{male(Y) \lor female(Y)\leftarrow hasParent(X,Y)}$}
\pause
\bs

\item \textbf{Existential:} \\
\bl{$\mi{\exists Y\, hasParent(X,Y)\leftarrow person(X)}$}
\bs
\pause

\item \textbf{Constraints:}\\
\bl{$\mi{\bot \leftarrow hasParent(X,Y),hasParent(Y,X)}$}
\pause
\bs

\item \textbf{Temporal constraints:} \bl{$\mi{\bot \leftarrow bornIn(X,Y),after(Y,Z),studied(X,Z)}$}
\ei
\end{frame}

\begin{frame}\frametitle{Outlook Issues}

\begin{itemize}
\item Rules from hybrid sources
\bigskip

\item Complex rule types, e.g., numerical, constraints, datalog+-
%\emph{If one has $\geq$ 4 siblings then one's parents have $\geq$ 5 children}\\
\bigskip

\item Background knowledge
\bigskip

\item Causality and novel rule measures
\bigskip

\item Exploit external functions possibly as a blackbox
\bigskip

\item Rule learning from commonsense KGs 
\bigskip

\item Optimizations
\end{itemize}
\end{frame}



\begin{frame}\frametitle{Huge Thanks!}
\begin{itemize}
\item \bl{For collaborations on the presented work}:
\begin{itemize}
\item Mohamed Gad-elrab, Hai Dang Tran, Thinh Vinh Ho, Thomas Pellissier-Tanon, Gerhard Weikum, Jacopo Urbani,  Evgeny Kharlamov, Francesca A. Lisi, Simon Razniewski, Paramita Mirza\\
\end{itemize}
\bs

\item \bl{For making the presentation material available online}:
\begin{itemize}
\item Thomas Eiter, Stephen Muggleton, Luc De Raedt, Luis Gallaraga
\end{itemize}
\end{itemize}
\bs


\end{frame}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% %\makeoverview
% \section{Ontologies and Rules}

% \begin{frame}\frametitle{Overview}
% \begin{itemize}
% \item[$\checkmark$] \bl{Motivation}
% \bigskip

% \item[] \textbf{\bl{Ontologies and Rules}}
% \bigskip

% \item[] \bl{Inconsistencies in DL-programs}
% \bigskip

% \item[] \bl{Nonmonotonic Rule Mining}
% \bigskip

% \item[] \bl{Further and Future Work}
% \end{itemize}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \begin{frame}
% \frametitle{History of Knowledge Representation}
% \small{\begin{itemize}
% \item \textbf{\bl{1950's:}} \bl{First Order Logic (FOL)} for KR (\alert{undecidable})\\
% (e.g. \cite{M59})
% \bigskip

% \item \textbf{\bl{1970's:}} \bl{Network-shaped structures} for KR (\alert{no formal semantics})\\
% (e.g. semantic networks \cite{semnet}, frames \cite{frames})
% \bigskip

% \item \textbf{\bl{1979:}} Encoding of \bl{network-shaped structures} into \bl{FOL} \cite{hayes79}
% \bigskip

% \item \textbf{\bl{1980's:}} \textcolor{blue}{Description Logics (DL)} for KR
% \begin{itemize}
% \item \bl{Decidable fragments} of \bl{FOL}
% \item Theories encoded in DLs are called \bl{ontologies}
% \item Many DLs with different expressiveness and computational features
% \item Particularly suited for \bl{conceptual reasoning}
% \end{itemize}
%  \end{itemize}}
% \end{frame}



% \begin{frame}
% \frametitle{Description Logic Ontologies}
% \textbf{\bl{Open World Assumption (OWA)}}: what is not derived is \bl{unknown}

%  \alt<2>{\begin{picture}(0.5,0.5)
%    \put(50,-136){\includegraphics[width=0.7\textwidth]{dl1}}
%   \end{picture}}{\begin{picture}(0.5,0.5)
%    \put(50,-136){\includegraphics[width=0.7\textwidth]{dl0}}
%   \end{picture}}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}
% \small{

% \textbf{Inclusions:} \gr{$\mi{Female \sqsubseteq \neg Male{,}hasSister \sqsubseteq hasSibling{,}hasBrother \sqsubseteq hasSibling}$}
% \smallskip
% \pause 

% \vspace{-.2cm}
% \textbf{Complex axioms:} \gr{\alt<2>{$\mi{Uncle \equiv Male \sqcap \exists hasSibling.\exists hasChild}$}{$\mi{\forall X\exists Y\,Z(Female(X) \wedge hasSibling(X,Y)\wedge hasChild(Y,Z))}$}}
% }
% \end{beamerboxesrounded}


% \end{frame}



% \begin{frame}\frametitle{What can not be said in DLs?}
% \begin{itemize}


% \item \bl{Exceptions} from theories (due to \bl{monotonicity})\\
% \end{itemize}
% \begin{center}
% \begin{columns}
% \begin{column}{.39\textwidth}
%  \uncover<2-4>{

%  $\gr{\mi{WithBeard \sqsubseteq Male}}$\\
%  $\gr{\mi{Female \sqsubseteq \neg Male}}$\\
%  $\gr{\mi{WithBeard(c)}}$\\
% }
%  \uncover<4->{\bl{$\mi{Female(c)}$\\}}
%  \uncover<2-4>{------------------------------------\\}
%  \uncover<3->{\gr{$\mi{Male(c)}$\\}}
%  \uncover<4->{\bl{$\neg \mi{Male(c)}$}\\}
% \end{column}
% \begin{column}{.39\textwidth}
%  \uncover<2-4>{

%  \emph{People with beards are male}\\
%  \emph{Female are not male}\\
%  \emph{C has a beard}\\
%  }
%  \uncover<4->{\emph{C is female}\\}
%  \uncover<2-4>{------------------------------------\\}
%  \uncover<3->{\emph{C is male}\\}
%  \uncover<4>{\emph{C is not male}\\}
% \end{column}
% \end{columns}
% \end{center}
% \uncover<4>{\begin{picture}(0.5,0.5)
%  \put(95,-10){\includegraphics[width=.25\textwidth]{malefemale}}
%  \end{picture}
% \bigskip

% \begin{center}\bl{Monotonicity:} the more we add, the more we get!\end{center}

% }
% \end{frame}


% \begin{frame}
%   \frametitle{History of Knowledge Representation}
% \bigskip
% \bigskip

% \begin{itemize}
% \item \textbf{\bl{1970's:}} \bl{Logic programming} \\(e.g. Prolog)
% \bigskip
% \bigskip

% \item \textbf{\bl{1980's:}} \bl{Nonmonotonic logics}\\ (e.g. circumscription \cite{DBLP:journals/ai/McCarthy80}, default logic \cite{DBLP:journals/ai/Reiter80})
% \bigskip
% \bigskip

% \item \bl{\textbf{1988:}} \bl{Nonmonotonic rules} under \bl{answer set semantics} (ASP) \\\cite{GL1988}
% \begin{itemize}
% \item \normalsize{Logic programs with \bl{model-based} semantics}
% \item \normalsize{\bl{Disjunctive datalog} with \bl{default negation} $\bl{\mi{not}}$}
% \end{itemize}

% \end{itemize}

% \end{frame}

% \begin{frame}\frametitle{Not is not $\neg$!}
%  \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\normalsize{\textbf{Default negation}} \large{\bl{$\naf$}} 
%    }
% \medskip

% At a rail road crossing cross the road if \textbf{no train is known} to approach\medskip

% \gr{$\mi{walk}\leftarrow \mi{at(X), crossing(X), \text{\emph{\textbf{not}} } train\_approaches(X)}$}

% \end{beamerboxesrounded}
% \bigskip
% \bigskip
% \bigskip

%  \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\normalsize{\textbf{Classical negation}}  \large{\bl{$\neg$}} 
%    }
% \medskip

% At a rail road crossing cross the road if \textbf{no train} approaches\medskip

% \gr{$\mi{walk}\leftarrow \mi{at(X), crossing(X), \neg train\_approaches(X)}$}
% \end{beamerboxesrounded}
% \end{frame}

% \begin{frame}\frametitle{Nonmonotonic Rules}
% \bigskip

% \bl{\textbf{Closed World Assumption (CWA):} } what is not derived is \bl{false}
% \bigskip
% \bigskip

% \small{ \bl{\textbf{Rule:} }
% $\underbrace{a_1 \lor \dotsc \lor a_k}_{\Large{\bl{\text{head}}}}\; \leftarrow\; \underbrace{b_1,\, \dotsc,\, b_m,\,\bl{not} \,b_{m+1},\,\dotsc,\,\bl{not} \,b_n}_{\bl{\text{body}}} $

% }
% \bigskip
% \bigskip

% \small{\bl{\textbf{Informal semantics:}} } If $b_1,\dotsc, b_{m}$ are true and \bl{none} of $b_{m+1},\dotsc,b_n$ is \bl{known}, \phantom{\textbf{Informal semantics:\;\;\;}}then at least one among $a_1,\dotsc, a_k$ must be true\bigskip
% \bigskip
% \bigskip

% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{}
% \small{
% \textbf{Default negation}: unless a child is adopted one of his parents must be female\medskip

% \gr{$\mi{female(Y)\lor female(Z)\leftarrow hasParent(X,Y),hasParent(X,Z),} \\
% \phantom{\mi{female(Y)\lor female(Z)\leftarrow}}\mi{Y \neq Z, \naf\,adopted(X)}$}
% \bigskip

% \textbf{Constraint:} ensure that no one is a parent of himself\medskip

% \gr{$ \bot \leftarrow \mi{parent(X,Y),parent(Y,X)}$}
% }

% \end{beamerboxesrounded}
% \bigskip

% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \begin{frame}
% \frametitle{Answer Set Programs}
% \begin{itemize}
% \item[]\uncover<1->{\bl{Evaluation} of ASP programs is model-based }%\footnote{unlike in prolog, which is based on theorem proving}}%\uncover<3->{, it consists of 2 steps:}
% \begin{itemize}
% \uncover<2->{\item[1.]\bl{Grounding}: substitute all \bl{variables with constants} in all possible ways }
% \uncover<4->{\item[2.]\bl{Solving}: compute a \bl{minimal model (answer set) $I$} satisfying all rules}
% \end{itemize}
% \end{itemize}
% \bigskip

% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\textbf{Answer set program (ASP)} is a set of nonmonotonic rules}
% \bigskip

% $\gr{
%       \begin{array}{l@{\qquad}}
%          \mbox{(1) }\mi{hasParent(john,pat)}\;\;\; \mbox{(2) }\mi{hasParent(john,alex)}\;\;\;\mbox{(3) }\mi{male(alex)}\\[0.35ex]
%          \mbox{(4) }\mi{female(\alt<3->{\mi{pat}}{\bl{Y}})} \leftarrow \alt<3->{\mi{hasParent(john,pat)}}{\mi{hasParent(\bl{X,Y})}},\mi{hasParent(\alt<3->{john,alex}{\bl{X,Z}}),}\\
%          \phantom{\mbox{(4) }\mi{female(\alt<3->{pat}{\bl{Y}})\,} \leftarrow }\only<1,2>{\bl{Y\neq Z},} \mi{male(\alt<3->{alex}{\bl{Z}})},\naf\ \mi{adopted(\alt<3->{\mi{john}}{\bl{X}})} \uncover<5->{\\[0.35ex]\bl{\mbox{(5) }\mi{adopted(john)}}}
%       \end{array}
%     }$
% \medskip

% \uncover<5->{\small{$\phantom{\mi{I{=}\{\mi{hasParent(john,pat),hasParent(john,alex),male(alex)}}}\bl{\mi{adopted(john)}}$}}
% \uncover<4->{
% \small{$\gr{\mi{I{=}\{\mi{hasParent(john,pat),hasParent(john,alex),male(alex)},\alt<5>{\cancel{\mi{female(pat)}}}{\mi{female(pat)}}\}}}$}

% \uncover<4>{\medskip

% \bl{CWA:} \gr{$\mi{adopted(john)}$} can not be derived, thus it is false}}

% \end{beamerboxesrounded}


% \begin{center}\visible<5>{\bl{Nonmonotonicity}: adding facts might lead to loss of consequences!}\end{center}
% \end{frame}


%  \begin{frame}\frametitle{Combining Ontologies and Rules}
%  \begin{picture}(0.5,0.5)
% \alt<2>{\put(50,-130){\includegraphics[width=0.7\textwidth]{dlvsrules}}}{\put(50,-130){\includegraphics[width=0.7\textwidth]{dlvsrules0}}}
%  \end{picture}

%  \end{frame}

% \section{Inconsistencies in DL-programs}

% \begin{frame}\frametitle{Overview}
% \begin{itemize}
% \item[$\checkmark$] \bl{Motivation}
% \bigskip

% \item[$\checkmark$] \bl{Ontologies and Rules}
% \bigskip

% \item[] \textbf{\bl{Inconsistencies in DL-programs}}
% \bigskip


% \item[] \bl{Nonmonotonic Rule Mining}
% \bigskip

% \item[] \bl{Further and Future Work}
% \end{itemize}

% \begin{picture}(0.5,0.5)
% \put(200,65){\includegraphics[width=0.11\textwidth]{eiter}}
% \put(204,55){\text{\footnotesize{T. Eiter}}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(265,78){\includegraphics[width=0.095\textwidth]{fink}}
% \put(267,68){\text{\footnotesize{M. Fink}}}
% \end{picture}
% \end{frame}



% \begin{frame}\frametitle{DL-programs}
% \bl{DL-programs:} loose coupling of \bl{ontologies} and \bl{rules} \cite{EIL08}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.5,0.5)
% \put(80,-25){\includegraphics[width=0.53\textwidth]{dlp}}
% \end{picture}
% \end{frame}


% \begin{frame}\frametitle{\alt<15->{DL-program Repair}{\alt<14>{Inconsistent DL-program}{DL-program}}}
% \bigskip

% \small{
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\centerline{DL ontology}}
% \vspace{-.1cm}
%  \begin{columns}
%  \begin{column}{.38\textwidth}
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\centerline{Logical part}}
% \vspace{-.2cm}
% \gr{\begin{center}\small{$%O{=}\left\{
% \begin{array}{@{\,}l@{}}
%  \mbox{(1) }\mathit{Child \sqsubseteq \exists hasParent} \\[0.25ex]
%  \mbox{(2) }\mathit{Female \sqsubseteq \neg Male}  \\[0.25ex] 
% \mbox{(3) } \mathit{Adopted \sqsubseteq Child} \\[0.25ex]
%  \end{array}
% %\right\}
% $}
% \end{center}}
%  \end{beamerboxesrounded}
%  \end{column}
%  \begin{column}{.49\textwidth}
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\centerline{Data part (KG)}}
% \vspace{-.2cm}
% \gr{\begin{center}\small{$%O{=}\left\{
% \begin{array}{@{\,}l@{\,}l@{}}
%  \alt<16>{\bl{\mbox{(4) }\cancel{\mathit{Male(pat)}}\,\,\mathit{Female(pat)}}}{\alt<7>{\bl{\mbox{(4) }\mathit{Male(pat)}}}{\mbox{(4) }\mathit{Male(pat)}}}& \alt<15>{\bl{\mi{Female(alex)}}}{\alt<7>{\mi{Male(tim)}}{\uncover<6,7>{\bl{\mi{Male(tim)}}}}}\\[0.25ex]
%  \mbox{(5) }\mathit{Male(john)}&  \\[0.25ex] 
% \alt<17>{}{\alt<3>{\bl{\mbox{(6) }\mi{hasParent(john,pat)}}}{\mbox{(6) } \mathit{hasParent(john,pat)}}}& \\[0.25ex]
%  \end{array}
% %\right\}
% $}
% \end{center}}
%  \end{beamerboxesrounded}
%  \end{column}
% \end{columns}
% \end{beamerboxesrounded}
% }
% \bigskip

%  \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\centerline{Rules}}
%  \vspace{-.1cm}
% \gr{\small{\begin{center}
% $\begin{array}{@{\,}l@{~\,}}
% \alt<11>{\bl{ \mbox{(7) }\mi{isChildOf(john,alex)}}}{ \mbox{(7) }\mi{isChildOf(john,alex)}}\;\;\;\;\;\;\alt<6>{\bl{(8)\; \mi{boy(tim)}}}{(8)\; \mi{boy(tim)}}\\[0.35ex]
%  \mbox{(9) }\mi{hasFather}(john,pat) \leftarrow \alt<2->{\dlatom{}{\alt<3>{\bl{\mi{hasParent}}}{\mi{hasParent}}}{\alt<3>{\bl{\mi{john,pat}}}{\mi{john,pat}}}\only<3-8>{\;\;\bl{\checkmark}}}{\call}, \alt<4->{\\
% \phantom{\mbox{(9) }\mi{hasfather}(john,pat) \leftarrow}\;\; \dlatom{\alt<5,6>{\bl{\mi{Male} \uplus \mi{boy}}}{\mi{Male} \uplus \mi{boy}}}{\alt<7>{\bl{\mi{Male}}}{\mi{Male}}}{\alt<7>{\bl{\mi{pat}}}{\mi{pat}}}\only<7-8>{\;\;\bl{\checkmark}}}{\call}\\[0.35ex]
% \alt<14>{\alert{\mbox{(10) }\bot \leftarrow \mi{hasFather(john,pat),isChildOf(john,alex)},}\\
% \phantom{\mbox{(10) }\bot \leftarrow }\; \alert{\naf\dlatom{}{\mi{Adopted}}{john},}\\
% \phantom{\mbox{(10) }\bot \leftarrow }\; \alert{\naf\dlatom{\mi{Child}\uplus\mi{boy}}{\neg \mi{Male}}{\mi{alex}}}
% }{\alt<9->{\mbox{(10) }\bot \leftarrow \alt<10-14>{\bl{\mi{hasFather(john,pat)}}}{\mi{hasFather(john,pat)}},\alt<11-14>{\bl{\mi{isChildOf(john,alex)}}}{\mi{isChildOf(john,alex)}},\\
% \phantom{\mbox{(10) }\bot \leftarrow }\; \alt<12-14>{\bl{\naf\dlatom{}{\mi{Adopted}}{john}}}{\naf\dlatom{}{\mi{Adopted}}{john}},\\
% \phantom{\mbox{(10) }\bot \leftarrow }\; \alt<13-14>{\bl{\naf\dlatom{\mi{Child}\uplus\mi{boy}}{\neg \mi{Male}}{alex}}}{\naf\dlatom{\mi{Child}\uplus\mi{boy}}{\neg \mi{Male}}{alex}}\\}{}}
% \end{array}$%
%  \end{center}}}
%  \end{beamerboxesrounded}
%  \medskip

% \alt<15,16,17>{\bl{Repair answer set: }\gr{$\mi{I=\{isChildOf(john,alex),boy(tim)}\only<15>{\mi{,hasFather(john,pat)}}\}$}}{\alt<14>{\alert{\textbf{Inconsistent DL-program}: no answer sets!}}{\uncover<8>{\small{\bl{Answer set:} \gr{$\mi{I=\{isChildOf(john,alex),boy(tim),hasFather(john,pat)\}}$}}}}}



% \end{frame}


% \begin{frame}
% \frametitle{Inconsistency Handling in DL-programs}
% \bigskip

% \small{\bl{\textbf{Goal:}} develop techniques for handling inconsistencies in DL-programs}\\
% \small{\bl{\textbf{Approach:}} repair ontology data part (KG) to regain consistency}
% \smallskip

% \begin{center}
% \includegraphics[width=0.9\textwidth]{InconsisDLP}
% \end{center}

% \end{frame}




% \begin{frame}
% \frametitle{Complexity of Repair Answer Sets}
% \bigskip

% \begin{tabular}{|l|}
% \hline
% \small{\textbf{INSTANCE}: A ground DL-program $\Pi=\tuple{O,P}$.}\\
% \small{\textbf{QUESTION}: Does there exist a repair answer set for $\Pi$?} \\
% \hline
% \end{tabular}
% \bigskip

% \begin{theorem}
%  Deciding repair and standard answer set existence have the same complexity if instance query-answering in $O$ is polynomial ($\dllite_{\cA}, \el$).
%  \end{theorem}

% \begin{table}[ht]

% \centering 

% \begin{tabular}{| c | c | c |} 
% \hline
% \centering{\bl{$\Pi$}} & \bl{FLP semantics}& \bl{weak semantics}\\ [0.5ex] % inserts table
% %heading
% \hline 
% \bl{normal} &  \small{$\Sigma^P_2$-complete} &  \small{$\NP$-complete}\\ [1.5ex]% inserting body of the table
% \hline
% \bl{disjunctive} &  \small{$\Sigma^P_2$-complete}&  \small{$\Sigma^P_2$-complete}\\
% [1.5ex] 
% \hline
% \end{tabular}
% \label{table:nonlin} 
% \end{table}
% \bigskip
% \bigskip
% \bigskip


% \tiny{T. Eiter, M. Fink, D. Stepanova. Data Repair of Inconsistent DL-programs. \emph{IJCAI2013}}
% \\
% \tiny{T. Eiter, M. Fink, D. Stepanova. Data Repair of Inconsistent Nonmonotonic Description Logic Programs. \emph{JAI2016}}
% \end{frame}



% \begin{frame}\frametitle{Ontology Repair Problem}
% \bigskip

% \begin{tabular}{|l|}
% \hline
% \small{\textbf{INSTANCE}: Ontology $O$, \gr{$D_{\mi{true}}=\{\tuple{\mi{update,query}}\}$}, \alert{$D_{\mi{false}}=\{\tuple{update,query}\}$}}\\
% \small{\textbf{QUESTION}: Does there exist $O$ data part, for which queries under their}\\\phantom{\small{\textbf{QUESTION}:}} \small{updates from $\gr{D_{\mi{true}}}$ are true and from $\alert{D_{\mi{false}}}$ are false?} \\
% \hline
% \end{tabular}
% \bigskip

% \begin{theorem}
%  The Ontology Repair Problem is \NP-complete even if $O=\emptyset$.
%  \end{theorem}
% \bigskip

% \bl{Tractable cases:}
% \begin{itemize}
% \item Deletion repair
% \item Bounded addition
% \item Bounded change
% \item $\dotsc$
% \end{itemize}
% \end{frame}

% \begin{frame}
% \frametitle{Optimized DL-program Repair}

% \small{\begin{itemize}
% \item For each \bl{DL-atom} compute \bl{minimal sets of facts} (\sups), whose presence in ontology \bl{ensures DL-atom's query entailment} (small for some DLs)
% \uncover<2->{\item \bl{Guess values of DL-atoms} under which the program has an answer set}
% \uncover<3->{\item Solve \bl{ontology repair problem} as a variant of a \bl{hitting set problem}}
% \end{itemize}}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.3,0.3)
%    \put(50,-5){\alt<3>{\includegraphics[width=.7\textwidth]{opt3}}{\alt<2>{\includegraphics[width=0.7\textwidth]{opt2}}{\includegraphics[width=.7\textwidth]{opt1}}}}
% \end{picture}
% \bigskip

% \uncover<3>{
% \tiny{T. Eiter, M. Fink, D. Stepanova. Towards Practical Deletion Repair of Inconsistent
% DL-programs. \emph{ECAI2014}}
% \\
% \tiny{T. Eiter, M. Fink, D. Stepanova. Computing Repairs for Inconsistent DL-programs
% over $\el$ Ontologies. \emph{JELIA2014, JAIR2016}}}

% \end{frame}


% \begin{frame}
% \frametitle{Example Benchmark}
% \begin{picture}(0.3,0.3)
%    \put(220,-30){\includegraphics[width=0.3\textwidth]{osm}}
% \end{picture}

% \bigskip
% \begin{itemize}
% \item \bl{Ontology:} MyITS\footnote{\tiny{http://www.kr.tuwien.ac.at/research/projects/myits/}}
% \begin{itemize}
% \item \bl{personalized route planning} with semantic
% information
% \smallskip

% \item logical axioms (406), (building features
% located inside private areas are not publicly accessible, covered
% bus stops are those with roofs) 
% \smallskip

% \item KG (4195 facts), Cork city map with leisure areas, bus stops,..
% \end{itemize}
% \bigskip


% \item \bl{Rules:} check that public stations don't lack public access, using \phantom{Rules:} CWA on private areas
% \bigskip

% \item \alert{Inconsistency:} wrong GPS coordinates result in roofed bus stops \phantom{Inconsistency:} being located inside private areas
% \bigskip

% \item \bl{Repair:} found within 12 seconds
% \end{itemize}
% \end{frame}


% \section{Nonmonotonic Rule Mining}


% \begin{frame}
% \frametitle{Overview}
% \begin{itemize}
% \item[$\checkmark$] \bl{Motivation}
% \bigskip

% \item[$\checkmark$] \bl{Ontologies and Rules}
% \bigskip

% \item[$\checkmark$] \bl{Inconsistencies in DL-programs}
% \bigskip

% \item[] \textbf{\bl{Nonmonotonic Rule Mining}}
% \bigskip

% \item[] \bl{Further and Future Work}
% \end{itemize}
% \begin{picture}(0.5,0.5)
% \put(170,45){\includegraphics[width=0.07\textwidth]{moh}}
% \put(163,35){\text{\tiny{M. Gad-Elrab}}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(202,58){\includegraphics[width=0.06\textwidth]{jacoppo}}
% \put(201,48){\text{\tiny{J. Urbani}}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(230,72){\includegraphics[width=0.065\textwidth]{weikum}}
% \put(227,62){\text{\tiny{G. Weikum}}}
% \end{picture}

% %\uncover<2>{
% \begin{picture}(0.5,0.5)
% \put(260,85.5){\includegraphics[width=0.08\textwidth]{tran}}
% \put(260,75.5){\text{\tiny{D. H. Tran}}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(292,98){\includegraphics[width=0.07\textwidth]{lisi}}
% \put(294,88){\text{\tiny{F. A. Lisi}}}
% \end{picture}
% %}
% \end{frame}


% \begin{frame}\frametitle{\alt<4>{Nonmonotonic Rule Mining}{Horn Rule Mining}}
% \smallskip

% \uncover<2->{\alt<4->{\bl{Nonmonotonic rule mining} from KGs: \alert{OWA} is a challenge!}{\bl{Horn rule} mining for KG \bl{completion} \cite{amie} } }
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip
%  \bigskip

% \alt<4->{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg3}}\end{picture}}{
% \alt<3->{
% \begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg2}}\end{picture}
% }{\alt<2->{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg1}}\end{picture}}{\begin{picture}(0.5,0.5)\put(43,-33){\includegraphics[width=0.75\textwidth]{kg0}}\end{picture}}}}
% \begin{center}
% \visible<2->{\rightline{\gr{$\mi{conf(r)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=$\alt<4>{$1$}{$\dfrac{2}{4}$}}}}
% \bigskip
% \bigskip

% \uncover<2->{\normalsize{\alt<4>{\textcolor{darkgreen}{$r:\;\mi{livesIn(X,Z)}\leftarrow \mi{isMarriedTo(Y,X),livesIn(Y,Z)},$}\,\alert{$\naf\ researcher(X)$}}{\textcolor{darkgreen}{$r:\;\mi{livesIn(X,Z)}\leftarrow \mi{isMarriedTo(Y,X),livesIn(Y,Z)}$}}}}
%  \end{center}

% \end{frame}



% \begin{frame}\frametitle{\alt<2>{Declarative Programming Example}{Declarative Programming Paradigm}}
% \alt<2>{
%  \begin{picture}(0.5,0.5)
%  \put(20,-135){\includegraphics[width=0.9\textwidth]{asp_2}}
%  \end{picture}
% \put(31,65){\text{\small{Graph 3-colorability}}}

% \begin{picture}(0.5,0.5)
% \put(20,115){\includegraphics[width=0.32\textwidth]{graph}}
% \end{picture}
% \begin{picture}(0.5,0.5)
% \put(207,115){\includegraphics[width=0.32\textwidth]{graph_col}}
% \end{picture}
% \put(85,70){$
% \tiny{
% \begin{array}{@{\,}l@{~\,}}
% \gr{\mi{node(1\dotsc 6)};\;\;\;\;\mi{edge(1,2)};\;\;\;\; \dotsc}\\[0.35ex]
% \gr{\mi{col(V,red)}\leftarrow \naf\;\mi{col(V,blue)}, \naf\;\mi{col(V,green)},\mi{node(V)};}\\[0.35ex]
% \gr{\mi{col(V,green)}\leftarrow \naf\;\mi{col(V,blue)},\naf\;\mi{col(V,red)},\mi{node(V)};}\\[0.35ex]
% \gr{\mi{col(V,blue)}\leftarrow \naf\;\mi{col(V,green)},\naf\;\mi{col(V,red)},\mi{node(V)};}\\[0.35ex]
% \gr{\bot\leftarrow \mi{col(V,C)},\mi{col(V,C')},C \neq C';}\\[0.35ex]
% \gr{\bot \leftarrow \mi{col(V,C)},\mi{col(V',C)}, \mi{edge(V,V')}}\\[0.35ex]
% \end{array}}
% $}
%  \put(215,0){\tiny{$\begin{array}{@{\,}l@{~\,}}
% \gr{\mi{node(1\dotsc 6)}};\;\;\;\;\gr{\mi{edge(1,2)};\dotsc}\\ \gr{\mi{col(1, red),col(2,blue)},}\\ \gr{\mi{col(3,red),col(4,green)},}\\ \gr{\mi{col(6,green),col(5,blue)}}\end{array}$}}
% }{
% \begin{picture}(0.5,0.5)
% \put(20,-120){\includegraphics[width=0.86\textwidth]{asp_1}}
% \end{picture}
% }
% \end{frame}

% \begin{frame}\frametitle{Nonmonotonic Rule Mining}
% \alt<2>{\begin{picture}(0.5,0.5)
% \put(20,-190){\includegraphics[width=0.86\textwidth]{asp_4}}
% \end{picture}

% \begin{picture}(0.5,0.5)
% \put(209,-35){\includegraphics[width=0.258\textwidth]{kg0}}
% \end{picture}
% \put(26,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{livesIn(Y,Z)}\leftarrow \mi{isMarried(X,Y)}, \\
% \phantom{\mi{livesIn(Y,Z)}\leftarrow} \mi{livesIn(X,Y)}, \\ \phantom{\mi{livesIn(Y,Z)}\leftarrow}\naf\ \mi{researcher(Y)}\end{array}
% $}}}
%  \put(209,-138){\gr{\tiny{$\begin{array}{@{\,}l@{~\,}}
% \mi{\gr{isMarriedTo}(brad,ann)};\\ \mi{\gr{isMarriedTo}(john,kate)};\\ \mi{\gr{isMarriedTo}(bob,alice)};\\ \mi{\gr{isMarriedTo}(clara, dave)}; \\ \mi{\gr{livesIn}(brad,berlin};\\ \dotsc\\ \mi{researcher(alice)};\\ \mi{researcher(dave)}\end{array}$}}}
% }{\begin{picture}(0.5,0.5)
% \put(20,-120){\includegraphics[width=0.86\textwidth]{asp_3}}
% \end{picture}}
% \end{frame}

% \begin{frame}\frametitle{Nonmonotonic Rule Mining from KGs}
% \bl{\textbf{Goal:}} learn nonmonotonic rules from KG\\
% \bl{\textbf{Approach:}} revise association rules learned using data mining methods
% \medskip

% \includegraphics[width=1.02\textwidth]{nmlearn}

% \end{frame}


% \begin{frame}\frametitle{Horn Theory Revision}
% \bigskip

%  \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Quality-based Horn Theory Revision}}}

%  \smallskip

%  \textbf{Given:} 
%  \begin{itemize}
%  \item Available KG 
% \uncover<2->{ \item Horn rule set}
%  \end{itemize}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

%  \uncover<3->{\noindent \textbf{Find:} }
%  \begin{itemize}
% \uncover<3->{ \item Nonmonotonic revision of Horn rule set}\uncover<4->{\\ with better 
%  predictive quality}
%  \end{itemize}
%  \end{beamerboxesrounded}
% \begin{picture}(0.5,0.5)\put(143,45){\alt<4>{\includegraphics[width=0.58\textwidth]{big_pic_4}}{\alt<3>{\includegraphics[width=0.58\textwidth]{big_pic_3}}{\alt<2>{\includegraphics[width=0.58\textwidth]{big_pic_2}}{\includegraphics[width=0.58\textwidth]{big_pic_1}}}}}\end{picture}
% \end{frame}

% \begin{frame}\frametitle{Avoid Data Overfitting}
% \begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{How to distinguish exceptions from noise?}\bigskip

% \small{$
%             \renewcommand{\arraystretch}{1.1}
%              \begin{array}{@{\,}l@{~~}l@{}}
%                \mi{\gr{r1:\,livesIn(X,Z) \leftarrow isMarriedTo(Y,X),livesIn(Y,Z),}\, \alert{\naf\ researcher(X)}}\\
%               \visible<2->{\phantom{r1:\,}\mi{\,not\_livesIn(X,Z) \leftarrow isMarriedTo(Y,X),livesIn(Y,Z),researcher(X)}\\[2.75ex]}
%               \visible<3->{\mi{\gr{r2:\,livesIn(X,Z)\leftarrow bornIn(X,Z),\,}\alert{\naf\ moved(X)}}}\\
%               \visible<3->{\phantom{r1:\,}\mi{\,not\_livesIn(X,Z)}\leftarrow bornIn(X,Z),moved(X)}
%              \end{array}$\bigskip

% \uncover<4>{$\{\gr{\mi{livesIn(c,d)}},\mi{not\_livesIn(c,d)}\}$ are conflicting predictions\bigskip

% \textbf{Intuition:} Rules with good exceptions should make few conflicting predictions
% }}
% \end{beamerboxesrounded}
% \end{frame}

% \begin{frame}\frametitle{Horn Theory Revision}

% \bigskip

%  \begin{beamerboxesrounded}[upper=uppercolblue,lower=lowercolblue,shadow=true]{\textbf{\bl{Quality-based Horn Theory Revision}}}

%  \smallskip

%  \textbf{Given:} 
%  \begin{itemize}
%  \item Available KG 
%  \item Horn rule set
%  \end{itemize}

% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

%  \noindent \textbf{Find:} 
%  \begin{itemize}
%  \item Nonmonotonic revision of Horn rules, such that \\
% \begin{itemize}
% \item number of \bl{conflicting predictions} is \textbf{minimal} \smallskip

% \item average \bl{conviction}
% is \textbf{maximal}
% \end{itemize}
%  \end{itemize}
%  \end{beamerboxesrounded}
% \begin{picture}(0.5,0.5)\put(143,68){\includegraphics[width=0.58\textwidth]{big_pic_4}}\end{picture}
% \end{frame}


% \begin{frame}\frametitle{Exception Candidates}
% \begin{picture}(0.5,0.5)\put(40,-183,5){\includegraphics[width=0.75\textwidth]{kg_advanced3}}
% \end{picture}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip


% \leftline{\gr{$r{:}\,\mi{livesIn(X,Z)}\,{\leftarrow}\, \mi{isMarriedTo(Y,X)\,{,}\,livesIn(Y,Z)}$}}
% \FrameText{\alert{$\left\{\begin{array}{@{}l@{}}
%  \mbox{}\small{\mi{{\naf}\,researcher(X)}}\\
% \mbox{}\small{\mi{{\naf}\,artist(Y)}}\end{array}\right\}$}}
% \end{frame}



% \begin{frame}\frametitle{Exception Ranking}

% \begin{center}
% $\mi{\gr{rule1}\;\;\; \alert{\{\underline{\mathbf{e_1}},e_2,e_3, \dotsc\}}}$\\
%  $\mi{\gr{rule2}\;\;\; \alert{\{e_1,\underline{\mathbf{e_2}},e_3, \dotsc\}}}$\\
%  $\mi{\gr{rule3}\;\;\; \alert{\{\underline{\mathbf{e_1}},e_2,e_3, \dotsc\}}}$\\
% \end{center}

% \begin{beamerboxesrounded}[upper=uppercolred,lower=lowercolred,shadow=true]{}
% \small{Finding globally best revision is expensive, exponentially many candidates!}
% \end{beamerboxesrounded}
% \begin{itemize}


% \item \bl{Naive ranking:} for every rule inject exception that results in the highest conviction
% \medskip

% \item \bl{Partial materialization (PM):} apply all rules apart from a given one, inject exception that results in the highest average conviction of the rule and its rewriting


% \medskip

% \item \bl{Ordered PM (OPM):} same as PM plus ordered rules application
% \medskip

% \item \bl{Weighted OPM:} same as OPM plus weights on predictions
% \end{itemize}
% \bigskip

% \tiny{M. Gad-Elrab, D. Stepanova, J. Urbani, G. Weikum. Exception-enriched Rule Learning from Knowledge Graphs. \emph{ISWC2016}}\\
% \tiny{D. Tran{,}\,D. Stepanova{,}\,M. Gad-Elrab{,}\,F. Lisi{,}\,G. Weikum. Towards Nonmonotonic Relational Learning from KGs{.}\,\emph{ILP2016}}
% \end{frame}

% \begin{frame}\frametitle{Experimental Setup}
% \vspace{-.4cm}
% \begin{itemize}
% \item \bl{Approximated ideal KG}: original KG 
% \smallskip

% \item \bl{Available KG}: for every relation randomly remove 20\% of facts from approximated ideal KG
% \smallskip

% \item \bl{Horn rules}: $\mi{h(X,Y)\leftarrow p(X,Z),q(Z,Y)}$ 
% \smallskip

% \item \bl{Exceptions}: $\mi{e_1(X),e_2(Y),e_3(X,Y)}$
% \smallskip

% \item \bl{Predictions} are computed using \bl{answer set solver} DLV % \footnote{\tiny{\url{http://dlvsystem.com}}}
% \end{itemize}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \bigskip
% \bigskip

% \visible<1>{\begin{picture}(0.5,0.5)\put(55,63){\includegraphics[width=0.75\textwidth]{big_pic_exp}}
% \end{picture}}

% \visible<2>{\vspace{-5,5cm}\begin{beamerboxesrounded}[upper=uppercolgreen,lower=lowercolgreen,shadow=true]{\textbf{Examples of revised rules:}}

%  \begin{tabular}{l}
% \footnotesize{

% Plots of films in a sequel are written by the same writer, unless a film is American}\\
%         \footnotesize{$\gr{r_1:  \mi{writtenBy(X, Z)}  \leftarrow
%         \mi{hasPredecessor(X, Y)},\mi{writtenBy(Y, Z)},}$ \alert{$ not$  $\mi{american\_film(X)} $}}\\   
% \\     
% \footnotesize{
% Spouses of film directors appear on the cast, unless they are silent film actors
% }\\
%       \footnotesize{ 
% $\gr{r_2:  \mi{actedIn(X, Z)}  \leftarrow
%         \mi{isMarriedTo(X, Y)},\mi{directed(Y, Z)},}$ \alert{$ not$  $\mi{silent\_film\_actor(X)} $}} \\
    
%  \end{tabular} 
% \end{beamerboxesrounded}      }



% \end{frame}

% \section{Ongoing and Future Work}
% \begin{frame}\frametitle{Overview}
% \begin{itemize}
% \item[$\checkmark$] \bl{Motivation}
% \bigskip

% \item[$\checkmark$] \bl{Ontologies and Rules}
% \bigskip

% \item[$\checkmark$] \bl{Inconsistencies in DL-programs}
% \bigskip

% \item[$\checkmark$] \bl{Nonmonotonic Rule Mining}
% \bigskip

% \item[] \textbf{\bl{Ongoing and Future Work}}
% \end{itemize}
% \end{frame}



% \begin{frame}\frametitle{Completeness-aware Rule Mining}
% \begin{itemize}
% \item Exploit \bl{cardinality meta-data} \cite{card} in \bl{rule mining}\\
% \emph{\gr{John has \textbf{5} children, Mary is a citizen of \textbf{2} countries}}
% \end{itemize}
% \bigskip\bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \begin{picture}(0.5,0.5)\put(40,-26){\includegraphics[width=0.8\textwidth]{worldmap}}
% \end{picture}

% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \tiny{Joint work with T. Pellissier-Tanon, S. Razniewski, P. Mirza, G. Weikum}
% \end{frame}




% \begin{frame}\frametitle{Ongoing and Future Work}
% \begin{itemize}
% \item Make use of \bl{logical background knowledge} in
% \begin{itemize}
% \normalsize{\item \bl{Rule learning} and other \bl{data mining} tasks}\footnote{\tiny{S. Paramonov, D. Stepanova, P. Miettinen. Hybrid Approach to Constraint-based Pattern Mining. Accepted to \emph{RR2017}}}
% \smallskip

% \normalsize{\item \bl{Information extraction} from text corpora}\footnote{\tiny{Joint work with M. Gad-Elrab, J. Urbani, G. Weikum}}
% \smallskip

% \normalsize{\item \bl{Natural language processing} tasks}
% \end{itemize}
% \end{itemize}
% \bigskip
% \bigskip

% \begin{itemize}
% \item Exploit \bl{answer set programs with\\ external computations} \cite{DBLP:conf/frocos/EiterBDFIK09} \\for the above problems
% \end{itemize}

% \begin{picture}(0.5,0.5)
%  \put(230,-20){\includegraphics[width=0.27\textwidth]{hex}}
% \end{picture}
% \end{frame}

% \begin{frame}\frametitle{Conclusion}

% \textbf{\bl{Summary:}}
% \begin{itemize}
% \small{\item \bl{Inconsistencies in combination of rules and ontologies}}
% \begin{itemize}
% \item Repair semantics and its complexity analysis
% \item Optimized algorithms for repair computation \\and their evaluation ($\dllite_{\cA}$ and $\el$ DLs)
% \end{itemize}
% \bigskip

% \small{\item \bl{Nonmonotonic rule mining from KGs}}
% \begin{itemize}
% \item Quality-based Horn theory revision framework under OWA
% \item Approach for computing and ranking exceptions based on\\ cross-talk among rules and its evaluation on real-world KGs
% \end{itemize}
% \end{itemize}
% \bigskip
% \bigskip

% \textbf{\bl{Future Directions:}}
% \small{\begin{itemize}
% \item Interlinking mining and reasoning in the KG context
% \item Exploiting logical background knowledge in information \\extraction and natural language processing tasks
% \end{itemize}}

% \end{frame}


\appendix
\begin{frame}[plain,allowframebreaks,allowdisplaybreaks]
  \frametitle{References}
  \bibliographystyle{named}
 \tiny{\bibliography{references}}
\end{frame}
% \section{Additional Material}


% \begin{frame}
% \frametitle{DL-program Repair Algorithm}
% \vspace{-.15cm}
% \begin{center}
% \alt<9->{\includegraphics[width=0.87\textwidth]{DLP_algfinalfail}}{\alt<8>{\includegraphics[width=0.87\textwidth]{DLP_algfinalok}}{\alt<7>{\includegraphics[width=0.87\textwidth]{DLP_alg5b}}{\alt<6>{\includegraphics[width=0.87\textwidth]{DLP_alg5a}}{\alt<5>{\includegraphics[width=0.87\textwidth]{DLP_alg4}}{\alt<4>{\includegraphics[width=0.87\textwidth]{DLP_alg3}}{\alt<3>{\includegraphics[width=0.87\textwidth]{DLP_alg2}}{\alt<2>{\includegraphics[width=0.87\textwidth]{DLP_alg1}}{\includegraphics[width=0.87\textwidth]{DLP_alg0}}}}}}}}}
% \end{center}
% \end{frame}


% \begin{frame}\frametitle{Spurious Rules due to Incompleteness}
% \uncover<2->{\begin{center}\bl{In real world:}\end{center}}
% \alt<3>{\begin{picture}(0.5,0.5)\put(25,-160){\includegraphics[width=0.85\textwidth]{kg_polit3}}
% \end{picture}}{\alt<2>{\begin{picture}(0.5,0.5)\put(25,-160){\includegraphics[width=0.85\textwidth]{kg_polit2}}
% \end{picture}}{\begin{picture}(0.5,0.5)\put(25,-160){\includegraphics[width=0.85\textwidth]{kg_polit1}}
% \end{picture}}}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip

% \visible<1->{\rightline{\gr{$\mi{conf(r)}=\dfrac{|\myfilledtriangle{lightblue}|}{|\myfilledtriangle{lightblue}|+|\mytriangle{darkred}{white}|}=$\alt<3>{$\dfrac{2}{6}$}{$\dfrac{2}{3}$}}}}
% \bigskip
% \bigskip

% \alt<3>{\centerline{\gr{$\mi{r:\;\overbrace{isPoliticianOf(X,Z)}^{\mi{complete}}}\leftarrow \overbrace{\mi{hasChild(X,Y),isCitizenOf(Y,Z)}}^{\mi{incomplete}}$}}}{\centerline{\gr{$\mi{r:\;isPoliticianOf(X,Z)\leftarrow hasChild(X,Y),isCitizenOf(Y,Z)}$}}}

% \end{frame}


% \begin{frame}\frametitle{Hybrid Constraint-based Pattern Mining}
% \begin{itemize}
% \item Interlink \bl{mining} and \bl{reasoning}
% \item Use declarative \bl{logic programming} \\for frequent pattern (itemset/sequence) filtering
% \item Combine various \bl{domain-specific} constraints 
% \end{itemize}
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip
% \bigskip



% \begin{picture}(0.5,0.5)\put(40,-10){\includegraphics[width=0.7\textwidth]{constraint_mining}}
% \end{picture}
% \bigskip
% \bigskip

% \tiny{Sergey Paramonov, Daria Stepanova, Pauli Miettinen. Hybrid Approach to Constraint-based Pattern Mining. \emph{RR2017}}
% \end{frame}


% \begin{frame}\frametitle{Semantically-enhanced Fact Spotting}
% \bigskip
% \bigskip

% \textbf{\bl{KG population problem:}} some facts are hard to spot in text due to reporting bias \gr{$\mi{lost(nadal,australianOpen2017)}$} 
% \bigskip
% \bigskip

% \bl{\textbf{Given:}} 
% \begin{itemize}
% \item Fact: \gr{$\mi{lost(nadal,australianOpen2017)}$} 
% \item Rule set: \gr{$\mi{lost(Z,Y)\leftarrow won(X,Y),finalist(Z,Y), X\neq Z}$}
% \item KG:  \gr{$\mi{won(federer,australianOpen2017)}$}
% \item Text: \gr{``... \emph{another \textbf{finalist} of \textbf{Australian Open in 2017} was \textbf{Nadal}}''}
% \end{itemize}
% \bigskip
% \bigskip

% \bl{\textbf{Find:}}
% \begin{itemize}
% \item Fact's truth value: \gr{$\mi{lost(nadal,australianOpen2017)}$} is true!
% \end{itemize} 
% \bigskip
% \bigskip
% \bigskip

% \tiny{Joint work with Mohamed Gad Elrab, Jacopo Urbani and Gerhard Weikum}

% \end{frame}






\end{document}

%%% Local Variables:
%%% TeX-PDF-mode: t
%%% TeX-debug-bad-boxes: t
%%% TeX-master: t
%%% TeX-parse-self: t
%%% TeX-auto-save: t
%%% reftex-plug-into-AUCTeX: t
%%% End:

